[{"paperId": "defeaddec92b53fc2e9787cc3652e3d8be812193", "url": "https://www.semanticscholar.org/paper/defeaddec92b53fc2e9787cc3652e3d8be812193", "title": "Segment convolutional neural networks (Seg-CNNs) for classifying relations in clinical notes", "abstract": "We propose Segment Convolutional Neural Networks (Seg-CNNs) for classifying relations from clinical notes. Seg-CNNs use only word-embedding features without manual feature engineering. Unlike typical CNN models, relations between 2 concepts are identified by simultaneously learning separate representations for text segments in a sentence: preceding, concept1, middle, concept2, and succeeding. We evaluate Seg-CNN on the i2b2/VA relation classification challenge dataset. We show that Seg-CNN achieves a state-of-the-art micro-average F-measure of 0.742 for overall evaluation, 0.686 for classifying medical problem-treatment relations, 0.820 for medical problem-test relations, and 0.702 for medical problem-medical problem relations. We demonstrate the benefits of learning segment-level representations. We show that medical domain word embeddings help improve relation classification. Seg-CNNs can be trained quickly for the i2b2/VA dataset on a graphics processing unit (GPU) platform. These results support the use of CNNs computed over segments of text for classifying medical relations, as they show state-of-the-art performance while requiring no manual feature engineering.", "year": 2018, "authors": [{"authorId": "1683396", "name": "Yuan Luo"}, {"authorId": "145215470", "name": "Yu Cheng"}, {"authorId": "1723337", "name": "\u00d6zlem Uzuner"}, {"authorId": "1679873", "name": "Peter Szolovits"}, {"authorId": "1690334", "name": "J. Starren"}], "cluster": 6, "position": {"x": 48.402687072753906, "y": -4.6387939453125}}, {"paperId": "4fd75d18b231f73e9c878cb6029900e4b0e327bb", "url": "https://www.semanticscholar.org/paper/4fd75d18b231f73e9c878cb6029900e4b0e327bb", "title": "Intimate Partner Violence and Injury Prediction From Radiology Reports", "abstract": "Intimate partner violence (IPV) is an urgent, prevalent, and under-detected public health issue. We present machine learning models to assess patients for IPV and injury. We train the predictive algorithms on radiology reports with 1) IPV labels based on entry to a violence prevention program and 2) injury labels provided by emergency radiology fellowship-trained physicians. Our dataset includes 34,642 radiology reports and 1479 patients of IPV victims and control patients. Our best model predicts IPV a median of 3.08 years before violence prevention program entry with a sensitivity of 64% and a specificity of 95%. We conduct error analysis to determine for which patients our model has especially high or low performance and discuss next steps for a deployed clinical risk model.", "year": 2021, "authors": [{"authorId": "2056276811", "name": "Irene Chen"}, {"authorId": "50229020", "name": "Emily Alsentzer"}, {"authorId": "46904371", "name": "Hyesun Park"}, {"authorId": "2110842212", "name": "Richard Thomas"}, {"authorId": "4000824", "name": "Babina Gosangi"}, {"authorId": "6604731", "name": "Rahul Gujrathi"}, {"authorId": "5559176", "name": "B. Khurana"}], "cluster": 5, "position": {"x": 44.448638916015625, "y": 3.1683130264282227}}, {"paperId": "4554bc45be85cca73e3f94220c8cb056cf6ebf74", "url": "https://www.semanticscholar.org/paper/4554bc45be85cca73e3f94220c8cb056cf6ebf74", "title": "Fast, Structured Clinical Documentation via Contextual Autocomplete", "abstract": "We present a system that uses a learned autocompletion mechanism to facilitate rapid creation of semi-structured clinical documentation. We dynamically suggest relevant clinical concepts as a doctor drafts a note by leveraging features from both unstructured and structured medical data. By constraining our architecture to shallow neural networks, we are able to make these suggestions in real time. Furthermore, as our algorithm is used to write a note, we can automatically annotate the documentation with clean labels of clinical concepts drawn from medical vocabularies, making notes more structured and readable for physicians, patients, and future algorithms. To our knowledge, this system is the only machine learning-based documentation utility for clinical notes deployed in a live hospital setting, and it reduces keystroke burden of clinical concepts by 67% in real environments.", "year": 2020, "authors": [{"authorId": "39921534", "name": "Divya Gopinath"}, {"authorId": "2056898702", "name": "Monica Agrawal"}, {"authorId": "2056702606", "name": "Luke S. Murray"}, {"authorId": "2986398", "name": "S. Horng"}, {"authorId": "1743286", "name": "D. Karger"}, {"authorId": "1746662", "name": "D. Sontag"}], "cluster": 6, "position": {"x": 47.17366409301758, "y": -4.219060897827148}}, {"paperId": "d77719ba4be4196c9a918ce8dff0edf5aa3c04e7", "url": "https://www.semanticscholar.org/paper/d77719ba4be4196c9a918ce8dff0edf5aa3c04e7", "title": "A Review of Challenges and Opportunities in Machine Learning for Health.", "abstract": "Modern electronic health records (EHRs) provide data to answer clinically meaningful questions. The growing data in EHRs makes healthcare ripe for the use of machine learning. However, learning in a clinical setting presents unique challenges that complicate the use of common machine learning methodologies. For example, diseases in EHRs are poorly labeled, conditions can encompass multiple underlying endotypes, and healthy individuals are underrepresented. This article serves as a primer to illuminate these challenges and highlights opportunities for members of the machine learning community to contribute to healthcare.", "year": 2020, "authors": [{"authorId": "2804918", "name": "M. Ghassemi"}, {"authorId": "2113888405", "name": "Tristan Naumann"}, {"authorId": "145610328", "name": "Peter F. Schulam"}, {"authorId": "1507094362", "name": "A. Beam"}, {"authorId": "34574044", "name": "I. Chen"}, {"authorId": "2615814", "name": "R. Ranganath"}], "cluster": 5, "position": {"x": 45.81096649169922, "y": 4.535282611846924}}, {"paperId": "e7bf950be4cf8309d0df68d18fa09e77f5b2511a", "url": "https://www.semanticscholar.org/paper/e7bf950be4cf8309d0df68d18fa09e77f5b2511a", "title": "De-identification of patient notes with recurrent neural networks", "abstract": "Objective\nPatient notes in electronic health records (EHRs) may contain critical information for medical investigations. However, the vast majority of medical investigators can only access de-identified notes, in order to protect the confidentiality of patients. In the United States, the Health Insurance Portability and Accountability Act (HIPAA) defines 18 types of protected health information that needs to be removed to de-identify patient notes. Manual de-identification is impractical given the size of electronic health record databases, the limited number of researchers with access to non-de-identified notes, and the frequent mistakes of human annotators. A reliable automated de-identification system would consequently be of high value.\n\n\nMaterials and Methods\nWe introduce the first de-identification system based on artificial neural networks (ANNs), which requires no handcrafted features or rules, unlike existing systems. We compare the performance of the system with state-of-the-art systems on two datasets: the i2b2 2014 de-identification challenge dataset, which is the largest publicly available de-identification dataset, and the MIMIC de-identification dataset, which we assembled and is twice as large as the i2b2 2014 dataset.\n\n\nResults\nOur ANN model outperforms the state-of-the-art systems. It yields an F1-score of 97.85 on the i2b2 2014 dataset, with a recall of 97.38 and a precision of 98.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with a recall of 99.25 and a precision of 99.21.\n\n\nConclusion\nOur findings support the use of ANNs for de-identification of patient notes, as they show better performance than previously published systems while requiring no manual feature engineering.", "year": 2017, "authors": [{"authorId": "2462276", "name": "Franck Dernoncourt"}, {"authorId": "2108574824", "name": "J. Y. Lee"}, {"authorId": "1723337", "name": "\u00d6zlem Uzuner"}, {"authorId": "1679873", "name": "Peter Szolovits"}], "cluster": 6, "position": {"x": 46.57765579223633, "y": -2.758225679397583}}, {"paperId": "4a10dffca6dcce9c570cb75aa4d76522c34a2fd4", "url": "https://www.semanticscholar.org/paper/4a10dffca6dcce9c570cb75aa4d76522c34a2fd4", "title": "CORD-19: The COVID-19 Open Research Dataset", "abstract": "The COVID-19 Open Research Dataset (CORD-19) is a growing resource of scientific papers on COVID-19 and related historical coronavirus research. CORD-19 is designed to facilitate the development of text mining and information retrieval systems over its rich collection of metadata and structured full text papers. Since its release, CORD-19 has been downloaded over 200K times and has served as the basis of many COVID-19 text mining and discovery systems. In this article, we describe the mechanics of dataset construction, highlighting challenges and key design decisions, provide an overview of how CORD-19 has been used, and describe several shared tasks built around the dataset. We hope this resource will continue to bring together the computing community, biomedical experts, and policy makers in the search for effective treatments and management policies for COVID-19.", "year": 2020, "authors": [{"authorId": "31860505", "name": "Lucy Lu Wang"}, {"authorId": "46258841", "name": "Kyle Lo"}, {"authorId": "1648642525", "name": "Yoganand Chandrasekhar"}, {"authorId": "65983884", "name": "Russell Reas"}, {"authorId": "82148460", "name": "Jiangjiang Yang"}, {"authorId": "40329918", "name": "Darrin Eide"}, {"authorId": "37996742", "name": "Kathryn Funk"}, {"authorId": "143967880", "name": "Rodney Michael Kinney"}, {"authorId": "51427852", "name": "Ziyang Liu"}, {"authorId": "153908924", "name": "William Merrill"}, {"authorId": "115392299", "name": "P. Mooney"}, {"authorId": "69437054", "name": "D. Murdick"}, {"authorId": "1453742562", "name": "Devvret Rishi"}, {"authorId": "2055678827", "name": "J. Sheehan"}, {"authorId": "3303634", "name": "Zhihong Shen"}, {"authorId": "1405473759", "name": "Brandon Stilson"}, {"authorId": "1860983", "name": "Alex D Wade"}, {"authorId": "1748169", "name": "Kuansan Wang"}, {"authorId": "46212260", "name": "Christopher Wilhelm"}, {"authorId": "2064542611", "name": "Boya Xie"}, {"authorId": "21811471", "name": "Douglas A. Raymond"}, {"authorId": "1780531", "name": "Daniel S. Weld"}, {"authorId": "1741101", "name": "Oren Etzioni"}, {"authorId": "41018147", "name": "Sebastian Kohlmeier"}], "cluster": 15, "position": {"x": -6.375059127807617, "y": -42.22916030883789}}, {"paperId": "e8d330f11df9c69f38b78a7cc4b1333ebecf7c55", "url": "https://www.semanticscholar.org/paper/e8d330f11df9c69f38b78a7cc4b1333ebecf7c55", "title": "Ethical Machine Learning in Health Care", "abstract": "The use of machine learning (ML) in healthcare raises numerous ethical concerns, especially as models can amplify existing health inequities. Here, we outline ethical considerations for equitable ML in the advancement of healthcare. Specifically, we frame ethics of ML in healthcare through the lens of social justice. We describe ongoing efforts and outline challenges in a proposed pipeline of ethical ML in health, ranging from problem selection to postdeployment considerations. We close by summarizing recommendations to address these challenges.", "year": 2021, "authors": [{"authorId": "34574044", "name": "I. Chen"}, {"authorId": "145192191", "name": "E. Pierson"}, {"authorId": "48345067", "name": "Sherri Rose"}, {"authorId": "34287745", "name": "Shalmali Joshi"}, {"authorId": "6745873", "name": "Kadija Ferryman"}, {"authorId": "2804918", "name": "M. Ghassemi"}], "cluster": 5, "position": {"x": 45.74773025512695, "y": 6.7068657875061035}}, {"paperId": "e21ab639b0308a71aeac643a12f59a32603d091d", "url": "https://www.semanticscholar.org/paper/e21ab639b0308a71aeac643a12f59a32603d091d", "title": "UPSTAGE: Unsupervised Context Augmentation for Utterance Classification in Patient-Provider Communication", "abstract": "Conversations between patients and providers in clinical settings provide a source of natural language data that may reflect and correlate with the patients\u2019 experience and response to the treatment they are receiving. When analyzing utterances in such conversations, it is not sufficient to consider each sentence in isolation, since its context may play a role in determining its semantic meaning. Recently, contextual information in natural language documents has been modeled using various techniques, such as recurrent neural networks with latent variables, or neural networks with attention mechanisms. In this paper, we present UnsuPerviSed conText AuGmEntation (Upstage), a classification framework that relies on both local and global contextual information from different sources. Upstage uses transformer models with pretrained language models and joint sentence representation to solve the task of classifying health topics in patient-provider conversations. In addition, Upstage leverages unlabeled corpora for pretraining and data augmentation to provide additional context, which leads to improved classification performance.", "year": 2020, "authors": [{"authorId": "2028953652", "name": "D. Min"}, {"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "11976579", "name": "S. Kuo"}, {"authorId": "5492986", "name": "W. Herman"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}], "cluster": 6, "position": {"x": 49.58979034423828, "y": -4.4507598876953125}}, {"paperId": "462cc2046ef4d48d844813b66d8a1ed6dfda3bc0", "url": "https://www.semanticscholar.org/paper/462cc2046ef4d48d844813b66d8a1ed6dfda3bc0", "title": "HumAID: Human-Annotated Disaster Incidents Data from Twitter with Deep Learning Benchmarks", "abstract": "Social networks are widely used for information consumption and dissemination, especially during time-critical events such as natural disasters. Despite its significantly large volume, social media content is often too noisy for direct use in any application. Therefore, it is important to filter, categorize, and concisely summarize the available content to facilitate effective consumption and decision-making. To address such issues automatic classification systems have been developed using supervised modeling approaches, thanks to the earlier efforts on creating labeled datasets. However, existing datasets are limited in different aspects (e.g., size, contains duplicates) and less suitable to support more advanced and data-hungry deep learning models. In this paper, we present a new large-scale dataset with \u223c77K human-labeled tweets, sampled from a pool of \u223c24 million tweets across 19 disaster events that happened between 2016 and 2019. Moreover, we propose a data collection and sampling pipeline, which is important for social media data sampling for human annotation. We report multiclass classification results using classic and deep learning (fastText and transformer) based models to set the ground for future studies. The dataset and associated resources are publicly available at https: //crisisnlp.qcri.org/humaid_dataset.html.", "year": 2021, "authors": [{"authorId": "37784060", "name": "Firoj Alam"}, {"authorId": "48166270", "name": "U. Qazi"}, {"authorId": "151491159", "name": "Muhammad Imran"}, {"authorId": "48046557", "name": "Ferda Ofli"}], "cluster": 17, "position": {"x": -17.077383041381836, "y": -27.653974533081055}}, {"paperId": "3f8d4444cd124e21d4fa47b514c8267a3d5d9649", "url": "https://www.semanticscholar.org/paper/3f8d4444cd124e21d4fa47b514c8267a3d5d9649", "title": "Can AI Help Reduce Disparities in General Medical and Mental Health Care?", "abstract": "Background\nAs machine learning becomes increasingly common in health care applications, concerns have been raised about bias in these systems' data, algorithms, and recommendations. Simply put, as health care improves for some, it might not improve for all.\n\n\nMethods\nTwo case studies are examined using a machine learning algorithm on unstructured clinical and psychiatric notes to predict intensive care unit (ICU) mortality and 30-day psychiatric readmission with respect to race, gender, and insurance payer type as a proxy for socioeconomic status.\n\n\nResults\nClinical note topics and psychiatric note topics were heterogenous with respect to race, gender, and insurance payer type, which reflects known clinical findings. Differences in prediction accuracy and therefore machine bias are shown with respect to gender and insurance type for ICU mortality and with respect to insurance policy for psychiatric 30-day readmission.\n\n\nConclusions\nThis analysis can provide a framework for assessing and identifying disparate impacts of artificial intelligence in health care.", "year": 2019, "authors": [{"authorId": "34574044", "name": "I. Chen"}, {"authorId": "1679873", "name": "Peter Szolovits"}, {"authorId": "2804918", "name": "M. Ghassemi"}], "cluster": 5, "position": {"x": 44.916175842285156, "y": 5.740966320037842}}, {"paperId": "561ede166947a8bedb8be9acff182913156e06c6", "url": "https://www.semanticscholar.org/paper/561ede166947a8bedb8be9acff182913156e06c6", "title": "Domain Adaptation with Adversarial Training and Graph Embeddings", "abstract": "The success of deep neural networks (DNNs) is heavily dependent on the availability of labeled data. However, obtaining labeled data is a big challenge in many real-world problems. In such scenarios, a DNN model can leverage labeled and unlabeled data from a related domain, but it has to deal with the shift in data distributions between the source and the target domains. In this paper, we study the problem of classifying social media posts during a crisis event (e.g., Earthquake). For that, we use labeled and unlabeled data from past similar events (e.g., Flood) and unlabeled data for the current event. We propose a novel model that performs adversarial learning based domain adaptation to deal with distribution drifts and graph based semi-supervised learning to leverage unlabeled data within a single unified deep learning framework. Our experiments with two real-world crisis datasets collected from Twitter demonstrate significant improvements over several baselines.", "year": 2018, "authors": [{"authorId": "37784060", "name": "Firoj Alam"}, {"authorId": "2708940", "name": "Shafiq R. Joty"}, {"authorId": "32584303", "name": "Muhammad Imran"}], "cluster": 17, "position": {"x": -17.944101333618164, "y": -28.947751998901367}}, {"paperId": "579914dac924d6b4a17889ea7b0dd744a62bbd74", "url": "https://www.semanticscholar.org/paper/579914dac924d6b4a17889ea7b0dd744a62bbd74", "title": "IBC-C : A Dataset for Armed Conflict Event Analysis", "abstract": "We describe the Iraq Body Count Corpus (IBC-C) dataset, the first substantial armed conflict-related dataset which can be used for conflict analysis. IBC-C provides a ground-truth dataset for conflict specific named entity recognition, slot filling, and event de-duplication. IBC-C is constructed using data collected by the Iraq Body Count project which has been recording casualties resulting from the ongoing war in Iraq since 2003. We describe the dataset\u2019s creation, how it can be used for the above three tasks and provide initial baseline results for the first task (named entity recognition) using Hidden Markov Models, Conditional Random Fields, and Recursive Neural Networks.", "year": 2016, "authors": [{"authorId": "1400416026", "name": "Andrej \u017dukov-Gregori\u010d"}, {"authorId": "41209732", "name": "Bartal Veyhe"}, {"authorId": "2114937923", "name": "Zhiyuan Luo"}], "cluster": 0, "position": {"x": 38.45361328125, "y": -25.89143943786621}}, {"paperId": "2d40f76055a7c28dd30c8b8f60c31724f8991cd8", "url": "https://www.semanticscholar.org/paper/2d40f76055a7c28dd30c8b8f60c31724f8991cd8", "title": "The Ivory Tower Lost: How College Students Respond Differently than the General Public to the COVID-19 Pandemic", "abstract": "In the United States, the country with the highest confirmed COVID-19 infection cases, a nationwide social distancing protocol has been implemented by the President. Following the closure of the University of Washington on March 7th, more than 1000 colleges and universities in the United States have cancelled in-person classes and campus activities, impacting millions of students. This paper aims to discover the social implications of this unprecedented disruption in our interactive society regarding both the general public and higher education populations by mining people's opinions on social media. We discover several topics embedded in a large number of COVID-19 tweets that represent the most central issues related to the pandemic, which are of great concerns for both college students and the general public. Moreover, we find significant differences between these two groups of Twitter users with respect to the sentiments they expressed towards the COVID-19 issues. To our best knowledge, this is the first social media-based study which focuses on the college student community's demographics and responses to prevalent social issues during a major crisis.", "year": 2020, "authors": [{"authorId": "1840946", "name": "Viet-An Duong"}, {"authorId": "144270183", "name": "Phu Pham"}, {"authorId": "9572971", "name": "Tongyu Yang"}, {"authorId": null, "name": "Yu Wang"}, {"authorId": "33642939", "name": "Jiebo Luo"}], "cluster": 20, "position": {"x": -9.143911361694336, "y": -17.8424129486084}}, {"paperId": "2a29f7cc10fc18ce6e031e0cf6fc307a6b85d8e9", "url": "https://www.semanticscholar.org/paper/2a29f7cc10fc18ce6e031e0cf6fc307a6b85d8e9", "title": "CrisisMMD: Multimodal Twitter Datasets from Natural Disasters", "abstract": "During natural and man-made disasters, people use social media platforms such as Twitter to post textual and multime- dia content to report updates about injured or dead people, infrastructure damage, and missing or found people among other information types. Studies have revealed that this on- line information, if processed timely and effectively, is ex- tremely useful for humanitarian organizations to gain situational awareness and plan relief operations. In addition to the analysis of textual content, recent studies have shown that imagery content on social media can boost disaster response significantly. Despite extensive research that mainly focuses on textual content to extract useful information, limited work has focused on the use of imagery content or the combination of both content types. One of the reasons is the lack of labeled imagery data in this domain. Therefore, in this paper, we aim to tackle this limitation by releasing a large multi-modal dataset collected from Twitter during different natural disasters. We provide three types of annotations, which are useful to address a number of crisis response and management tasks for different humanitarian organizations.", "year": 2018, "authors": [{"authorId": "37784060", "name": "Firoj Alam"}, {"authorId": "1727159", "name": "Ferda Ofli"}, {"authorId": "32584303", "name": "Muhammad Imran"}], "cluster": 17, "position": {"x": -16.44186782836914, "y": -26.642818450927734}}, {"paperId": "3004f78d84752f3ffe8e54fa265b2ee85dac9728", "url": "https://www.semanticscholar.org/paper/3004f78d84752f3ffe8e54fa265b2ee85dac9728", "title": "Text as Data for Conflict Research: A Literature Survey", "abstract": "Computer-aided text analysis (CATA) offers exciting new possibilities for conflict research that this contribution describes using a range of exemplary studies from a variety of disciplines including sociology, political science, communication studies, and computer science. The chapter synthesizes empirical research that investigates conflict in relation to text across different formats and genres. This includes both conflict as it is verbalized in the news media, in political speeches, and other public documents and conflict as it occurs in online spaces (social media platforms, forums) and that is largely confined to such spaces (e.g., flaming and trolling). Particular emphasis is placed on research that aims to find commonalities between online and offline conflict, and that systematically investigates the dynamics of group behavior. Both work using inductive computational procedures, such as topic modeling, and supervised machine learning approaches are assessed, as are more traditional forms of content analysis, such as dictionaries. Finally, cross-validation is highlighted as a crucial step in CATA, in order to make the method as useful as possible to scholars interested in enlisting text mining for conflict research.", "year": 2019, "authors": [{"authorId": "9040191", "name": "Seraphine F. Maerz"}, {"authorId": "70224648", "name": "C. Puschmann"}], "cluster": 18, "position": {"x": 9.534296989440918, "y": -6.889867305755615}}, {"paperId": "aea14f23a951975f605a981d003386e46bf8acfe", "url": "https://www.semanticscholar.org/paper/aea14f23a951975f605a981d003386e46bf8acfe", "title": "A Neural Approach to Automated Essay Scoring", "abstract": "Traditional automated essay scoring systems rely on carefully designed features to evaluate and score essays. The performance of such systems is tightly bound to the quality of the underlying features. However, it is laborious to manually design the most informative features for such a system. In this paper, we develop an approach based on recurrent neural networks to learn the relation between an essay and its assigned score, without any feature engineering. We explore several neural network models for the task of automated essay scoring and perform some analysis to get some insights of the models. The results show that our best system, which is based on long short-term memory networks, outperforms a strong baseline by 5.6% in terms of quadratic weighted Kappa, without requiring any feature engineering.", "year": 2016, "authors": [{"authorId": "2916420", "name": "K. Taghipour"}, {"authorId": "34789794", "name": "H. Ng"}], "cluster": 7, "position": {"x": -18.88136100769043, "y": 20.33602523803711}}, {"paperId": "42c63d952f0cce7f89738e818fc9ab4e723bf7b6", "url": "https://www.semanticscholar.org/paper/42c63d952f0cce7f89738e818fc9ab4e723bf7b6", "title": "One-to-X analogical reasoning on word embeddings: a case for diachronic armed conflict prediction from news texts", "abstract": "We extend the well-known word analogy task to a one-to-X formulation, including one-to-none cases, when no correct answer exists. The task is cast as a relation discovery problem and applied to historical armed conflicts datasets, attempting to predict new relations of type `location:armed-group' based on data about past events. As the source of semantic information, we use diachronic word embedding models trained on English news texts. A simple technique to improve diachronic performance in such task is demonstrated, using a threshold based on a function of cosine distance to decrease the number of false positives; this approach is shown to be beneficial on two different corpora. Finally, we publish a ready-to-use test set for one-to-X analogy evaluation on historical armed conflicts data.", "year": 2019, "authors": [{"authorId": "2689095", "name": "Andrey Kutuzov"}, {"authorId": "2027091", "name": "Erik Velldal"}, {"authorId": "2732223", "name": "Lilja \u00d8vrelid"}], "cluster": 0, "position": {"x": 36.341548919677734, "y": -25.05143928527832}}, {"paperId": "636d4c0b0fe6919abe6eb546907d28ed39bf56e6", "url": "https://www.semanticscholar.org/paper/636d4c0b0fe6919abe6eb546907d28ed39bf56e6", "title": "Using Natural Language Processing for Automatic Detection of Plagiarism", "abstract": "Current plagiarism detection tools are mostly limited to comparisons of suspicious plagiarised texts and potential original texts at string level. In this study the aim is to improve the accuracy of plagiarism detection by incorporating Natural Language Processing (NLP) techniques into existing approaches. We propose a framework for external plagiarism detection in which a number of NLP techniques are applied to process a set of suspicious and original documents, not only to analyse strings but also the structure of the text, using resources to account for text relations. Initial results obtained with a corpus of plagiarised short paragraphs have showed that NLP techniques improve the accuracy of existing approaches.", "year": 2010, "authors": [{"authorId": "2004654", "name": "Miranda Chong"}, {"authorId": "1702974", "name": "Lucia Specia"}, {"authorId": "1746371", "name": "R. Mitkov"}], "cluster": 7, "position": {"x": -23.761474609375, "y": 22.631900787353516}}, {"paperId": "4ed75f35ae7343cd906f311390f572a58e36805c", "url": "https://www.semanticscholar.org/paper/4ed75f35ae7343cd906f311390f572a58e36805c", "title": "Enriching textbooks through data mining", "abstract": "Textbooks play an important role in any educational system. Unfortunately, many textbooks produced in developing countries are not written well and they often lack adequate coverage of important concepts. We propose a technological solution to address this problem based on enriching textbooks with authoritative web content. We augment textbooks at the section level for key concepts discussed in the section. We use ideas from data mining for identifying the concepts that need augmentation as well as to determine the links to the authoritative content that should be used for augmentation. Our evaluation, employing textbooks from India, shows that we are able to enrich textbooks on different subjects and across different grades with high quality augmentations using automated techniques.", "year": 2010, "authors": [{"authorId": "144947410", "name": "R. Agrawal"}, {"authorId": "144979147", "name": "Sreenivas Gollapudi"}, {"authorId": "1769861", "name": "K. Kenthapadi"}, {"authorId": "2897313", "name": "Nitish Srivastava"}, {"authorId": "13027331", "name": "R. Velu"}], "cluster": 7, "position": {"x": -27.2707462310791, "y": 13.85197639465332}}, {"paperId": "0eb5872733e643f43a0c1a7ff78953dfea74dfea", "url": "https://www.semanticscholar.org/paper/0eb5872733e643f43a0c1a7ff78953dfea74dfea", "title": "Automated Scoring: Beyond Natural Language Processing", "abstract": "In this position paper, we argue that building operational automated scoring systems is a task that has disciplinary complexity above and beyond standard competitive shared tasks which usually involve applying the latest machine learning techniques to publicly available data in order to obtain the best accuracy. Automated scoring systems warrant significant cross-discipline collaboration of which natural language processing and machine learning are just two of many important components. Such systems have multiple stakeholders with different but valid perspectives that can often times be at odds with each other. Our position is that it is essential for us as NLP researchers to understand and incorporate these perspectives in our research and work towards a mutually satisfactory solution in order to build automated scoring systems that are accurate, fair, unbiased, and useful.", "year": 2018, "authors": [{"authorId": "1723404", "name": "Nitin Madnani"}, {"authorId": "145557710", "name": "A. Cahill"}], "cluster": 7, "position": {"x": -19.782886505126953, "y": 20.816835403442383}}, {"paperId": "2ca0403eabc3893fed255fc119a927d83a1af739", "url": "https://www.semanticscholar.org/paper/2ca0403eabc3893fed255fc119a927d83a1af739", "title": "Tracing armed conflicts with diachronic word embedding models", "abstract": "Recent studies have shown that word embedding models can be used to trace time-related (diachronic) semantic shifts in particular words. In this paper, we evaluate some of these approaches on the new task of predicting the dynamics of global armed conflicts on a year-to-year basis, using a dataset from the conflict research field as the gold standard and the Gigaword news corpus as the training data. The results show that much work still remains in extracting \u2018cultural\u2019 semantic shifts from diachronic word embedding models. At the same time, we present a new task complete with an evaluation set and introduce the \u2018anchor words\u2019 method which outperforms previous approaches on this set.", "year": 2017, "authors": [{"authorId": "2689095", "name": "Andrey Kutuzov"}, {"authorId": "2027091", "name": "Erik Velldal"}, {"authorId": "2732223", "name": "Lilja \u00d8vrelid"}], "cluster": 0, "position": {"x": 36.7366828918457, "y": -25.910547256469727}}, {"paperId": "0cdeb238355617a640471987af36d8e09cd905c0", "url": "https://www.semanticscholar.org/paper/0cdeb238355617a640471987af36d8e09cd905c0", "title": "Event Data on Armed Conflict and Security: New Perspectives, Old Challenges, and Some Solutions", "abstract": "This article presents the Event Data on Conflict and Security (EDACS) dataset, discusses the inherent problems of georeferenced conflict data, and shows how these challenges are met within EDACS. Based on an event data approach, EDACS contributes to the growing number of novel georeferenced datasets that allow researchers to identify causal pathways of violence and the dynamics of (transboundary) violence through spatiotemporal disaggregation. However, the unreflected use of any of these datasets will give researchers unjustified confidence in their findings, as the pitfalls are many and propagating errors can result in misleading conclusions. To identify and handle the different challenges to overall event data quality, we argue in favor of transparency in the data collection and coding process, to empower analysts to challenge the data and avoid cascading errors. In particular, we investigate how the choice of news sources, the handling of geographic precision, and the use of auxiliary data can bias event data. We demonstrate how the EDACS dataset design enables the analyst to deal with these issues by providing a set of variables indicating the news sources, possible sources of bias, and detailed information on geographic precision. This allows for a flexible use of the data based on individual analytical requirements.", "year": 2012, "authors": [{"authorId": "52098235", "name": "S. Chojnacki"}, {"authorId": "69960834", "name": "Christian Ickler"}, {"authorId": "144839872", "name": "Michael Spies"}, {"authorId": "119191332", "name": "J. Wiesel"}], "cluster": 0, "position": {"x": 36.81386947631836, "y": -27.827735900878906}}, {"paperId": "311381feeb6346bfcb2ba622bd8f713261a4075d", "url": "https://www.semanticscholar.org/paper/311381feeb6346bfcb2ba622bd8f713261a4075d", "title": "Modeling the Relationship between User Comments and Edits in Document Revision", "abstract": "Management of collaborative documents can be difficult, given the profusion of edits and comments that multiple authors make during a document\u2019s evolution. Reliably modeling the relationship between edits and comments is a crucial step towards helping the user keep track of a document in flux. A number of authoring tasks, such as categorizing and summarizing edits, detecting completed to-dos, and visually rearranging comments could benefit from such a contribution. Thus, in this paper we explore the relationship between comments and edits by defining two novel, related tasks: Comment Ranking and Edit Anchoring. We begin by collecting a dataset with more than half a million comment-edit pairs based on Wikipedia revision histories. We then propose a hierarchical multi-layer deep neural-network to model the relationship between edits and comments. Our architecture tackles both Comment Ranking and Edit Anchoring tasks by encoding specific edit actions such as additions and deletions, while also accounting for document context. In a number of evaluation settings, our experimental results show that our approach outperforms several strong baselines significantly. We are able to achieve a precision@1 of 71.0% and a precision@3 of 94.4% for Comment Ranking, while we achieve 74.4% accuracy on Edit Anchoring.", "year": 2019, "authors": [{"authorId": "2048981220", "name": "Xuchao Zhang"}, {"authorId": "1801149", "name": "Dheeraj Rajagopal"}, {"authorId": "2417334", "name": "Michael Gamon"}, {"authorId": "3001990", "name": "Sujay Kumar Jauhar"}, {"authorId": "1752590", "name": "Chang-Tien Lu"}], "cluster": 6, "position": {"x": 43.38134765625, "y": -7.901239395141602}}, {"paperId": "bc6a4304afdf59783638a6a0d9fc2c2acb6e5b67", "url": "https://www.semanticscholar.org/paper/bc6a4304afdf59783638a6a0d9fc2c2acb6e5b67", "title": "Educational Question Answering Motivated by Question-Specific Concept Maps", "abstract": "Question answering (QA) is the automated process of answering general questions submitted by humans in natural language. QA has previously been explored within the educational context to facilitate learning, however the majority of works have focused on text-based answering. As an alternative, this paper proposes an approach to return answers as a concept map, which further encourages meaningful learning and knowledge organisation. Additionally, this paper investigates whether adapting the returned concept map to the specific question context provides further learning benefit. A randomised experiment was conducted with a sample of 59 Computer Science undergraduates, obtaining statistically significant results on learning gain when students are provided with the question-specific concept maps. Further, time spent on studying the concept maps were positively correlated with the learning gain.", "year": 2015, "authors": [{"authorId": "2469250", "name": "Thushari Atapattu"}, {"authorId": "1679867", "name": "K. Falkner"}, {"authorId": "1807135", "name": "Nickolas J. G. Falkner"}], "cluster": 7, "position": {"x": -25.422143936157227, "y": 17.237945556640625}}, {"paperId": "d114af5d3dcb3792bd9faec1476feba5aaf3617f", "url": "https://www.semanticscholar.org/paper/d114af5d3dcb3792bd9faec1476feba5aaf3617f", "title": "A Multimodal Human-Computer Interaction System and Its Application in Smart Learning Environments", "abstract": "A multimodal human-computer interaction system is composed of the comprehensive usage of various input and output channels. For the information input, apart from the traditional keyboard typing, mouse clicking, screen touching, the latest speech and face recognition technology can be used. For the output, the traditional screen display, the latest speech and facial expression synthesis and gesture generation can be used. After literature review of related works, this paper at first presents such a system, MMISE (Multimodal Interaction System for Education), about its architecture and working mechanism, POOOIIM (Pedagogical Objective Oriented Output, Input and Implementation Mechanism) illustrated with practical examples. Then this paper introduces this system\u2019s pilot applications in the epidemic time of novel coronavirus in 2020.", "year": 2020, "authors": [{"authorId": "40111240", "name": "Jiyou Jia"}, {"authorId": "1820790357", "name": "Yunfan He"}, {"authorId": "11019966", "name": "Huixiao Le"}], "cluster": 7, "position": {"x": -30.416410446166992, "y": 14.830124855041504}}, {"paperId": "f8868be52c8c0d64920e5f67870c01ba48601608", "url": "https://www.semanticscholar.org/paper/f8868be52c8c0d64920e5f67870c01ba48601608", "title": "Natural Language Processing and Language Learning", "abstract": "As a relatively young field of research and development started by work on cryptanalysis and machine translation around 50 years ago, Natural Language Processing (NLP) is concerned with the automated processing of human language. It addresses the analysis and generation of written and spoken language, though speech processing is often regarded as a separate subfield. NLP emphasizes processing and applications and as such can be seen as the applied side of Computational Linguistics, the interdisciplinary field of research concerned with formal analysis and modeling of language and its applications at the intersection of Linguistics, Computer Science, and Psychology. In terms of the language aspects dealt with in NLP, traditionally lexical, morphological and syntactic aspects of language were at the center of attention, but aspects of meaning, discourse, and the relation to the extra-linguistic context have become increasingly prominent in the last decade. A good introduction and overview of the field is provided in Jurafsky & Martin (2009).", "year": 2012, "authors": [{"authorId": "46191146", "name": "C. Chapelle"}, {"authorId": "2080321132", "name": "Blackwell"}], "cluster": 7, "position": {"x": -22.319643020629883, "y": 21.70616340637207}}, {"paperId": "911e61212eb26325d3fe58f454f36f4e70c54c7a", "url": "https://www.semanticscholar.org/paper/911e61212eb26325d3fe58f454f36f4e70c54c7a", "title": "Characterizing Stage-aware Writing Assistance for Collaborative Document Authoring", "abstract": "Writing is a complex non-linear process that begins with a mental model of intent, and progresses through an outline of ideas, to words on paper (and their subsequent refinement). Despite past research in understanding writing, Web-scale consumer and enterprise collaborative digital writing environments are yet to greatly benefit from intelligent systems that understand the stages of document evolution, providing opportune assistance based on authors' situated actions and context. In this paper, we present three studies that explore temporal stages of document authoring. We first survey information workers at a large technology company about their writing habits and preferences, concluding that writers do in fact conceptually progress through several distinct phases while authoring documents. We also explore, qualitatively, how writing stages are linked to document lifespan. We supplement these qualitative findings with an analysis of the longitudinal user interaction logs of a popular digital writing platform over several million documents. Finally, as a first step towards facilitating an intelligent digital writing assistant, we conduct a preliminary investigation into the utility of user interaction log data for predicting the temporal stage of a document. Our results support the benefit of tools tailored to writing stages, identify primary tasks associated with these stages, and show that it is possible to predict stages from anonymous interaction logs. Together, these results argue for the benefit and feasibility of more tailored digital writing assistance.", "year": 2020, "authors": [{"authorId": "2264984", "name": "Bahareh Sarrafzadeh"}, {"authorId": "3001990", "name": "Sujay Kumar Jauhar"}, {"authorId": "2417334", "name": "Michael Gamon"}, {"authorId": "144502831", "name": "E. Lank"}, {"authorId": "34286525", "name": "Ryen W. White"}], "cluster": 6, "position": {"x": 42.630889892578125, "y": -8.455682754516602}}, {"paperId": "e3bfb8a9ff3fe89a8e7747a82c7c0172d275ef3a", "url": "https://www.semanticscholar.org/paper/e3bfb8a9ff3fe89a8e7747a82c7c0172d275ef3a", "title": "Question answering system on education acts using NLP techniques", "abstract": "Question Answering (QA) system in information retrieval is a task of automatically answering a correct answer to the questions asked by human in natural language using either a pre-structured database or a collection of natural language documents. It presents only the requested information instead of searching full documents like search engine. As information in day to day life is increasing, so to retrieve the exact fragment of information even for a simple query requires large and expensive resources. This is the paper which describes the different methodology and implementation details of question answering system for general language and also proposes the closed domain QA System for handling documents related to education acts sections to retrieve more precise answers using NLP techniques.", "year": 2016, "authors": [{"authorId": "40649724", "name": "Sweta P. Lende"}, {"authorId": "1714912", "name": "M. Raghuwanshi"}], "cluster": 7, "position": {"x": -24.7214412689209, "y": 18.11271858215332}}, {"paperId": "065332576fd9b264a5a338549239bb39e6733819", "url": "https://www.semanticscholar.org/paper/065332576fd9b264a5a338549239bb39e6733819", "title": "Inferring Social Media Users\u2019 Mental Health Status from Multimodal Information", "abstract": "Worldwide, an increasing number of people are suffering from mental health disorders such as depression and anxiety. In the United States alone, one in every four adults suffers from a mental health condition, which makes mental health a pressing concern. In this paper, we explore the use of multimodal cues present in social media posts to predict users\u2019 mental health status. Specifically, we focus on identifying social media activity that either indicates a mental health condition or its onset. We collect posts from Flickr and apply a multimodal approach that consists of jointly analyzing language, visual, and metadata cues and their relation to mental health. We conduct several classification experiments aiming to discriminate between (1) healthy users and users affected by a mental health illness; and (2) healthy users and users prone to mental illness. Our experimental results indicate that using multiple modalities can improve the performance of this classification task as compared to the use of one modality at a time, and can provide important cues into a user\u2019s mental status.", "year": 2020, "authors": [{"authorId": "2898992", "name": "Z. Xu"}, {"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}], "cluster": 17, "position": {"x": -15.453354835510254, "y": -24.82683753967285}}, {"paperId": "55925bc2522a1d4cb007ac78273f7c2efafa3916", "url": "https://www.semanticscholar.org/paper/55925bc2522a1d4cb007ac78273f7c2efafa3916", "title": "Predicting Counselor Behaviors in Motivational Interviewing Encounters", "abstract": "As the number of people receiving psycho-therapeutic treatment increases, the automatic evaluation of counseling practice arises as an important challenge in the clinical domain. In this paper, we address the automatic evaluation of counseling performance by analyzing counselors\u2019 language during their interaction with clients. In particular, we present a model towards the automation of Motivational Interviewing (MI) coding, which is the current gold standard to evaluate MI counseling. First, we build a dataset of hand labeled MI encounters; second, we use text-based methods to extract and analyze linguistic patterns associated with counselor behaviors; and third, we develop an automatic system to predict these behaviors. We introduce a new set of features based on semantic information and syntactic patterns, and show that they lead to accuracy figures of up to 90%, which represent a significant improvement with respect to features used in the past.", "year": 2017, "authors": [{"authorId": "2108384855", "name": "Satinder Singh"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}, {"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "34613400", "name": "K. Resnicow"}, {"authorId": "2113905187", "name": "Lawrence An"}, {"authorId": "5400787", "name": "K. Goggin"}, {"authorId": "2307781", "name": "D. Catley"}], "cluster": 1, "position": {"x": -36.476436614990234, "y": -0.8391461372375488}}, {"paperId": "81d13af7eb78725492854bb9860b57af2b2a1778", "url": "https://www.semanticscholar.org/paper/81d13af7eb78725492854bb9860b57af2b2a1778", "title": "Data Mining and Student e-Learning Profiles", "abstract": "Data mining techniques have been applied to educational research in various ways. In this paper, I presented the application of sequential data mining algorithms to analyze computer logs to profile learners in terms of their learning tactic use and motivation in a web-based learning environment (gStudy). The data mining algorithms are employed to discover patterns which characterize learners either across session or groups based on their study tactic choice and goal orientation. The use of this method is illustrated through a sequential pattern analysis of gStudy log files generated by university students.", "year": 2010, "authors": [{"authorId": "50504088", "name": "Mingming Zhou"}], "cluster": 7, "position": {"x": -28.157934188842773, "y": 14.365102767944336}}, {"paperId": "9b0c9d241269b98c80f65a14d5d65263d0688d70", "url": "https://www.semanticscholar.org/paper/9b0c9d241269b98c80f65a14d5d65263d0688d70", "title": "What Makes a Good Counselor? Learning to Distinguish between High-quality and Low-quality Counseling Conversations", "abstract": "The quality of a counseling intervention relies highly on the active collaboration between clients and counselors. In this paper, we explore several linguistic aspects of the collaboration process occurring during counseling conversations. Specifically, we address the differences between high-quality and low-quality counseling. Our approach examines participants\u2019 turn-by-turn interaction, their linguistic alignment, the sentiment expressed by speakers during the conversation, as well as the different topics being discussed. Our results suggest important language differences in low- and high-quality counseling, which we further use to derive linguistic features able to capture the differences between the two groups. These features are then used to build automatic classifiers that can predict counseling quality with accuracies of up to 88%.", "year": 2019, "authors": [{"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "50171962", "name": "Xinyi Wu"}, {"authorId": "34613400", "name": "K. Resnicow"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}], "cluster": 1, "position": {"x": -37.05705642700195, "y": -2.1860506534576416}}, {"paperId": "c239aaa2a87ea63fae666b2051f1923afaa45fc2", "url": "https://www.semanticscholar.org/paper/c239aaa2a87ea63fae666b2051f1923afaa45fc2", "title": "HappyDB: A Corpus of 100, 000 Crowdsourced Happy Moments", "abstract": "The science of happiness is an area of positive psychology concerned with understanding what behaviors make people happy in a sustainable fashion. Recently, there has been interest in developing technologies that help incorporate the findings of the science of happiness into users' daily lives by steering them towards behaviors that increase happiness. With the goal of building technology that can understand how people express their happy moments in text, we crowd-sourced HappyDB, a corpus of 100,000 happy moments that we make publicly available. This paper describes HappyDB and its properties, and outlines several important NLP problems that can be studied with the help of the corpus. We also apply several state-of-the-art analysis techniques to analyze HappyDB. Our results demonstrate the need for deeper NLP techniques to be developed which makes HappyDB an exciting resource for follow-on research.", "year": 2018, "authors": [{"authorId": "35584853", "name": "Akari Asai"}, {"authorId": "35412470", "name": "Sara Evensen"}, {"authorId": "3047778", "name": "Behzad Golshan"}, {"authorId": "1770962", "name": "A. Halevy"}, {"authorId": "2052674361", "name": "Vivian Li"}, {"authorId": "2888751", "name": "A. Lopatenko"}, {"authorId": "46552353", "name": "Daniela Stepanov"}, {"authorId": "38844482", "name": "Yoshihiko Suhara"}, {"authorId": "34582619", "name": "W. Tan"}, {"authorId": "10032840", "name": "Yinzhan Xu"}], "cluster": 2, "position": {"x": -19.215099334716797, "y": 3.05825138092041}}, {"paperId": "35112c6bfa715b2bc86fc5b6c331f8a1a0b07add", "url": "https://www.semanticscholar.org/paper/35112c6bfa715b2bc86fc5b6c331f8a1a0b07add", "title": "Understanding and Predicting Empathic Behavior in Counseling Therapy", "abstract": "Counselor empathy is associated with better outcomes in psychology and behavioral counseling. In this paper, we explore several aspects pertaining to counseling interaction dynamics and their relation to counselor empathy during motivational interviewing encounters. Particularly, we analyze aspects such as participants\u2019 engagement, participants\u2019 verbal and nonverbal accommodation, as well as topics being discussed during the conversation, with the final goal of identifying linguistic and acoustic markers of counselor empathy. We also show how we can use these findings alongside other raw linguistic and acoustic features to build accurate counselor empathy classifiers with accuracies of up to 80%.", "year": 2017, "authors": [{"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}, {"authorId": "34613400", "name": "K. Resnicow"}, {"authorId": "2108384855", "name": "Satinder Singh"}, {"authorId": "2113905187", "name": "Lawrence An"}], "cluster": 1, "position": {"x": -38.42436599731445, "y": -0.9921884536743164}}, {"paperId": "c278eb333c78313a3762b5b2f07ace7443582b94", "url": "https://www.semanticscholar.org/paper/c278eb333c78313a3762b5b2f07ace7443582b94", "title": "Expressive Interviewing: A Conversational System for Coping with COVID-19", "abstract": "The ongoing COVID-19 pandemic has raised concerns for many regarding personal and public health implications, financial security and economic stability. Alongside many other unprecedented challenges, there are increasing concerns over social isolation and mental health. We introduce \\textit{Expressive Interviewing}--an interview-style conversational system that draws on ideas from motivational interviewing and expressive writing. Expressive Interviewing seeks to encourage users to express their thoughts and feelings through writing by asking them questions about how COVID-19 has impacted their lives. We present relevant aspects of the system's design and implementation as well as quantitative and qualitative analyses of user interactions with the system. In addition, we conduct a comparative evaluation with a general purpose dialogue system for mental health that shows our system potential in helping users to cope with COVID-19 issues.", "year": 2020, "authors": [{"authorId": "1484893124", "name": "Charles Welch"}, {"authorId": "1801600316", "name": "Allison Lahnala"}, {"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "2072820796", "name": "Siqi Shen"}, {"authorId": "94361572", "name": "S. Seraj"}, {"authorId": "2113905187", "name": "Lawrence An"}, {"authorId": "34613400", "name": "K. Resnicow"}, {"authorId": "1854783", "name": "J. Pennebaker"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}], "cluster": 20, "position": {"x": -13.287038803100586, "y": -16.358800888061523}}, {"paperId": "aa2bbf5a1485cc90401e4a35c04463fcb4e632f0", "url": "https://www.semanticscholar.org/paper/aa2bbf5a1485cc90401e4a35c04463fcb4e632f0", "title": "Quantifying the Effects of COVID-19 on Mental Health Support Forums", "abstract": "The COVID-19 pandemic, like many of the disease outbreaks that have preceded it, is likely to have a profound effect on mental health. Understanding its impact can inform strategies for mitigating negative consequences. In this work, we seek to better understand the effects of COVID-19 on mental health by examining discussions within mental health support communities on Reddit. First, we quantify the rate at which COVID-19 is discussed in each community, or subreddit, in order to understand levels of preoccupation with the pandemic. Next, we examine the volume of activity in order to determine whether the quantity of people seeking online mental health support has risen. Finally, we analyze how COVID-19 has influenced language use and topics of discussion within each subreddit.", "year": 2020, "authors": [{"authorId": "1395927418", "name": "Laura Biester"}, {"authorId": "92093876", "name": "K. Matton"}, {"authorId": "10197529", "name": "Janarthanan Rajendran"}, {"authorId": "2523983", "name": "E. Provost"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}], "cluster": 20, "position": {"x": -10.466595649719238, "y": -17.640480041503906}}, {"paperId": "c151f144c2c0e8d3b176edaf2ce5369c7707bd31", "url": "https://www.semanticscholar.org/paper/c151f144c2c0e8d3b176edaf2ce5369c7707bd31", "title": "Large-scale Analysis of Counseling Conversations: An Application of Natural Language Processing to Mental Health", "abstract": "Mental illness is one of the most pressing public health issues of our time. While counseling and psychotherapy can be effective treatments, our knowledge about how to conduct successful counseling conversations has been limited due to lack of large-scale data with labeled outcomes of the conversations. In this paper, we present a large-scale, quantitative study on the discourse of text-message-based counseling conversations. We develop a set of novel computational discourse analysis methods to measure how various linguistic aspects of conversations are correlated with conversation outcomes. Applying techniques such as sequence-based conversation models, language model comparisons, message clustering, and psycholinguistics-inspired word frequency analyses, we discover actionable conversation strategies that are associated with better conversation outcomes.", "year": 2016, "authors": [{"authorId": "1745524", "name": "Tim Althoff"}, {"authorId": "144358401", "name": "Kevin Clark"}, {"authorId": "1702139", "name": "J. Leskovec"}], "cluster": 1, "position": {"x": -35.721641540527344, "y": -3.0265092849731445}}, {"paperId": "7cb5bc9f8bc023f1f2c94e2e83012f1d35e4e01d", "url": "https://www.semanticscholar.org/paper/7cb5bc9f8bc023f1f2c94e2e83012f1d35e4e01d", "title": "Ingredients for Happiness: Modeling constructs via semi-supervised content driven inductive transfer", "abstract": "Modeling affect via understanding the social constructs behind them is an important task in devising robust and accurate systems for socially relevant scenarios. In the CL-Aff Shared Task (part of Affective Content Analysis workshop @ AAAI 2019), the organizers released a dataset of \u2018happy\u2019 moments, called the HappyDB corpus. The task is to detect two social constructs: the agency (i.e., whether the author is in control of the happy moment) and the social characteristics (i.e., whether anyone else other than the author was also involved in the happy moment). We employ an inductive transfer learning technique where we utilize a pre-trained language model and fine-tune it on the target task for both the binary classification tasks. At first, we use a language model pre-trained on the huge WikiText-103 corpus. This step utilizes an AWDLSTM with three hidden layers for training the language model. In the second step, we fine-tune the pre-trained language model on both the labeled and unlabeled instances from the HappyDB dataset. Finally, we train a classifier on top of the language model for each of the identification tasks. Our experiments using 10-fold cross validation on the corpus show that we achieve a high accuracy of \u223c93% for detection of the social characteristic and \u223c87% for agency of the author, showing significant gains over other baselines. We also show that using the unlabeled dataset for fine-tuning the language model in the second step improves our accuracy by 1-2% across detection of both the constructs.", "year": 2019, "authors": [{"authorId": "50708394", "name": "B. Syed"}, {"authorId": "7259599", "name": "Vijayasaradhi Indurthi"}, {"authorId": "2053918106", "name": "Kulin Shah"}, {"authorId": "46722320", "name": "Manish Gupta"}, {"authorId": "1704709", "name": "Vasudeva Varma"}], "cluster": 2, "position": {"x": -17.976837158203125, "y": 2.4455952644348145}}, {"paperId": "b688b67aa1980225e72e81f3d971d0e97a0d5484", "url": "https://www.semanticscholar.org/paper/b688b67aa1980225e72e81f3d971d0e97a0d5484", "title": "Building a Motivational Interviewing Dataset", "abstract": "This paper contributes a novel psychological dataset consisting of counselors\u2019 behaviors during Motivational Interviewing encounters. Annotations were conducted using the Motivational Interviewing Integrity Treatment (MITI). We describe relevant aspects associated with the construction of a dataset that relies on behavioral coding such as data acquisition, transcription, expert data annotations, and reliability assessments. The dataset contains a total of 22,719 counselor utterances extracted from 277 motivational interviewing sessions that are annotated with 10 counselor behavioral codes. The reliability analysis showed that annotators achieved excellent agreement at session level, with Intraclass Correlation Coefficient (ICC) scores in the range of 0.75 to 1, and fair to good agreement at utterance level, with Cohen\u2019s Kappa scores ranging from 0.31 to 0.64. Behavioral interventions are a promising approach to address public health issues such as smoking cessation, increasing physical activity, and reducing substance abuse, among others (Resnicow et al., 2002). In particular, Motivational Interviewing (MI), a client centered psychotherapy style, has been receiving increasing attention from the clinical psychology community due to its established efficacy for treating addiction and other behaviors (Moyers et al., 2009; Apodaca et al., 2014; Barnett et al., 2014; Catley et al., 2012). Despite its potential benefits in combating addiction and in providing broader disease prevention and management, implementing MI counseling at larger scale or in other domains is limited by the need for human-based evaluations. Currently, this requires a human either watching or listening to video-tapes and then providing evaluative feedback. Recently, computational approaches have been proposed to aid the MI evaluation process (Atkins et al., 2014; Xiao et al., 2014; Klonek et al., 2015). However, learning resources for this task are not readily available. Having such resources will enable the application of data-driven strategies for the automatic coding of counseling behaviors, thus providing researchers with automatic means for the evaluation of MI. Moreover, this can also be useful to explore how MI works by relating MI behaviors to health outcomes, and to provide counselors with evaluative feedback that helps them improve their MI skills. In this paper, we present the construction and validation of a dataset annotated with counselor verbal behaviours using the Motivational Interviewing Treatment Integrity 4.0 (MITI), which is the current gold standard for MI-based psychology interventions. The dataset is derived from 277 MI sessions containing a total of 22,719 coded utterances. 1 Motivational Interviewing Miller and Rollnick define MI as a collaborative, goal-oriented style of psychotherapy with particular attention to the language of change (Miller and Rollnick, 2013). MI has been widely used as a treatment method in clinical trials on psychotherapy research to address addictive behaviors such as alcohol, tobacco and drug use; promote healthier habits such as nutrition and fitness; and help clients with", "year": 2016, "authors": [{"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}, {"authorId": "34613400", "name": "K. Resnicow"}, {"authorId": "2108384855", "name": "Satinder Singh"}, {"authorId": "2113905187", "name": "Lawrence An"}], "cluster": 1, "position": {"x": -36.399452209472656, "y": 0.4972495138645172}}, {"paperId": "c2fd13dab7a581f2f875826b204d063f42b63a8b", "url": "https://www.semanticscholar.org/paper/c2fd13dab7a581f2f875826b204d063f42b63a8b", "title": "Happiness Entailment: Automating Suggestions for Well-Being", "abstract": "Understanding what makes people happy is a central topic in psychology. Prior work has mostly focused on developing self-reporting assessment tools for individuals and relies on experts to analyze the periodic reported assessments. One of the goals of the analysis is to understand what actions are necessary to encourage modifications in the behaviors of the individuals to improve their overall well-being. In this paper, we outline a complementary approach; on the assumption that the user journals her happy moments as short texts, a system can analyze these texts and propose sustainable suggestions for the user that may lead to an overall improvement in her well-being. We prototype one necessary component of such a system, the Happiness Entailment Recognition (HER)module, which takes as input a short text describing an event, a candidate suggestion, and outputs a determination about whether the suggestion is more likely to be good for this user based on the event described. This component is implemented as a neural network model with two encoders, one for the user input and one for the candidate actionable suggestion, with additional layers to capture psychologically significant features in the happy moment and suggestion. Our model achieves an AU-ROC of 0.831 and outperforms our baseline as well as the current state-of-the-art Textual Entailment model from AllenNLP by more than 48% of improvements, confirming the uniqueness and complexity of the HER task.", "year": 2019, "authors": [{"authorId": "35412470", "name": "Sara Evensen"}, {"authorId": "38844482", "name": "Yoshihiko Suhara"}, {"authorId": "1770962", "name": "A. Halevy"}, {"authorId": "2052674361", "name": "Vivian Li"}, {"authorId": "34582619", "name": "W. Tan"}, {"authorId": "91456334", "name": "Saran Mumick"}], "cluster": 2, "position": {"x": -19.29674530029297, "y": 1.8245487213134766}}, {"paperId": "1b41d919b912795927109fde8383d5bc25467b3c", "url": "https://www.semanticscholar.org/paper/1b41d919b912795927109fde8383d5bc25467b3c", "title": "HopeEDI: A Multilingual Hope Speech Detection Dataset for Equality, Diversity, and Inclusion", "abstract": "Over the past few years, systems have been developed to control online content and eliminate abusive, offensive or hate speech content. However, people in power sometimes misuse this form of censorship to obstruct the democratic right of freedom of speech. Therefore, it is imperative that research should take a positive reinforcement approach towards online content that is encouraging, positive and supportive contents. Until now, most studies have focused on solving this problem of negativity in the English language, though the problem is much more than just harmful content. Furthermore, it is multilingual as well. Thus, we have constructed a Hope Speech dataset for Equality, Diversity and Inclusion (HopeEDI) containing user-generated comments from the social media platform YouTube with 28,451, 20,198 and 10,705 comments in English, Tamil and Malayalam, respectively, manually labelled as containing hope speech or not. To our knowledge, this is the first research of its kind to annotate hope speech for equality, diversity and inclusion in a multilingual setting. We determined that the inter-annotator agreement of our dataset using Krippendorff\u2019s alpha. Further, we created several baselines to benchmark the resulting dataset and the results have been expressed using precision, recall and F1-score. The dataset is publicly available for the research community. We hope that this resource will spur further research on encouraging inclusive and responsive speech that reinforces positiveness.", "year": 2020, "authors": [{"authorId": "117018834", "name": "Bharathi Raja Chakravarthi"}], "cluster": 24, "position": {"x": 0.08429143577814102, "y": -4.155139446258545}}, {"paperId": "64c68fa52491c4a815f21917e068e4c19dd404b0", "url": "https://www.semanticscholar.org/paper/64c68fa52491c4a815f21917e068e4c19dd404b0", "title": "FERMI at SemEval-2019 Task 5: Using Sentence embeddings to Identify Hate Speech Against Immigrants and Women in Twitter", "abstract": "This paper describes our system (Fermi) for Task 5 of SemEval-2019: HatEval: Multilingual Detection of Hate Speech Against Immigrants and Women on Twitter. We participated in the subtask A for English and ranked first in the evaluation on the test set. We evaluate the quality of multiple sentence embeddings and explore multiple training models to evaluate the performance of simple yet effective embedding-ML combination algorithms. Our team - Fermi\u2019s model achieved an accuracy of 65.00% for English language in task A. Our models, which use pretrained Universal Encoder sentence embeddings for transforming the input and SVM (with RBF kernel) for classification, scored first position (among 68) in the leaderboard on the test set for Subtask A in English language. In this paper we provide a detailed description of the approach, as well as the results obtained in the task.", "year": 2019, "authors": [{"authorId": "7259599", "name": "Vijayasaradhi Indurthi"}, {"authorId": "50708394", "name": "B. Syed"}, {"authorId": "2045067", "name": "Manish Shrivastava"}, {"authorId": "138436346", "name": "Nikhil Chakravartula"}, {"authorId": "46722320", "name": "Manish Gupta"}, {"authorId": "1704709", "name": "Vasudeva Varma"}], "cluster": 24, "position": {"x": -0.6629555821418762, "y": -1.0045875310897827}}, {"paperId": "a9d09338a3a0d9102c1e623e6ad434a446c0bbfe", "url": "https://www.semanticscholar.org/paper/a9d09338a3a0d9102c1e623e6ad434a446c0bbfe", "title": "Automatic Classification of Neutralization Techniques in the Narrative of Climate Change Scepticism", "abstract": "Neutralisation techniques, e.g. denial of responsibility and denial of victim, are used in the narrative of climate change scepticism to justify lack of action or to promote an alternative view. We first draw on social science to introduce the problem to the community of nlp, present the granularity of the coding schema and then collect manual annotations of neutralised techniques in text relating to climate change, and experiment with supervised and semi- supervised BERT-based models.", "year": 2021, "authors": [{"authorId": "1984990", "name": "Shraey Bhatia"}, {"authorId": "1800564", "name": "Jey Han Lau"}, {"authorId": "123917295", "name": "Tim Baldwin"}], "cluster": 12, "position": {"x": -24.83423614501953, "y": -43.09953689575195}}, {"paperId": "9de154d3c886177380062be7c8d50304a335752f", "url": "https://www.semanticscholar.org/paper/9de154d3c886177380062be7c8d50304a335752f", "title": "Fermi at SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media using Sentence Embeddings", "abstract": "This paper describes our system (Fermi) for Task 6: OffensEval: Identifying and Categorizing Offensive Language in Social Media of SemEval-2019. We participated in all the three sub-tasks within Task 6. We evaluate multiple sentence embeddings in conjunction with various supervised machine learning algorithms and evaluate the performance of simple yet effective embedding-ML combination algorithms. Our team Fermi\u2019s model achieved an F1-score of 64.40%, 62.00% and 62.60% for sub-task A, B and C respectively on the official leaderboard. Our model for sub-task C which uses pre-trained ELMo embeddings for transforming the input and uses SVM (RBF kernel) for training, scored third position on the official leaderboard. Through the paper we provide a detailed description of the approach, as well as the results obtained for the task.", "year": 2019, "authors": [{"authorId": "7259599", "name": "Vijayasaradhi Indurthi"}, {"authorId": "50708394", "name": "B. Syed"}, {"authorId": "2045067", "name": "Manish Shrivastava"}, {"authorId": "46722320", "name": "Manish Gupta"}, {"authorId": "1704709", "name": "Vasudeva Varma"}], "cluster": 24, "position": {"x": -0.9179582595825195, "y": -0.16151808202266693}}, {"paperId": "32bf7ad3fdda71036b48f7dc85cad407674277b7", "url": "https://www.semanticscholar.org/paper/32bf7ad3fdda71036b48f7dc85cad407674277b7", "title": "Women worry about family, men about the economy: Gender differences in emotional responses to COVID-19", "abstract": "Among the critical challenges around the COVID-19 pandemic is dealing with the potentially detrimental effects on people's mental health. Designing appropriate interventions and identifying the concerns of those most at risk requires methods that can extract worries, concerns and emotional responses from text data. We examine gender differences and the effect of document length on worries about the ongoing COVID-19 situation. Our findings suggest that i) short texts do not offer as adequate insights into psychological processes as longer texts. We further find ii) marked gender differences in topics concerning emotional responses. Women worried more about their loved ones and severe health concerns while men were more occupied with effects on the economy and society. This paper adds to the understanding of general gender differences in language found elsewhere, and shows that the current unique circumstances likely amplified these effects. We close this paper with a call for more high-quality datasets due to the limitations of Tweet-sized data.", "year": 2020, "authors": [{"authorId": "51241310", "name": "Isabelle van der Vegt"}, {"authorId": "6032930", "name": "Bennett Kleinberg"}], "cluster": 20, "position": {"x": -11.657832145690918, "y": -17.307065963745117}}, {"paperId": "1d7a0e8be2bbe7d148bb48a1f9de218beaea4ed5", "url": "https://www.semanticscholar.org/paper/1d7a0e8be2bbe7d148bb48a1f9de218beaea4ed5", "title": "DeSMOG: Detecting Stance in Media On Global Warming", "abstract": "Citing opinions is a powerful yet understudied strategy in argumentation. For example, an environmental activist might say, \u201cLeading scientists agree that global warming is a serious concern,\u201d framing a clause which affirms their own stance (\u201cthat global warming is serious\u201d) as an opinion endorsed (\"[scientists] agree\u201d) by a reputable source (\u201cleading\u201d). In contrast, a global warming denier might frame the same clause as the opinion of an untrustworthy source with a predicate connoting doubt: \u201cMistaken scientists claim [...].\" Our work studies opinion-framing in the global warming (GW) debate, an increasingly partisan issue that has received little attention in NLP. We introduce DeSMOG, a dataset of stance-labeled GW sentences, and train a BERT classifier to study novel aspects of argumentation in how different sides of a debate represent their own and each other\u2019s opinions. From 56K news articles, we find that similar linguistic devices for self-affirming and opponent-doubting discourse are used across GW-accepting and skeptic media, though GW-skeptical media shows more opponent-doubt. We also find that authors often characterize sources as hypocritical, by ascribing opinions expressing the author\u2019s own view to source entities known to publicly endorse the opposing view. We release our stance dataset, model, and lexicons of framing devices for future work on opinion-framing and the automatic detection of GW stance.", "year": 2020, "authors": [{"authorId": "18160260", "name": "Yiwei Luo"}, {"authorId": "35540755", "name": "D. Card"}, {"authorId": "1746807", "name": "Dan Jurafsky"}], "cluster": 12, "position": {"x": -24.253582000732422, "y": -42.14400863647461}}, {"paperId": "1d37460baded22f488085e82985419178679dce0", "url": "https://www.semanticscholar.org/paper/1d37460baded22f488085e82985419178679dce0", "title": "The Climate Change Debate and Natural Language Processing", "abstract": "The debate around climate change (CC)\u2014its extent, its causes, and the necessary responses\u2014is intense and of global importance. Yet, in the natural language processing (NLP) community, this domain has so far received little attention. In contrast, it is of enormous prominence in various social science disciplines, and some of that work follows the \u201dtext-as-data\u201d paradigm, seeking to employ quantitative methods for analyzing large amounts of CC-related text. Other research is qualitative in nature and studies details, nuances, actors, and motivations within CC discourses. Coming from both NLP and Political Science, and reviewing key works in both disciplines, we discuss how social science approaches to CC debates can inform advances in text-mining/NLP, and how, in return, NLP can support policy-makers and activists in making sense of large-scale and complex CC discourses across multiple genres, channels, topics, and communities. This is paramount for their ability to make rapid and meaningful impact on the discourse, and for shaping the necessary policy change.", "year": 2021, "authors": [{"authorId": "2574304", "name": "Manfred Stede"}, {"authorId": "80953245", "name": "R. Patz"}], "cluster": 12, "position": {"x": -26.304122924804688, "y": -39.22821807861328}}, {"paperId": "998039a4876edc440e0cabb0bc42239b0eb29644", "url": "https://www.semanticscholar.org/paper/998039a4876edc440e0cabb0bc42239b0eb29644", "title": "Tackling Climate Change with Machine Learning", "abstract": "Climate change is one of the greatest challenges facing humanity, and we, as machine learning experts, may wonder how we can help. Here we describe how machine learning can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by machine learning, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the machine learning community to join the global effort against climate change.", "year": 2019, "authors": [{"authorId": "2381187", "name": "D. Rolnick"}, {"authorId": "49698491", "name": "P. Donti"}, {"authorId": "12736608", "name": "L. Kaack"}, {"authorId": "80536011", "name": "K. Kochanski"}, {"authorId": "8651990", "name": "Alexandre Lacoste"}, {"authorId": "46769963", "name": "K. Sankaran"}, {"authorId": "2068943123", "name": "Andrew Slavin Ross"}, {"authorId": "1417437895", "name": "Nikola Milojevic-Dupont"}, {"authorId": "3106683", "name": "Natasha Jaques"}, {"authorId": "1419467725", "name": "Anna Waldman-Brown"}, {"authorId": "2993731", "name": "Alexandra Luccioni"}, {"authorId": "3422058", "name": "Tegan Maharaj"}, {"authorId": "74936246", "name": "Evan D. Sherwin"}, {"authorId": "103485736", "name": "S. Mukkavilli"}, {"authorId": "36121677", "name": "K. K\u00f6rding"}, {"authorId": "2064532325", "name": "Carla P. Gomes"}, {"authorId": "2067948334", "name": "Andrew Y. Ng"}, {"authorId": "48987704", "name": "D. Hassabis"}, {"authorId": "144189092", "name": "John C. Platt"}, {"authorId": "47628266", "name": "F. Creutzig"}, {"authorId": "1695997", "name": "J. Chayes"}, {"authorId": "1751762", "name": "Yoshua Bengio"}], "cluster": 8, "position": {"x": -33.734458923339844, "y": -24.0400333404541}}, {"paperId": "52ef2bea83eba1575fcfd02c82b4228f7aab0bd6", "url": "https://www.semanticscholar.org/paper/52ef2bea83eba1575fcfd02c82b4228f7aab0bd6", "title": "Cheap Talk and Cherry-Picking: What ClimateBert has to say on Corporate Climate Risk Disclosures", "abstract": "Disclosure of climate-related financial risks greatly helps investors assess companies' preparedness for climate change. Voluntary disclosures such as those based on the recommendations of the Task Force for Climate-related Financial Disclosures (TCFD) are being hailed as an effective measure for better climate risk management. We ask whether this expectation is justified. We do so with the help of a deep neural language model, which we christen ClimateBert. We train ClimateBert on thousands of sentences related to climate-risk disclosures aligned with the TCFD recommendations. In analyzing the disclosures of TCFD-supporting firms, ClimateBert comes to the sobering conclusion that the firms' TCFD support is mostly cheap talk and that firms cherry-pick to report primarily non-material climate risk information. From our analysis, we conclude that the only way out of this dilemma is to turn voluntary reporting into regulatory disclosures.", "year": 2021, "authors": [{"authorId": "2006205621", "name": "Julia Anna Bingler"}, {"authorId": "10743797", "name": "Mathias Kraus"}, {"authorId": "3073566", "name": "Markus Leippold"}], "cluster": 12, "position": {"x": -34.88462448120117, "y": -34.34577941894531}}, {"paperId": "bbc6486ad37365b77b9d0de8894f595d70af49ac", "url": "https://www.semanticscholar.org/paper/bbc6486ad37365b77b9d0de8894f595d70af49ac", "title": "Ask BERT: How Regulatory Disclosure of Transition and Physical Climate Risks affects the CDS Term Structure", "abstract": "We use BERT, an AI-based algorithm for language understanding, to decipher regulatory climate-risk disclosures and measure their impact on the credit default swap (CDS) market. Risk disclosures can either increase or decrease credit spreads, depending on whether disclosure reveals new risks or sharpens the signal and decreases the uncertainty. Training BERT to differentiate between transition and physical climate risks, we find that disclosing transition risks increases CDS spreads, especially after the Paris Climate Agreement of 2015, while disclosing physical climate risks leads to a decrease in CDS spreads. These impacts are statistically and economically highly significant.", "year": 2020, "authors": [{"authorId": "104846221", "name": "Julian F. K\u00f6lbel"}, {"authorId": "3073566", "name": "Markus Leippold"}, {"authorId": "2050613648", "name": "J. Rillaerts"}, {"authorId": "2048787257", "name": "Q. Wang"}], "cluster": 12, "position": {"x": -35.6352653503418, "y": -34.799095153808594}}, {"paperId": "134c8486ae58b421681656c85bbc48dc862f6f98", "url": "https://www.semanticscholar.org/paper/134c8486ae58b421681656c85bbc48dc862f6f98", "title": "ClimaText: A Dataset for Climate Change Topic Detection", "abstract": "Climate change communication in the mass media and other textual sources may affect and shape public perception. Extracting climate change information from these sources is an important task, e.g., for filtering content and e-discovery, sentiment analysis, automatic summarization, question-answering, and fact-checking. However, automating this process is a challenge, as climate change is a complex, fast-moving, and often ambiguous topic with scarce resources for popular text-based AI tasks. In this paper, we introduce \\textsc{ClimaText}, a dataset for sentence-based climate change topic detection, which we make publicly available. We explore different approaches to identify the climate change topic in various text sources. We find that popular keyword-based models are not adequate for such a complex and evolving task. Context-based algorithms like BERT \\cite{devlin2018bert} can detect, in addition to many trivial cases, a variety of complex and implicit topic patterns. Nevertheless, our analysis reveals a great potential for improvement in several directions, such as, e.g., capturing the discussion on indirect effects of climate change. Hence, we hope this work can serve as a good starting point for further research on this topic.", "year": 2020, "authors": [{"authorId": "2029887098", "name": "Francesco S. Varini"}, {"authorId": "1389036863", "name": "Jordan L. Boyd-Graber"}, {"authorId": "2754495", "name": "Massimiliano Ciaramita"}, {"authorId": "3073566", "name": "Markus Leippold"}], "cluster": 12, "position": {"x": -24.93079376220703, "y": -39.02309036254883}}, {"paperId": "086e6733e5fda70bbce0c7545bd06d5634918a60", "url": "https://www.semanticscholar.org/paper/086e6733e5fda70bbce0c7545bd06d5634918a60", "title": "CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims", "abstract": "We introduce CLIMATE-FEVER, a new publicly available dataset for verification of climate change-related claims. By providing a dataset for the research community, we aim to facilitate and encourage work on improving algorithms for retrieving evidential support for climate-specific claims, addressing the underlying language understanding challenges, and ultimately help alleviate the impact of misinformation on climate change. We adapt the methodology of FEVER [1], the largest dataset of artificially designed claims, to real-life claims collected from the Internet. While during this process, we could rely on the expertise of renowned climate scientists, it turned out to be no easy task. We discuss the surprising, subtle complexity of modeling real-world climate-related claims within the \\textsc{fever} framework, which we believe provides a valuable challenge for general natural language understanding. We hope that our work will mark the beginning of a new exciting long-term joint effort by the climate science and AI community.", "year": 2020, "authors": [{"authorId": "2106073554", "name": "Thomas Diggelmann"}, {"authorId": "1389036863", "name": "Jordan L. Boyd-Graber"}, {"authorId": "2362210", "name": "Jannis Bulian"}, {"authorId": "2754495", "name": "Massimiliano Ciaramita"}, {"authorId": "3073566", "name": "Markus Leippold"}], "cluster": 12, "position": {"x": -27.42916488647461, "y": -35.3819580078125}}, {"paperId": "418b9f37b07a05b38798e97f57e17a6cc1048b92", "url": "https://www.semanticscholar.org/paper/418b9f37b07a05b38798e97f57e17a6cc1048b92", "title": "You are right. I am ALARMED - But by Climate Change Counter Movement", "abstract": "The world is facing the challenge of climate crisis. Despite the consensus in scientific community about anthropogenic global warming, the web is flooded with articles spreading climate misinformation. These articles are carefully constructed by climate change counter movement (cccm) organizations to influence the narrative around climate change. We revisit the literature on climate misinformation in social sciences and repackage it to introduce in the community of NLP. Despite considerable work in detection of fake news, there is no misinformation dataset available that is specific to the domain.of climate change. We try to bridge this gap by scraping and releasing articles with known climate change misinformation.", "year": 2020, "authors": [{"authorId": "1984990", "name": "Shraey Bhatia"}, {"authorId": "1800564", "name": "Jey Han Lau"}, {"authorId": "145465286", "name": "Timothy Baldwin"}], "cluster": 12, "position": {"x": -28.609600067138672, "y": -37.00680160522461}}, {"paperId": "171847842d161743f2b52dc4f85c121087ceb426", "url": "https://www.semanticscholar.org/paper/171847842d161743f2b52dc4f85c121087ceb426", "title": "Comparing Attitudes to Climate Change in the Media using sentiment analysis based on Latent Dirichlet Allocation", "abstract": "News media typically present biased accounts of news stories, and different publications present different angles on the same event. In this research, we investigate how different publications differ in their approach to stories about climate change, by examining the sentiment and topics presented. To understand these attitudes, we find sentiment targets by combining Latent Dirichlet Allocation (LDA) with SentiWordNet, a general sentiment lexicon. Using LDA, we generate topics containing keywords which represent the sentiment targets, and then annotate the data using SentiWordNet before regrouping the articles based on topic similarity. Preliminary analysis identifies clearly different attitudes on the same issue presented in different news sources. Ongoing work is investigating how systematic these attitudes are between different publications, and how these may change over time.", "year": 2017, "authors": [{"authorId": "2051229488", "name": "Ye Jiang"}, {"authorId": "3456762", "name": "Xingyi Song"}, {"authorId": "48276492", "name": "J. Harrison"}, {"authorId": "1776008", "name": "S. Quegan"}, {"authorId": "2144272", "name": "D. Maynard"}], "cluster": 12, "position": {"x": -23.151180267333984, "y": -38.945091247558594}}, {"paperId": "9b1653e3b57016958d10ff8531475eb0483d156c", "url": "https://www.semanticscholar.org/paper/9b1653e3b57016958d10ff8531475eb0483d156c", "title": "Social Privacy in Networked Publics: Teens\u2019 Attitudes, Practices, and Strategies", "abstract": "This paper examines how teens understand privacy in highly public networked environments like Facebook and Twitter. We describe both teens\u2019 practices, their privacy strategies, and the structural conditions in which they are embedded, highlighting the ways in which privacy, as it plays out in everyday life, is related more to agency and the ability to control a social situation than particular properties of information. Finally, we discuss the implications of teens\u2019 practices and strategies, revealing the importance of social norms as a regulatory force.(This paper was presented at Oxford Internet Institute\u2019s \u201cA Decade in Internet Time: Symposium on the Dynamics of the Internet and Society\u201d on September 22, 2011.)", "year": 2011, "authors": [{"authorId": "38818867", "name": "D. Boyd"}, {"authorId": "2929988", "name": "Alice E. Marwick"}], "cluster": 3, "position": {"x": 38.11747360229492, "y": 23.77903175354004}}, {"paperId": "f071e7c19fc18fc4d4ab69ce13f0c4e92cfb08c4", "url": "https://www.semanticscholar.org/paper/f071e7c19fc18fc4d4ab69ce13f0c4e92cfb08c4", "title": "Learning Twitter User Sentiments on Climate Change with Limited Labeled Data", "abstract": "While it is well-documented that climate change accepters and deniers have become increasingly polarized in the United States over time, there has been no large-scale examination of whether these individuals are prone to changing their opinions as a result of natural external occurrences. On the sub-population of Twitter users, we examine whether climate change sentiment changes in response to five separate natural disasters occurring in the U.S. in 2018. We begin by showing that relevant tweets can be classified with over 75% accuracy as either accepting or denying climate change when using our methodology to compensate for limited labeled data; results are robust across several machine learning models and yield geographic-level results in line with prior research. We then apply RNNs to conduct a cohort-level analysis showing that the 2018 hurricanes yielded a statistically significant increase in average tweet sentiment affirming climate change. However, this effect does not hold for the 2018 blizzard and wildfires studied, implying that Twitter users' opinions on climate change are fairly ingrained on this subset of natural disasters.", "year": 2019, "authors": [{"authorId": "101883616", "name": "Allison Koenecke"}, {"authorId": "1411879443", "name": "Jordi Feliu-Fab\u00e0"}], "cluster": 12, "position": {"x": -24.394798278808594, "y": -35.670372009277344}}, {"paperId": "29584ed6d68a06fdf91440a018f6bc83a44fd177", "url": "https://www.semanticscholar.org/paper/29584ed6d68a06fdf91440a018f6bc83a44fd177", "title": "Paragraph-level Rationale Extraction through Regularization: A case study on European Court of Human Rights Cases", "abstract": "Interpretability or explainability is an emerging research field in NLP. From a user-centric point of view, the goal is to build models that provide proper justification for their decisions, similar to those of humans, by requiring the models to satisfy additional constraints. To this end, we introduce a new application on legal text where, contrary to mainstream literature targeting word-level rationales, we conceive rationales as selected paragraphs in multi-paragraph structured court cases. We also release a new dataset comprising European Court of Human Rights cases, including annotations for paragraph-level rationales. We use this dataset to study the effect of already proposed rationale constraints, i.e., sparsity, continuity, and comprehensiveness, formulated as regularizers. Our findings indicate that some of these constraints are not beneficial in paragraph-level rationale extraction, while others need re-formulation to better handle the multi-label nature of the task we consider. We also introduce a new constraint, singularity, which further improves the quality of rationales, even compared with noisy rationale supervision. Experimental results indicate that the newly introduced task is very challenging and there is a large scope for further research.", "year": 2021, "authors": [{"authorId": "10783142", "name": "Ilias Chalkidis"}, {"authorId": "121316873", "name": "Manos Fergadiotis"}, {"authorId": "8245526", "name": "D. Tsarapatsanis"}, {"authorId": "2042831965", "name": "Nikolaos Aletras"}, {"authorId": "1752430", "name": "Ion Androutsopoulos"}, {"authorId": "1950133", "name": "Prodromos Malakasiotis"}], "cluster": 15, "position": {"x": 2.163275957107544, "y": -50.387943267822266}}, {"paperId": "2547836827e0423f198320977d393f574e0fb3d6", "url": "https://www.semanticscholar.org/paper/2547836827e0423f198320977d393f574e0fb3d6", "title": "Framing and Agenda-setting in Russian News: a Computational Analysis of Intricate Political Strategies", "abstract": "Amidst growing concern over media manipulation, NLP attention has focused on overt strategies like censorship and \u201cfake news\u201d. Here, we draw on two concepts from political science literature to explore subtler strategies for government media manipulation: agenda-setting (selecting what topics to cover) and framing (deciding how topics are covered). We analyze 13 years (100K articles) of the Russian newspaper Izvestia and identify a strategy of distraction: articles mention the U.S. more frequently in the month directly following an economic downturn in Russia. We introduce embedding-based methods for cross-lingually projecting English frames to Russian, and discover that these articles emphasize U.S. moral failings and threats to the U.S. Our work offers new ways to identify subtle media manipulation strategies at the intersection of agenda-setting and framing.", "year": 2018, "authors": [{"authorId": "49713890", "name": "Anjalie Field"}, {"authorId": "38317249", "name": "Doron Kliger"}, {"authorId": "2524073", "name": "S. Wintner"}, {"authorId": "50617806", "name": "Jennifer Pan"}, {"authorId": "1746807", "name": "Dan Jurafsky"}, {"authorId": "145317727", "name": "Yulia Tsvetkov"}], "cluster": 19, "position": {"x": 15.899378776550293, "y": -12.783203125}}, {"paperId": "9c2cab0e72f2588e857671c1fbb13b5fba8f2586", "url": "https://www.semanticscholar.org/paper/9c2cab0e72f2588e857671c1fbb13b5fba8f2586", "title": "Cross-Platform Disinformation Campaigns: Lessons Learned and Next Steps", "abstract": "We conducted a mixed-method, interpretative analysis of an online, cross-platform disinformation campaign targeting the White Helmets, a rescue group operating in rebel-held areas of Syria that has become the subject of a persistent effort of delegitimization. This research helps to conceptualize what a disinformation campaign is and how it works. Based on what we learned from this case study, we conclude that a comprehensive understanding of disinformation requires accounting for the spread of content across platforms and that social media platforms should increase collaboration to detect and characterize disinformation campaigns.", "year": 2020, "authors": [{"authorId": "3181624", "name": "Kate Starbird"}, {"authorId": "50503504", "name": "T. Wilson"}], "cluster": 15, "position": {"x": 10.732643127441406, "y": -33.301387786865234}}, {"paperId": "3475876c3f5e624587181744bc5acf4223aecd00", "url": "https://www.semanticscholar.org/paper/3475876c3f5e624587181744bc5acf4223aecd00", "title": "Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings", "abstract": "We provide an NLP framework to uncover four linguistic dimensions of political polarization in social media: topic choice, framing, affect and illocutionary force. We quantify these aspects with existing lexical methods, and propose clustering of tweet embeddings as a means to identify salient topics for analysis across events; human evaluations show that our approach generates more cohesive topics than traditional LDA-based models. We apply our methods to study 4.4M tweets on 21 mass shootings. We provide evidence that the discussion of these events is highly polarized politically and that this polarization is primarily driven by partisan differences in framing rather than topic choice. We identify framing devices, such as grounding and the contrasting use of the terms \u201cterrorist\u201d and \u201ccrazy\u201d, that contribute to polarization. Results pertaining to topic choice, affect and illocutionary force suggest that Republicans focus more on the shooter and event-specific facts (news) while Democrats focus more on the victims and call for policy changes. Our work contributes to a deeper understanding of the way group divisions manifest in language and to computational methods for studying them.", "year": 2019, "authors": [{"authorId": "81551000", "name": "Dorottya Demszky"}, {"authorId": "2779427", "name": "Nikhil Garg"}, {"authorId": "35248702", "name": "R. Voigt"}, {"authorId": "145085305", "name": "James Y. Zou"}, {"authorId": "8731644", "name": "Matthew Gentzkow"}, {"authorId": "122795272", "name": "Jesse M. Shapiro"}, {"authorId": "1746807", "name": "Dan Jurafsky"}], "cluster": 18, "position": {"x": 10.499655723571777, "y": -9.777066230773926}}, {"paperId": "546c87abc26137359c43898559884ba9d6c5ae64", "url": "https://www.semanticscholar.org/paper/546c87abc26137359c43898559884ba9d6c5ae64", "title": "Predicting the Role of Political Trolls in Social Media", "abstract": "We investigate the political roles of \"Internet trolls\" in social media. Political trolls, such as the ones linked to the Russian Internet Research Agency (IRA), have recently gained enormous attention for their ability to sway public opinion and even influence elections. Analysis of the online traces of trolls has shown different behavioral patterns, which target different slices of the population. However, this analysis is manual and labor-intensive, thus making it impractical as a first-response tool for newly-discovered troll farms. In this paper, we show how to automate this analysis by using machine learning in a realistic setting. In particular, we show how to classify trolls according to their political role ---left, news feed, right--- by using features extracted from social media, i.e., Twitter, in two scenarios: (i) in a traditional supervised learning scenario, where labels for trolls are available, and (ii) in a distant supervision scenario, where labels for trolls are not available, and we rely on more-commonly-available labels for news outlets mentioned by the trolls. Technically, we leverage the community structure and the text of the messages in the online social network of trolls represented as a graph, from which we extract several types of learned representations, i.e.,~embeddings, for the trolls. Experiments on the \"IRA Russian Troll\" dataset show that our methodology improves over the state-of-the-art in the first scenario, while providing a compelling case for the second scenario, which has not been explored in the literature thus far.", "year": 2019, "authors": [{"authorId": "2063953501", "name": "Atanas Atanasov"}, {"authorId": "35168570", "name": "G. D. F. Morales"}, {"authorId": "1683562", "name": "Preslav Nakov"}], "cluster": 23, "position": {"x": -7.312419891357422, "y": -6.495222091674805}}, {"paperId": "08e3ce4454012d928470efa96a54aa08dd8a96b0", "url": "https://www.semanticscholar.org/paper/08e3ce4454012d928470efa96a54aa08dd8a96b0", "title": "Automatically Characterizing Targeted Information Operations Through Biases Present in Discourse on Twitter", "abstract": "This paper considers the problem of automatically characterizing biases that may be associated with emerging information operations via artificial intelligence. Accurate analysis of these emerging topics usually requires laborious, manual analysis by experts to annotate millions of tweets to identify biases in new topics. We introduce adaptations of the Word Embedding Association Test [1] to a new domain: information operations. We validate our method using known information operation-related tweets from Twitter's Transparency Reports, and we perform a case study on the COVID-19 pandemic to evaluate our method's performance on non-labeled Twitter data, demonstrating its usability in emerging domains.", "year": 2021, "authors": [{"authorId": "1643684431", "name": "Autumn Toney"}, {"authorId": "2070539062", "name": "Akshat Pandey"}, {"authorId": "28735341", "name": "W. Guo"}, {"authorId": "3119101", "name": "David A. Broniatowski"}, {"authorId": "144537437", "name": "Aylin Caliskan"}], "cluster": 18, "position": {"x": 8.78038215637207, "y": -10.628458976745605}}, {"paperId": "a12d22ff91ce159a0d3558ed5aaed115115beabd", "url": "https://www.semanticscholar.org/paper/a12d22ff91ce159a0d3558ed5aaed115115beabd", "title": "Fine-Grained Analysis of Propaganda in News Articles", "abstract": "Propaganda aims at influencing people\u2019s mindset with the purpose of advancing a specific agenda. Previous work has addressed propaganda detection at document level, typically labelling all articles from a propagandistic news outlet as propaganda. Such noisy gold labels inevitably affect the quality of any learning system trained on them. A further issue with most existing systems is the lack of explainability. To overcome these limitations, we propose a novel task: performing fine-grained analysis of texts by detecting all fragments that contain propaganda techniques as well as their type. In particular, we create a corpus of news articles manually annotated at fragment level with eighteen propaganda techniques and propose a suitable evaluation measure. We further design a novel multi-granularity neural network, and we show that it outperforms several strong BERT-based baselines.", "year": 2019, "authors": [{"authorId": "34086979", "name": "Giovanni Da San Martino"}, {"authorId": "1885974", "name": "Seunghak Yu"}, {"authorId": "1397442049", "name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"authorId": "2065869784", "name": "R. Petrov"}, {"authorId": "1683562", "name": "Preslav Nakov"}], "cluster": 15, "position": {"x": 12.374465942382812, "y": -38.46517562866211}}, {"paperId": "c0a2ee56fc80d971e920fba6179f81b515533592", "url": "https://www.semanticscholar.org/paper/c0a2ee56fc80d971e920fba6179f81b515533592", "title": "Historical Change in the Moral Foundations of Political Persuasion", "abstract": "How have attempts at political persuasion changed over time? Using nine corpora dating back through 1789, containing over 7 million words of speech (1,666 documents in total), covering three different countries, plus the entire Google nGram corpus, we find that language relating to togetherness permanently crowded out language relating to duties and obligations in the persuasive speeches of politicians during the early 20th century. This shift is temporally predicted by a rise in Western nationalism and the mass movement of people from more rural to more urban areas and is unexplained by changes in language, private political speech, or nonmoral persuasion. We theorize that the emergence of the modern state in the 1920s had psychopolitical consequences for the ways that people understood and communicated their relationships with their government, which was then reflected in the levers of persuasion chosen by political elites.", "year": 2020, "authors": [{"authorId": "51217405", "name": "N. Buttrick"}, {"authorId": "145855924", "name": "R. Moulder"}, {"authorId": "33364770", "name": "S. Oishi"}], "cluster": 18, "position": {"x": 10.01955509185791, "y": -3.3419411182403564}}, {"paperId": "7de1c0db3b3848d1a51dbfefce8b73e89a682177", "url": "https://www.semanticscholar.org/paper/7de1c0db3b3848d1a51dbfefce8b73e89a682177", "title": "Classification of Moral Foundations in Microblog Political Discourse", "abstract": "Previous works in computer science, as well as political and social science, have shown correlation in text between political ideologies and the moral foundations expressed within that text. Additional work has shown that policy frames, which are used by politicians to bias the public towards their stance on an issue, are also correlated with political ideology. Based on these associations, this work takes a first step towards modeling both the language and how politicians frame issues on Twitter, in order to predict the moral foundations that are used by politicians to express their stances on issues. The contributions of this work includes a dataset annotated for the moral foundations, annotation guidelines, and probabilistic graphical models which show the usefulness of jointly modeling abstract political slogans, as opposed to the unigrams of previous works, with policy frames for the prediction of the morality underlying political tweets.", "year": 2018, "authors": [{"authorId": "49808204", "name": "Kristen Marie Johnson"}, {"authorId": "2877164", "name": "Dan Goldwasser"}], "cluster": 18, "position": {"x": 9.634902000427246, "y": -5.259972095489502}}, {"paperId": "c0472b63d7d45d948dea42c4b5efffb6859541f9", "url": "https://www.semanticscholar.org/paper/c0472b63d7d45d948dea42c4b5efffb6859541f9", "title": "Technology, Autonomy, and Manipulation", "abstract": "Since 2016, when the Facebook/Cambridge Analytica scandal began to emerge, public concern has grown around the threat of \u201conline manipulation\u201d. While these worries are familiar to privacy researchers, this paper aims to make them more salient to policymakers \u2014 first, by defining \u201conline manipulation\u201d, thus enabling identification of manipulative practices; and second, by drawing attention to the specific harms online manipulation threatens. We argue that online manipulation is the use of information technology to covertly influence another person\u2019s decision-making, by targeting and exploiting their decision-making vulnerabilities. Engaging in such practices can harm individuals by diminishing their economic interests, but its deeper, more insidious harm is its challenge to individual autonomy. We explore this autonomy harm, emphasising its implications for both individuals and society, and we briefly outline some strategies for combating online manipulation and strengthening autonomy in an increasingly digital world.", "year": 2019, "authors": [{"authorId": "2585895", "name": "Daniel Susser"}, {"authorId": "33174950", "name": "B. Roessler"}, {"authorId": "2994505", "name": "H. Nissenbaum"}], "cluster": 3, "position": {"x": 39.06345748901367, "y": 22.914100646972656}}, {"paperId": "d89e89eac7882790b48ad73376742e7a93fea4fd", "url": "https://www.semanticscholar.org/paper/d89e89eac7882790b48ad73376742e7a93fea4fd", "title": "Red Bots Do It Better:Comparative Analysis of Social Bot Partisan Behavior", "abstract": "Recent research brought awareness of the issue of bots on social media and the significant risks of mass manipulation of public opinion in the context of political discussion. In this work, we leverage Twitter to study the discourse during the 2018 US midterm elections and analyze social bot activity and interactions with humans. We collected 2.6 million tweets for 42 days around the election day from nearly 1 million users. We use the collected tweets to answer three research questions: (i) Do social bots lean and behave according to a political ideology? (ii) Can we observe different strategies among liberal and conservative bots? (iii) How effective are bot strategies in engaging humans? We show that social bots can be accurately classified according to their political leaning and behave accordingly. Conservative bots share most of the topics of discussion with their human counterparts, while liberal bots show less overlap and a more inflammatory attitude. We studied bot interactions with humans and observed different strategies. Finally, we measured bots embeddedness in the social network and the extent of human engagement with each group of bots. Results show that conservative bots are more deeply embedded in the social network and more effective than liberal bots at exerting influence on humans.", "year": 2019, "authors": [{"authorId": "3349623", "name": "Luca Luceri"}, {"authorId": "144003355", "name": "A. Deb"}, {"authorId": "9552744", "name": "Adam Badawy"}, {"authorId": "2082804692", "name": "Emilio Ferrara"}], "cluster": 23, "position": {"x": -5.459749698638916, "y": -7.546175479888916}}, {"paperId": "16981cc4ddefd3ea7655754fd83a2a8ff2203a8b", "url": "https://www.semanticscholar.org/paper/16981cc4ddefd3ea7655754fd83a2a8ff2203a8b", "title": "Automatically Neutralizing Subjective Bias in Text", "abstract": "Texts like news, encyclopedias, and some social media strive for objectivity. Yet bias in the form of inappropriate subjectivity - introducing attitudes via framing, presupposing truth, and casting doubt - remains ubiquitous. This kind of bias erodes our collective trust and fuels social conflict. To address this issue, we introduce a novel testbed for natural language generation: automatically bringing inappropriately subjective text into a neutral point of view (\"neutralizing\" biased text). We also offer the first parallel corpus of biased language. The corpus contains 180,000 sentence pairs and originates from Wikipedia edits that removed various framings, presuppositions, and attitudes from biased sentences. Last, we propose two strong encoder-decoder baselines for the task. A straightforward yet opaque CONCURRENT system uses a BERT encoder to identify subjective words as part of the generation process. An interpretable and controllable MODULAR algorithm separates these steps, using (1) a BERT-based classifier to identify problematic words and (2) a novel join embedding through which the classifier can edit the hidden states of the encoder. Large-scale human evaluation across four domains (encyclopedias, news headlines, books, and political speeches) suggests that these algorithms are a first step towards the automatic identification and reduction of bias.", "year": 2020, "authors": [{"authorId": "4099006", "name": "Reid Pryzant"}, {"authorId": "144584594", "name": "Richard Diehl Martinez"}, {"authorId": "40556444", "name": "Nathan Dass"}, {"authorId": "1795664", "name": "S. Kurohashi"}, {"authorId": "1746807", "name": "Dan Jurafsky"}, {"authorId": "2022168", "name": "Diyi Yang"}], "cluster": 16, "position": {"x": 3.23270583152771, "y": 10.24474811553955}}, {"paperId": "9e82aba279807a6c8541c8811f049a40ebca36c1", "url": "https://www.semanticscholar.org/paper/9e82aba279807a6c8541c8811f049a40ebca36c1", "title": "Issue Framing in Online Discussion Fora", "abstract": "In online discussion fora, speakers often make arguments for or against something, say birth control, by highlighting certain aspects of the topic. In social science, this is referred to as issue framing. In this paper, we introduce a new issue frame annotated corpus of online discussions. We explore to what extent models trained to detect issue frames in newswire and social media can be transferred to the domain of discussion fora, using a combination of multi-task and adversarial training, assuming only unlabeled training data in the target domain.", "year": 2019, "authors": [{"authorId": "34604611", "name": "Mareike Hartmann"}, {"authorId": "93663917", "name": "Tallulah Jansen"}, {"authorId": "1736067", "name": "Isabelle Augenstein"}, {"authorId": "1700187", "name": "Anders S\u00f8gaard"}], "cluster": 19, "position": {"x": 20.544818878173828, "y": -18.20265769958496}}, {"paperId": "15130cdd46ff7e3a69384e6c62ab1775c4aba96f", "url": "https://www.semanticscholar.org/paper/15130cdd46ff7e3a69384e6c62ab1775c4aba96f", "title": "Analyzing Framing through the Casts of Characters in the News", "abstract": "We present an unsupervised model for the discovery and clustering of latent \u201cpersonas\u201d (characterizations of entities). Our model simultaneously clusters documents featuring similar collections of personas. We evaluate this model on a collection of news articles about immigration, showing that personas help predict the coarse-grained framing annotations in the Media Frames Corpus. We also introduce automated model selection as a fair and robust form of feature evaluation.", "year": 2016, "authors": [{"authorId": "35540755", "name": "D. Card"}, {"authorId": "2603663", "name": "J. Gross"}, {"authorId": "2641095", "name": "Amber E. Boydstun"}, {"authorId": "144365875", "name": "Noah A. Smith"}], "cluster": 19, "position": {"x": 19.74046516418457, "y": -14.218762397766113}}, {"paperId": "a0a5669b310ceb3840a599bf4f27a077a643d613", "url": "https://www.semanticscholar.org/paper/a0a5669b310ceb3840a599bf4f27a077a643d613", "title": "A Systematic Media Frame Analysis of 1.5 Million New York Times Articles from 2000 to 2017", "abstract": "Framing is an indispensable narrative device for news media because even the same facts may lead to conflicting understandings if deliberate framing is employed. Therefore, identifying media framing is a crucial step to understanding how news media influence the public. Framing is, however, difficult to operationalize and detect, and thus traditional media framing studies had to rely on manual annotation, which is challenging to scale up to massive news datasets. Here, by developing a media frame classifier that achieves state-of-the-art performance, we systematically analyze the media frames of 1.5 million New York Times articles published from 2000 to 2017. By examining the ebb and flow of media frames over almost two decades, we show that short-term frame abundance fluctuation closely corresponds to major events, while there also exist several long-term trends, such as the gradually increasing prevalence of the \u201cCultural identity\u201d frame. By examining specific topics and sentiments, we identify characteristics and dynamics of each frame. Finally, as a case study, we delve into the framing of mass shootings, revealing three major framing patterns. Our scalable, computational approach to massive news datasets opens up new pathways for systematic media framing studies.", "year": 2020, "authors": [{"authorId": "2113451145", "name": "Haewoon Kwak"}, {"authorId": "40660541", "name": "Jisun An"}, {"authorId": "36663090", "name": "Yong-Yeol Ahn"}], "cluster": 19, "position": {"x": 17.904796600341797, "y": -13.297539710998535}}, {"paperId": "2cd74561109e2675634e0f4f0129fcfbc238a1d8", "url": "https://www.semanticscholar.org/paper/2cd74561109e2675634e0f4f0129fcfbc238a1d8", "title": "Connotation Frames of Power and Agency in Modern Films", "abstract": "The framing of an action influences how we perceive its actor. We introduce connotation frames of power and agency, a pragmatic formalism organized using frame semantic representations, to model how different levels of power and agency are implicitly projected on actors through their actions. We use the new power and agency frames to measure the subtle, but prevalent, gender bias in the portrayal of modern film characters and provide insights that deviate from the well-known Bechdel test. Our contributions include an extended lexicon of connotation frames along with a web interface that provides a comprehensive analysis through the lens of connotation frames.", "year": 2017, "authors": [{"authorId": "2729164", "name": "Maarten Sap"}, {"authorId": "24851412", "name": "Marcella Cindy Prasettio"}, {"authorId": "14487640", "name": "Ari Holtzman"}, {"authorId": "2516777", "name": "Hannah Rashkin"}, {"authorId": "1699545", "name": "Yejin Choi"}], "cluster": 19, "position": {"x": 20.4084415435791, "y": -8.536280632019043}}, {"paperId": "245bcbdfff19721c226059a5d5b1ae71b67e0572", "url": "https://www.semanticscholar.org/paper/245bcbdfff19721c226059a5d5b1ae71b67e0572", "title": "FrameAxis: Characterizing Framing Bias and Intensity with Word Embedding", "abstract": "We propose FrameAxis, a method of characterizing the framing of a given text by identifying the most relevant semantic axes (\"microframes\") defined by antonym word pairs. In contrast to the traditional framing analysis, which has been constrained by a small number of manually annotated general frames, our unsupervised approach provides much more detailed insights, by considering a host of semantic axes. Our method is capable of quantitatively teasing out framing bias -- how biased a text is in each microframe -- and framing intensity -- how much each microframe is used -- from the text, offering a nuanced characterization of framing. We evaluate our approach using SemEval datasets as well as three other datasets and human evaluations, demonstrating that FrameAxis can reliably characterize documents with relevant microframes. Our method may allow scalable and nuanced computational analyses of framing across disciplines.", "year": 2020, "authors": [{"authorId": "2113451145", "name": "Haewoon Kwak"}, {"authorId": "40660541", "name": "Jisun An"}, {"authorId": "36663090", "name": "Yong-Yeol Ahn"}], "cluster": 19, "position": {"x": 17.359039306640625, "y": -16.685237884521484}}, {"paperId": "20a37289d0b7c90065850eb7bf96d5ac3c8a21e4", "url": "https://www.semanticscholar.org/paper/20a37289d0b7c90065850eb7bf96d5ac3c8a21e4", "title": "Modeling Frames in Argumentation", "abstract": "In argumentation, framing is used to emphasize a specific aspect of a controversial topic while concealing others. When talking about legalizing drugs, for instance, its economical aspect may be emphasized. In general, we call a set of arguments that focus on the same aspect a frame. An argumentative text has to serve the \u201cright\u201d frame(s) to convince the audience to adopt the author\u2019s stance (e.g., being pro or con legalizing drugs). More specifically, an author has to choose frames that fit the audience\u2019s cultural background and interests. This paper introduces frame identification, which is the task of splitting a set of arguments into non-overlapping frames. We present a fully unsupervised approach to this task, which first removes topical information and then identifies frames using clustering. For evaluation purposes, we provide a corpus with 12, 326 debate-portal arguments, organized along the frames of the debates\u2019 topics. On this corpus, our approach outperforms different strong baselines, achieving an F1-score of 0.28.", "year": 2019, "authors": [{"authorId": "22312473", "name": "Yamen Ajjour"}, {"authorId": "2300829", "name": "Milad Alshomary"}, {"authorId": "2626599", "name": "Henning Wachsmuth"}, {"authorId": "144146081", "name": "Benno Stein"}], "cluster": 19, "position": {"x": 19.74955177307129, "y": -17.061931610107422}}, {"paperId": "c899c6048a1bd99590972c5fb2f9fd00db8d4e18", "url": "https://www.semanticscholar.org/paper/c899c6048a1bd99590972c5fb2f9fd00db8d4e18", "title": "Who Falls for Online Political Manipulation?", "abstract": "Social media, once hailed as a vehicle for democratization and the promotion of positive social change across the globe, are under attack for becoming a tool of political manipulation and spread of disinformation. A case in point is the alleged use of trolls by Russia to spread malicious content in Western elections. This paper examines the Russian interference campaign in the 2016 US presidential election on Twitter. Our aim is twofold: first, we test whether predicting users who spread trolls\u2019 content is feasible in order to gain insight on how to contain their influence in the future; second, we identify features that are most predictive of users who either intentionally or unintentionally play a vital role in spreading this malicious content. We collected a dataset with over 43 million election-related posts shared on Twitter between September 16 and November 9, 2016, by about 5.7 million users. This dataset includes accounts associated with the Russian trolls identified by the US Congress. Proposed models are able to very accurately identify users who spread the trolls\u2019 content (average AUC score of 96%, using 10-fold validation). We show that political ideology, bot likelihood scores, and some activity-related account meta data are the most predictive features of whether a user spreads trolls\u2019 content or not.", "year": 2019, "authors": [{"authorId": "9552744", "name": "Adam Badawy"}, {"authorId": "1782658", "name": "Kristina Lerman"}, {"authorId": "48898287", "name": "Emilio Ferrara"}], "cluster": 23, "position": {"x": -6.957888126373291, "y": -7.4582839012146}}, {"paperId": "92408cc19033cc4af29accef3793014ab79355c2", "url": "https://www.semanticscholar.org/paper/92408cc19033cc4af29accef3793014ab79355c2", "title": "The Media Frames Corpus: Annotations of Frames Across Issues", "abstract": "We describe the first version of the Media Frames Corpus: several thousand news articles on three policy issues, annotated in terms of media framing. We motivate framing as a phenomenon of study for computational linguistics and describe our annotation process.", "year": 2015, "authors": [{"authorId": "35540755", "name": "D. Card"}, {"authorId": "2641095", "name": "Amber E. Boydstun"}, {"authorId": "2603663", "name": "J. Gross"}, {"authorId": "1680292", "name": "P. Resnik"}, {"authorId": "144365875", "name": "Noah A. Smith"}], "cluster": 19, "position": {"x": 18.248794555664062, "y": -14.761427879333496}}, {"paperId": "1778d1da6264ed4274fb94115ebbc3b4f34c9f7a", "url": "https://www.semanticscholar.org/paper/1778d1da6264ed4274fb94115ebbc3b4f34c9f7a", "title": "Misinfo Belief Frames: A Case Study on Covid & Climate News", "abstract": "Prior beliefs of readers impact the way in which they project meaning onto news headlines. These beliefs can influence their perception of news reliability, as well as their reaction to news, and their likelihood of spreading the misinformation through social networks. However, most prior work focuses on fact-checking veracity of news or stylometry rather than measuring impact of misinformation. We propose Misinfo Belief Frames, a formalism for understanding how readers perceive the reliability of news and the impact of misinformation. We also introduce the Misinfo Belief Frames (MBF) corpus, a dataset of 66k inferences over 23.5k headlines. Misinformation frames use commonsense reasoning to uncover implications of real and fake news headlines focused on global crises: the Covid-19 pandemic and climate change. Our results using large-scale language modeling to predict misinformation frames show that machine-generated inferences can influence readers\u2019 trust in news headlines (readers\u2019 trust in news headlines was affected in 29.3% of cases). This demonstrates the potential effectiveness of using generated frames to counter misinformation.", "year": 2021, "authors": [{"authorId": "119902504", "name": "Saadia Gabriel"}, {"authorId": "1474550731", "name": "Skyler Hallinan"}, {"authorId": "2729164", "name": "Maarten Sap"}, {"authorId": "2078508715", "name": "Pemi Nguyen"}, {"authorId": "3268360", "name": "Franziska Roesner"}, {"authorId": "2890423", "name": "Eunsol Choi"}, {"authorId": "2111165011", "name": "Yejin Choi"}], "cluster": 21, "position": {"x": -0.12540866434574127, "y": -22.43503761291504}}, {"paperId": "9129399d6b1599508709e3a72f80defd52ef89c9", "url": "https://www.semanticscholar.org/paper/9129399d6b1599508709e3a72f80defd52ef89c9", "title": "The online competition between pro- and anti-vaccination views", "abstract": "Distrust in scientific expertise 1 \u2013 14 is dangerous. Opposition to vaccination with a future vaccine against SARS-CoV-2, the causal agent of COVID-19, for example, could amplify outbreaks 2 \u2013 4 , as happened for measles in 2019 5 , 6 . Homemade remedies 7 , 8 and falsehoods are being shared widely on the Internet, as well as dismissals of expert advice 9 \u2013 11 . There is a lack of understanding about how this distrust evolves at the system level 13 , 14 . Here we provide a map of the contention surrounding vaccines that has emerged from the global pool of around three billion Facebook users. Its core reveals a multi-sided landscape of unprecedented intricacy that involves nearly 100\u00a0million individuals partitioned into highly dynamic, interconnected clusters across cities, countries, continents and languages. Although smaller in overall size, anti-vaccination clusters manage to become highly entangled with undecided clusters in the main online network, whereas pro-vaccination clusters are more peripheral. Our theoretical framework reproduces the recent explosive growth in anti-vaccination views, and predicts that these views will dominate in a decade. Insights provided by this framework can inform new policies and approaches to interrupt this shift to negative views. Our results challenge the conventional thinking about undecided individuals in issues of contention surrounding health, shed light on other issues of contention such as climate change 11 , and highlight the key role of network cluster dynamics in multi-species ecologies 15 . Insights into the interactions between pro- and anti-vaccination clusters on Facebook can enable policies and approaches that attempt to interrupt the shift to anti-vaccination views and persuade undecided individuals to adopt a pro-vaccination stance.", "year": 2020, "authors": [{"authorId": "2069626187", "name": "N. Johnson"}, {"authorId": "143618115", "name": "N. Vel\u00e1squez"}, {"authorId": "1695773203", "name": "N. J. Restrepo"}, {"authorId": "152152429", "name": "R. Leahy"}, {"authorId": "1720776022", "name": "N. Gabriel"}, {"authorId": "1695503420", "name": "Sara El Oud"}, {"authorId": "37987273", "name": "M. Zheng"}, {"authorId": "1971592", "name": "P. Manrique"}, {"authorId": "3160568", "name": "S. Wuchty"}, {"authorId": "51169219", "name": "Y. Lupu"}], "cluster": -1, "position": {"x": -2.612794876098633, "y": -12.349417686462402}}, {"paperId": "2a501b074261e81b9126e80a0a308cfa5e76f8c1", "url": "https://www.semanticscholar.org/paper/2a501b074261e81b9126e80a0a308cfa5e76f8c1", "title": "Linguistic Models for Analyzing and Detecting Biased Language", "abstract": "Unbiased language is a requirement for reference sources like encyclopedias and scientific texts. Bias is, nonetheless, ubiquitous, making it crucial to understand its nature and linguistic realization and hence detect bias automatically. To this end we analyze real instances of human edits designed to remove bias from Wikipedia articles. The analysis uncovers two classes of bias: framing bias, such as praising or perspective-specific words, which we link to the literature on subjectivity; and epistemological bias, related to whether propositions that are presupposed or entailed in the text are uncontroversially accepted as true. We identify common linguistic cues for these classes, including factive verbs, implicatives, hedges, and subjective intensifiers. These insights help us develop features for a model to solve a new prediction task of practical importance: given a biased sentence, identify the bias-inducing word. Our linguistically-informed model performs almost as well as humans tested on the same task.", "year": 2013, "authors": [{"authorId": "144409897", "name": "Marta Recasens"}, {"authorId": "1388368997", "name": "Cristian Danescu-Niculescu-Mizil"}, {"authorId": "1746807", "name": "Dan Jurafsky"}], "cluster": -1, "position": {"x": 2.4573354721069336, "y": 10.54664421081543}}, {"paperId": "ed1c17451a23471afde91c109ecadc6aab8b2ba6", "url": "https://www.semanticscholar.org/paper/ed1c17451a23471afde91c109ecadc6aab8b2ba6", "title": "A Survey on Multimodal Disinformation Detection", "abstract": "Recent years have witnessed the proliferation of fake news, propaganda, misinformation, and disinformation online. While initially this was mostly about textual content, over time images and videos gained popularity, as they are much easier to consume, attract much more attention, and spread further than simple text. As a result, researchers started targeting different modalities and combinations thereof. As different modalities are studied in different research communities, with insufficient interaction, here we offer a survey that explores the state-of-the-art on multimodal disinformation detection covering various combinations of modalities: text, images, audio, video, network structure, and temporal information. Moreover, while some studies focused on factuality, others investigated how harmful the content is. While these two components in the definition of disinformation \u2013 (i) factuality and (ii) harmfulness, are equally important, they are typically studied in isolation. Thus, we argue for the need to tackle disinformation detection by taking into account multiple modalities as well as both factuality and harmfulness, in the same framework. Finally, we discuss current challenges and future research directions.", "year": 2021, "authors": [{"authorId": "37784060", "name": "Firoj Alam"}, {"authorId": "40598011", "name": "S. Cresci"}, {"authorId": "144054829", "name": "Tanmoy Chakraborty"}, {"authorId": "144925193", "name": "F. Silvestri"}, {"authorId": "2757957", "name": "D. Dimitrov"}, {"authorId": "34086979", "name": "Giovanni Da San Martino"}, {"authorId": "65877664", "name": "Shaden Shaar"}, {"authorId": "22593971", "name": "Hamed Firooz"}, {"authorId": "2026545715", "name": "Preslav Nakov"}], "cluster": 15, "position": {"x": 10.359627723693848, "y": -35.521244049072266}}, {"paperId": "460986c12b9fdedc3bf9a710c429c5a84608055a", "url": "https://www.semanticscholar.org/paper/460986c12b9fdedc3bf9a710c429c5a84608055a", "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective and a Call to Arms", "abstract": "With the outbreak of the COVID-19 pandemic, people turned to social media to read and to share timely information including statistics, warnings, advice, and inspirational stories. Unfortunately, alongside all this useful information, there was also a new blending of medical and political misinformation and disinformation, which gave rise to the first global infodemic. While fighting this infodemic is typically thought of in terms of factuality, the problem is much broader as malicious content includes not only fake news, rumors, and conspiracy theories, but also promotion of fake cures, panic, racism, xenophobia, and mistrust in the authorities, among others. This is a complex problem that needs a holistic approach combining the perspectives of journalists, fact-checkers, policymakers, government entities, social media platforms, and society as a whole. Taking them into account we define an annotation schema and detailed annotation instructions, which reflect these perspectives. We performed initial annotations using this schema, and our initial experiments demonstrated sizable improvements over the baselines. Now, we issue a call to arms to the research community and beyond to join the fight by supporting our crowdsourcing annotation efforts.", "year": 2021, "authors": [{"authorId": "37784060", "name": "Firoj Alam"}, {"authorId": "6415321", "name": "Fahim Dalvi"}, {"authorId": "65877664", "name": "Shaden Shaar"}, {"authorId": "145938140", "name": "Nadir Durrani"}, {"authorId": "143779235", "name": "Hamdy Mubarak"}, {"authorId": "47195288", "name": "Alex Nikolov"}, {"authorId": "34086979", "name": "Giovanni Da San Martino"}, {"authorId": "1683403", "name": "Ahmed Abdelali"}, {"authorId": "50433033", "name": "Hassan Sajjad"}, {"authorId": "143758717", "name": "Kareem Darwish"}, {"authorId": "1683562", "name": "Preslav Nakov"}], "cluster": 21, "position": {"x": -1.2088439464569092, "y": -19.476993560791016}}, {"paperId": "418b9f37b07a05b38798e97f57e17a6cc1048b92", "url": "https://www.semanticscholar.org/paper/418b9f37b07a05b38798e97f57e17a6cc1048b92", "title": "You are right. I am ALARMED - But by Climate Change Counter Movement", "abstract": "The world is facing the challenge of climate crisis. Despite the consensus in scientific community about anthropogenic global warming, the web is flooded with articles spreading climate misinformation. These articles are carefully constructed by climate change counter movement (cccm) organizations to influence the narrative around climate change. We revisit the literature on climate misinformation in social sciences and repackage it to introduce in the community of NLP. Despite considerable work in detection of fake news, there is no misinformation dataset available that is specific to the domain.of climate change. We try to bridge this gap by scraping and releasing articles with known climate change misinformation.", "year": 2020, "authors": [{"authorId": "1984990", "name": "Shraey Bhatia"}, {"authorId": "1800564", "name": "Jey Han Lau"}, {"authorId": "145465286", "name": "Timothy Baldwin"}], "cluster": 12, "position": {"x": -29.163204193115234, "y": -36.33010482788086}}, {"paperId": "38d243b9f6e2c786699dbc83513fb190372cde07", "url": "https://www.semanticscholar.org/paper/38d243b9f6e2c786699dbc83513fb190372cde07", "title": "Automated Fact-Checking for Assisting Human Fact-Checkers", "abstract": "The reporting and analysis of current events around the globe has expanded from professional, editorlead journalism all the way to citizen journalism. Politicians and other key players enjoy direct access to their audiences through social media, bypassing the filters of official cables or traditional media. However, the multiple advantages of free speech and direct communication are dimmed by the misuse of the media to spread inaccurate or misleading claims. These phenomena have led to the modern incarnation of the fact-checker \u2014 a professional whose main aim is to examine claims using available evidence to assess their veracity. As in other text forensics tasks, the amount of information available makes the work of the fact-checker more difficult. With this in mind, starting from the perspective of the professional fact-checker, we survey the available intelligent technologies that can support the human expert in the different steps of her fact-checking endeavor. These include identifying claims worth fact-checking; detecting relevant previously fact-checked claims; retrieving relevant evidence to fact-check a claim; and actually verifying a claim. In each case, we pay attention to the challenges in future work and the potential impact on real-world fact-checking.", "year": 2021, "authors": [{"authorId": "2026545715", "name": "Preslav Nakov"}, {"authorId": "1801487", "name": "D. Corney"}, {"authorId": "2905745", "name": "Maram Hasanain"}, {"authorId": "37784060", "name": "Firoj Alam"}, {"authorId": "1693370300", "name": "Tamer Elsayed"}, {"authorId": "2063950160", "name": "A. Barr'on-Cedeno"}, {"authorId": "1802817", "name": "Paolo Papotti"}, {"authorId": "65877664", "name": "Shaden Shaar"}, {"authorId": "34086979", "name": "Giovanni Da San Martino"}], "cluster": 15, "position": {"x": 1.833479642868042, "y": -40.63487243652344}}, {"paperId": "1dad69f1fd4403aed4d3d709ab794113291d625c", "url": "https://www.semanticscholar.org/paper/1dad69f1fd4403aed4d3d709ab794113291d625c", "title": "Fake News: Spread of Misinformation about Urological Conditions on Social Media.", "abstract": "Although there is a large amount of user-generated content about urological health issues on social media, much of this content has not been vetted for information accuracy. In this article, we review the literature on the quality and balance of information on urological health conditions on social networks. Across a wide range of benign and malignant urological conditions, studies show a substantial amount of commercial, biased and/or inaccurate information present on popular social networking sites. The healthcare community should take proactive steps to improve the quality of medical information on social networks. PATIENT SUMMARY: In this review, we examined the spread of misinformation about urological health conditions on social media. We found that a significant amount of the circulating information is commercial, biased or misinformative.", "year": 2019, "authors": [{"authorId": "2235946", "name": "S. Loeb"}, {"authorId": "49187173", "name": "Jacob Taylor"}, {"authorId": "2989346", "name": "J. Borin"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}, {"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "40893848", "name": "N. Byrne"}, {"authorId": "32806077", "name": "A. Chiang"}, {"authorId": "38657671", "name": "A. Langford"}], "cluster": 21, "position": {"x": 1.3335692882537842, "y": -18.475915908813477}}, {"paperId": "76de89ca66f898e8211acba7392ef2d4a7e14125", "url": "https://www.semanticscholar.org/paper/76de89ca66f898e8211acba7392ef2d4a7e14125", "title": "Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection", "abstract": "Fake news has altered society in negative ways in politics and culture. It has adversely affected both online social network systems as well as offline communities and conversations. Using automatic machine learning classification models is an efficient way to combat the widespread dissemination of fake news. However, a lack of effective, comprehensive datasets has been a problem for fake news research and detection model development. Prior fake news datasets do not provide multimodal text and image data, metadata, comment data, and fine-grained fake news categorization at the scale and breadth of our dataset. We present Fakeddit, a novel multimodal dataset consisting of over 1 million samples from multiple categories of fake news. After being processed through several stages of review, the samples are labeled according to 2-way, 3-way, and 6-way classification categories through distant supervision. We construct hybrid text+image models and perform extensive experiments for multiple variations of classification, demonstrating the importance of the novel aspect of multimodality and fine-grained classification unique to Fakeddit.", "year": 2020, "authors": [{"authorId": "30347964", "name": "Kai Nakamura"}, {"authorId": "49285370", "name": "Sharon Levy"}, {"authorId": "1682479", "name": "William Yang Wang"}], "cluster": 15, "position": {"x": 10.180022239685059, "y": -37.28755569458008}}, {"paperId": "bc8c416f821b93795370524247c8a455c373ee6e", "url": "https://www.semanticscholar.org/paper/bc8c416f821b93795370524247c8a455c373ee6e", "title": "Fake News: A Survey of Research, Detection Methods, and Opportunities", "abstract": "The explosive growth in fake news and its erosion to democracy, justice, and public trust has increased the demand for fake news analysis, detection and intervention. This survey comprehensively and systematically reviews fake news research. The survey identifies and specifies fundamental theories across various disciplines, e.g., psychology and social science, to facilitate and enhance the interdisciplinary research of fake news. Current fake news research is reviewed, summarized and evaluated. These studies focus on fake news from four perspective: (1) the false knowledge it carries, (2) its writing style, (3) its propagation patterns, and (4) the credibility of its creators and spreaders. We characterize each perspective with various analyzable and utilizable information provided by news and its spreaders, various strategies and frameworks that are adaptable, and techniques that are applicable. By reviewing the characteristics of fake news and open issues in fake news studies, we highlight some potential research tasks at the end of this survey.", "year": 2018, "authors": [{"authorId": "47155134", "name": "Xinyi Zhou"}, {"authorId": "2281410", "name": "R. Zafarani"}], "cluster": 15, "position": {"x": 4.906987190246582, "y": -37.13057327270508}}, {"paperId": "8415274c8fb370cbab84ad82ab2f469786ddee72", "url": "https://www.semanticscholar.org/paper/8415274c8fb370cbab84ad82ab2f469786ddee72", "title": "Weaponized Health Communication: Twitter Bots and Russian Trolls Amplify the Vaccine Debate", "abstract": "Objectives To understand how Twitter bots and trolls (\u201cbots\u201d) promote online health content. Methods We compared bots\u2019 to average users\u2019 rates of vaccine-relevant messages, which we collected online from July 2014 through September 2017. We estimated the likelihood that users were bots, comparing proportions of polarized and antivaccine tweets across user types. We conducted a content analysis of a Twitter hashtag associated with Russian troll activity. Results Compared with average users, Russian trolls (\u03c72(1)\u2009=\u2009102.0; P\u2009<\u2009.001), sophisticated bots (\u03c72(1)\u2009=\u200928.6; P\u2009<\u2009.001), and \u201ccontent polluters\u201d (\u03c72(1)\u2009=\u20097.0; P\u2009<\u2009.001) tweeted about vaccination at higher rates. Whereas content polluters posted more antivaccine content (\u03c72(1)\u2009=\u200911.18; P\u2009<\u2009.001), Russian trolls amplified both sides. Unidentifiable accounts were more polarized (\u03c72(1)\u2009=\u200912.1; P\u2009<\u2009.001) and antivaccine (\u03c72(1)\u2009=\u200935.9; P\u2009<\u2009.001). Analysis of the Russian troll hashtag showed that its messages were more political and divisive. Conclusions Whereas bots that spread malware and unsolicited content disseminated antivaccine messages, Russian trolls promoted discord. Accounts masquerading as legitimate users create false equivalency, eroding public consensus on vaccination. Public Health Implications. Directly confronting vaccine skeptics enables bots to legitimize the vaccine debate. More research is needed to determine how best to combat bot-driven content.", "year": 2018, "authors": [{"authorId": "3119101", "name": "David A. Broniatowski"}, {"authorId": "26759530", "name": "A. Jamison"}, {"authorId": "2053993324", "name": "SiHua Qi"}, {"authorId": "32335850", "name": "Lulwah Alkulaib"}, {"authorId": "144799987", "name": "Tao Chen"}, {"authorId": "145583569", "name": "Adrian Benton"}, {"authorId": "144673084", "name": "S. Quinn"}, {"authorId": "1782853", "name": "Mark Dredze"}], "cluster": 24, "position": {"x": -2.2886807918548584, "y": -10.87727165222168}}, {"paperId": "1213d98f3d0a42d575bbd2c2af0309c7f76024a1", "url": "https://www.semanticscholar.org/paper/1213d98f3d0a42d575bbd2c2af0309c7f76024a1", "title": "Combating Fake News: A Survey on Identification and Mitigation Techniques", "abstract": "The proliferation of fake news on social media has opened up new directions of research for timely identification and containment of fake news, and mitigation of its widespread impact on public opinion. While much of the earlier research was focused on identification of fake news based on its contents or by exploiting users' engagements with the news on social media, there has been a rising interest in proactive intervention strategies to counter the spread of misinformation and its impact on society. In this survey, we describe the modern-day problem of fake news and, in particular, highlight the technical challenges associated with it. We discuss existing methods and techniques applicable to both identification and mitigation, with a focus on the significant advances in each method and their advantages and limitations. In addition, research has often been limited by the quality of existing datasets and their specific application contexts. To alleviate this problem, we comprehensively compile and summarize characteristic features of available datasets. Furthermore, we outline new directions of research to facilitate future development of effective and interdisciplinary solutions.", "year": 2019, "authors": [{"authorId": "2082949", "name": "Karishma Sharma"}, {"authorId": "2053324591", "name": "Feng Qian"}, {"authorId": "2116480752", "name": "He Jiang"}, {"authorId": "2820106", "name": "Natali Ruchansky"}, {"authorId": "47474380", "name": "Ming Zhang"}, {"authorId": "46400027", "name": "Y. Liu"}], "cluster": 15, "position": {"x": 6.519308090209961, "y": -37.20990753173828}}, {"paperId": "29370adbf0674ad72d5e0bcc59582c22035bd0aa", "url": "https://www.semanticscholar.org/paper/29370adbf0674ad72d5e0bcc59582c22035bd0aa", "title": "Coronavirus on Social Media: Analyzing Misinformation in Twitter Conversations", "abstract": "The ongoing Coronavirus Disease (COVID-19) pandemic highlights the interconnected-ness of our present-day globalized world. With social distancing policies in place, virtual communication has become an important source of (mis)information. As increasing number of people rely on social media platforms for news, identifying misinformation has emerged as a critical task in these unprecedented times. In addition to being malicious, the spread of such information poses a serious public health risk. To this end, we design a dashboard to track misinformation on popular social media news sharing platform - Twitter. Our dashboard allows visibility into the social media discussions around Coronavirus and the quality of information shared on the platform as the situation evolves. We collect streaming data using the Twitter API from March 1, 2020 to date and provide analysis of topic clusters and social sentiments related to important emerging policies such as \"#socialdistancing\" and \"#workfromhome\". We track emerging hashtags over time, and provide location and time sensitive analysis of sentiments. In addition, we study the challenging problem of misinformation on social media, and provide a detection method to identify false, misleading and clickbait contents from Twitter information cascades. The dashboard maintains an evolving list of detected misinformation cascades with the corresponding detection scores, accessible online athttps://ksharmar.this http URL.", "year": 2020, "authors": [{"authorId": "2082949", "name": "Karishma Sharma"}, {"authorId": "145260557", "name": "Sungyong Seo"}, {"authorId": "27737939", "name": "Chuizheng Meng"}, {"authorId": "2267664", "name": "Sirisha Rambhatla"}, {"authorId": "146055386", "name": "Aastha Dua"}, {"authorId": "1947397", "name": "Y. Liu"}], "cluster": 21, "position": {"x": -0.3439689576625824, "y": -19.94161033630371}}, {"paperId": "c6a9ca56c93323c0199dd22631d1cf731bdd7ec1", "url": "https://www.semanticscholar.org/paper/c6a9ca56c93323c0199dd22631d1cf731bdd7ec1", "title": "Automatic Detection of Fake News", "abstract": "The proliferation of misleading information in everyday access media outlets such as social media feeds, news blogs, and online newspapers have made it challenging to identify trustworthy news sources, thus increasing the need for computational tools able to provide insights into the reliability of online content. In this paper, we focus on the automatic identification of fake content in online news. Our contribution is twofold. First, we introduce two novel datasets for the task of fake news detection, covering seven different news domains. We describe the collection, annotation, and validation process in detail and present several exploratory analyses on the identification of linguistic differences in fake and legitimate news content. Second, we conduct a set of learning experiments to build accurate fake news detectors, and show that we can achieve accuracies of up to 76%. In addition, we provide comparative analyses of the automatic and manual identification of fake news.", "year": 2018, "authors": [{"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "6032930", "name": "Bennett Kleinberg"}, {"authorId": "32809241", "name": "Alexandra Lefevre"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}], "cluster": 15, "position": {"x": 8.314414024353027, "y": -38.83345031738281}}, {"paperId": "44ecb9783e43d726fc87b7ffdd580b01e13a85cb", "url": "https://www.semanticscholar.org/paper/44ecb9783e43d726fc87b7ffdd580b01e13a85cb", "title": "Rumors, False Flags, and Digital Vigilantes: Misinformation on Twitter after the 2013 Boston Marathon Bombing", "abstract": "The Boston Marathon bombing story unfolded on every possible carrier of information available in the spring of 2013, including Twitter. As information spread, it was filled with rumors (unsubstantiated information), and many of these rumors contained misinformation. Earlier studies have suggested that crowdsourced information flows can correct misinformation, and our research investigates this proposition. This exploratory research examines three rumors, later demonstrated to be false, that circulated on Twitter in the aftermath of the bombings. Our findings suggest that corrections to the misinformation emerge but are muted compared with the propagation of the misinformation. The similarities and differences we observe in the patterns of the misinformation and corrections contained within the stream over the days that followed the attacks suggest directions for possible research strategies to automatically detect misinformation.", "year": 2014, "authors": [{"authorId": "3181624", "name": "Kate Starbird"}, {"authorId": "3330847", "name": "Jim Maddock"}, {"authorId": "2751519", "name": "M. Orand"}, {"authorId": "72318911", "name": "Peg Achterman"}, {"authorId": "35236169", "name": "R. Mason"}], "cluster": 22, "position": {"x": 0.9336422681808472, "y": -26.146183013916016}}, {"paperId": "69116800a8a8195531d29c8e14cefb1c92cbb8a7", "url": "https://www.semanticscholar.org/paper/69116800a8a8195531d29c8e14cefb1c92cbb8a7", "title": "Extractive and Abstractive Explanations for Fact-Checking and Evaluation of News", "abstract": "In this paper, we explore the construction of natural language explanations for news claims, with the goal of assisting fact-checking and news evaluation applications. We experiment with two methods: (1) an extractive method based on Biased TextRank \u2013 a resource-effective unsupervised graph-based algorithm for content extraction; and (2) an abstractive method based on the GPT-2 language model. We perform comparative evaluations on two misinformation datasets in the political and health news domains, and find that the extractive method shows the most promise.", "year": 2021, "authors": [{"authorId": "1721683964", "name": "Ashkan Kazemi"}, {"authorId": "2109964406", "name": "Zehua Li"}, {"authorId": "1396239754", "name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"authorId": "2105984203", "name": "Rada Mihalcea"}], "cluster": 15, "position": {"x": 2.882227659225464, "y": -47.0319938659668}}, {"paperId": "a1e58f89f57f57fad3c77cd558444ad5ad64b525", "url": "https://www.semanticscholar.org/paper/a1e58f89f57f57fad3c77cd558444ad5ad64b525", "title": "The spread of true and false news online", "abstract": "Lies spread faster than the truth There is worldwide concern over false news and the possibility that it can influence political, economic, and social well-being. To understand how false news spreads, Vosoughi et al. used a data set of rumor cascades on Twitter from 2006 to 2017. About 126,000 rumors were spread by \u223c3 million people. False news reached more people than the truth; the top 1% of false news cascades diffused to between 1000 and 100,000 people, whereas the truth rarely diffused to more than 1000 people. Falsehood also diffused faster than the truth. The degree of novelty and the emotional reactions of recipients may be responsible for the differences observed. Science, this issue p. 1146 A large-scale analysis of tweets reveals that false rumors spread further and faster than the truth. We investigated the differential diffusion of all of the verified true and false news stories distributed on Twitter from 2006 to 2017. The data comprise ~126,000 stories tweeted by ~3 million people more than 4.5 million times. We classified news as true or false using information from six independent fact-checking organizations that exhibited 95 to 98% agreement on the classifications. Falsehood diffused significantly farther, faster, deeper, and more broadly than the truth in all categories of information, and the effects were more pronounced for false political news than for false news about terrorism, natural disasters, science, urban legends, or financial information. We found that false news was more novel than true news, which suggests that people were more likely to share novel information. Whereas false stories inspired fear, disgust, and surprise in replies, true stories inspired anticipation, sadness, joy, and trust. Contrary to conventional wisdom, robots accelerated the spread of true and false news at the same rate, implying that false news spreads more than the truth because humans, not robots, are more likely to spread it.", "year": 2018, "authors": [{"authorId": "1918441", "name": "Soroush Vosoughi"}, {"authorId": "145364504", "name": "D. Roy"}, {"authorId": "2413779", "name": "Sinan Aral"}], "cluster": 22, "position": {"x": 1.117970585823059, "y": -27.33690071105957}}, {"paperId": "6f78b5608fed43f106da192f12e09d9edbd2fce0", "url": "https://www.semanticscholar.org/paper/6f78b5608fed43f106da192f12e09d9edbd2fce0", "title": "Social Media and Fake News in the 2016 Election", "abstract": "Following the 2016 U.S. presidential election, many have expressed concern about the effects of false stories (\u201cfake news\u201d), circulated largely through social media. We discuss the economics of fake news and present new data on its consumption prior to the election. Drawing on web browsing data, archives of fact-checking websites, and results from a new online survey, we find: (i) social media was an important but not dominant source of election news, with 14 percent of Americans calling social media their \u201cmost important\u201d source; (ii) of the known false news stories that appeared in the three months before the election, those favoring Trump were shared a total of 30 million times on Facebook, while those favoring Clinton were shared 8 million times; (iii) the average American adult saw on the order of one or perhaps several fake news stories in the months around the election, with just over half of those who recalled seeing them believing them; and (iv) people are much more likely to believe stories that favor their preferred candidate, especially if they have ideologically segregated social media networks.", "year": 2017, "authors": [{"authorId": "6112526", "name": "H. Allcott"}, {"authorId": "8731644", "name": "Matthew Gentzkow"}], "cluster": 22, "position": {"x": 2.0764567852020264, "y": -28.851587295532227}}, {"paperId": "03c294ad75bd1bac92217419ac25358227f6a901", "url": "https://www.semanticscholar.org/paper/03c294ad75bd1bac92217419ac25358227f6a901", "title": "\"Liar, Liar Pants on Fire\": A New Benchmark Dataset for Fake News Detection", "abstract": "Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present liar: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from PolitiFact.com, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate meta-data with text. We show that this hybrid approach can improve a text-only deep learning model.", "year": 2017, "authors": [{"authorId": "1682479", "name": "William Yang Wang"}], "cluster": 15, "position": {"x": 8.706587791442871, "y": -40.03666305541992}}, {"paperId": "20b2f18aaf10a9221c5edf3720d4cce7da672104", "url": "https://www.semanticscholar.org/paper/20b2f18aaf10a9221c5edf3720d4cce7da672104", "title": "That is a Known Lie: Detecting Previously Fact-Checked Claims", "abstract": "The recent proliferation of \u201dfake news\u201d has triggered a number of responses, most notably the emergence of several manual fact-checking initiatives. As a result and over time, a large number of fact-checked claims have been accumulated, which increases the likelihood that a new claim in social media or a new statement by a politician might have already been fact-checked by some trusted fact-checking organization, as viral claims often come back after a while in social media, and politicians like to repeat their favorite statements, true or false, over and over again. As manual fact-checking is very time-consuming (and fully automatic fact-checking has credibility issues), it is important to try to save this effort and to avoid wasting time on claims that have already been fact-checked. Interestingly, despite the importance of the task, it has been largely ignored by the research community so far. Here, we aim to bridge this gap. In particular, we formulate the task and we discuss how it relates to, but also differs from, previous work. We further create a specialized dataset, which we release to the research community. Finally, we present learning-to-rank experiments that demonstrate sizable improvements over state-of-the-art retrieval and textual similarity approaches.", "year": 2020, "authors": [{"authorId": "65877664", "name": "Shaden Shaar"}, {"authorId": "34086979", "name": "Giovanni Da San Martino"}, {"authorId": "1693976811", "name": "Nikolay Babulkov"}, {"authorId": "1683562", "name": "Preslav Nakov"}], "cluster": 15, "position": {"x": 6.513463020324707, "y": -42.98264694213867}}, {"paperId": "7d3c2ff37d04914836f9cbd9ce54b6c97aa74a22", "url": "https://www.semanticscholar.org/paper/7d3c2ff37d04914836f9cbd9ce54b6c97aa74a22", "title": "Truth of Varying Shades: Analyzing Language in Fake News and Political Fact-Checking", "abstract": "We present an analytic study on the language of news media in the context of political fact-checking and fake news detection. We compare the language of real news with that of satire, hoaxes, and propaganda to find linguistic characteristics of untrustworthy text. To probe the feasibility of automatic political fact-checking, we also present a case study based on PolitiFact.com using their factuality judgments on a 6-point scale. Experiments show that while media fact-checking remains to be an open research question, stylistic cues can help determine the truthfulness of text.", "year": 2017, "authors": [{"authorId": "2516777", "name": "Hannah Rashkin"}, {"authorId": "2890423", "name": "Eunsol Choi"}, {"authorId": "1835709", "name": "J. Jang"}, {"authorId": "143683394", "name": "Svitlana Volkova"}, {"authorId": "1699545", "name": "Yejin Choi"}], "cluster": 15, "position": {"x": 3.592846632003784, "y": -38.66729736328125}}, {"paperId": "1e3d1055fc65966bc2c64505785207d7e8d71022", "url": "https://www.semanticscholar.org/paper/1e3d1055fc65966bc2c64505785207d7e8d71022", "title": "Rumor Cascades", "abstract": "Online social networks provide a rich substrate for rumor propagation. Information received via friends tends to be trusted, and online social networks allow individuals to transmit information to many friends at once. By referencing known rumors from Snopes.com, a popular website documenting memes and urban legends, we track the propagation of thousands of rumors appearing on Facebook. From this sample we infer the rates at which rumors from different categories and of varying truth value are uploaded and reshared. We find that rumor cascades run deeper in the social network than reshare cascades in general. We then examine the effect of individual reshares receiving a comment containing a link to a Snopes article on the evolution of the cascade. We find that receiving such a comment increases the likelihood that a reshare of a rumor will be deleted. Furthermore, large cascades are able to accumulate hundreds of Snopes comments while continuing to propagate. Finally, using a dataset of rumors copied and pasted from one status update to another, we show that rumors change over time and that different variants tend to dominate different bursts in popularity.", "year": 2014, "authors": [{"authorId": "34760887", "name": "A. Friggeri"}, {"authorId": "1778398", "name": "Lada A. Adamic"}, {"authorId": "1996878", "name": "Dean Eckles"}, {"authorId": "144500753", "name": "Justin Cheng"}], "cluster": 22, "position": {"x": -0.6128554940223694, "y": -27.825389862060547}}, {"paperId": "9aefd614e52336151966d8dca2ed0ea62a8f30af", "url": "https://www.semanticscholar.org/paper/9aefd614e52336151966d8dca2ed0ea62a8f30af", "title": "The Limitations of Stylometry for Detecting Machine-Generated Fake News", "abstract": "Recent developments in neural language models (LMs) have raised concerns about their potential misuse for automatically spreading misinformation. In light of these concerns, several studies have proposed to detect machine-generated fake news by capturing their stylistic differences from human-written text. These approaches, broadly termed stylometry, have found success in source attribution and misinformation detection in human-written texts. However, in this work, we show that stylometry is limited against machine-generated misinformation. Whereas humans speak differently when trying to deceive, LMs generate stylistically consistent text, regardless of underlying motive. Thus, though stylometry can successfully prevent impersonation by identifying text provenance, it fails to distinguish legitimate LM applications from those that introduce false information. We create two benchmarks demonstrating the stylistic similarity between malicious and legitimate uses of LMs, utilized in auto-completion and editing-assistance settings.1 Our findings highlight the need for non-stylometry approaches in detecting machine-generated misinformation, and open up the discussion on the desired evaluation benchmarks.", "year": 2020, "authors": [{"authorId": "32303439", "name": "Tal Schuster"}, {"authorId": "39347554", "name": "R. Schuster"}, {"authorId": "143896588", "name": "Darsh J. Shah"}, {"authorId": "1741283", "name": "R. Barzilay"}], "cluster": 15, "position": {"x": 12.464693069458008, "y": -42.5465202331543}}, {"paperId": "9e8ac8df8b46c36cad3f307f85975012479b5a32", "url": "https://www.semanticscholar.org/paper/9e8ac8df8b46c36cad3f307f85975012479b5a32", "title": "Fact or Fiction: Verifying Scientific Claims", "abstract": "We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that supports or refutes a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SciFact, and demonstrate that these models benefit from combined training on a large dataset of claims about Wikipedia articles, together with the new SciFact data. We show that our claim verification system is able to identify plausible evidence for 23 / 36 claims relevant to COVID-19 on the CORD-19 corpus. Our results and experiments strongly suggest that our new task and data will support significant future research efforts.", "year": 2020, "authors": [{"authorId": "30051202", "name": "David Wadden"}, {"authorId": "46258841", "name": "Kyle Lo"}, {"authorId": "31860505", "name": "Lucy Lu Wang"}, {"authorId": "32370203", "name": "Shanchuan Lin"}, {"authorId": "15292561", "name": "Madeleine van Zuylen"}, {"authorId": "2527954", "name": "Arman Cohan"}, {"authorId": "2548384", "name": "Hannaneh Hajishirzi"}], "cluster": 15, "position": {"x": -4.711389541625977, "y": -43.974788665771484}}, {"paperId": "6f373f4711e1285bdec23069c9503d3bf77bfaef", "url": "https://www.semanticscholar.org/paper/6f373f4711e1285bdec23069c9503d3bf77bfaef", "title": "A Benchmark Dataset of Check-worthy Factual Claims", "abstract": "In this paper we present the ClaimBuster dataset of 23,533 statements extracted from all U.S. general election presidential debates and annotated by human coders. The ClaimBuster dataset can be leveraged in building computational methods to identify claims that are worth fact-checking from the myriad of sources of digital or traditional media. The ClaimBuster dataset is publicly available to the research community, and it can be found at this http URL.", "year": 2020, "authors": [{"authorId": "144285061", "name": "Fatma Arslan"}, {"authorId": "2789540", "name": "Naeemul Hassan"}, {"authorId": "2128664093", "name": "Chengkai Li"}, {"authorId": "2819331", "name": "M. Tremayne"}], "cluster": 15, "position": {"x": -0.4344393312931061, "y": -43.87556076049805}}, {"paperId": "ad7129af0644dbcafa9aa2f111cb76526ea444a1", "url": "https://www.semanticscholar.org/paper/ad7129af0644dbcafa9aa2f111cb76526ea444a1", "title": "Defending Against Neural Fake News", "abstract": "Recent progress in natural language generation has raised dual-use concerns. While applications like summarization and translation are positive, the underlying technology also might enable adversaries to generate neural fake news: targeted propaganda that closely mimics the style of real news. \nModern computer security relies on careful threat modeling: identifying potential threats and vulnerabilities from an adversary's point of view, and exploring potential mitigations to these threats. Likewise, developing robust defenses against neural fake news requires us first to carefully investigate and characterize the risks of these models. We thus present a model for controllable text generation called Grover. Given a headline like `Link Found Between Vaccines and Autism,' Grover can generate the rest of the article; humans find these generations to be more trustworthy than human-written disinformation. \nDeveloping robust verification techniques against generators like Grover is critical. We find that best current discriminators can classify neural fake news from real, human-written, news with 73% accuracy, assuming access to a moderate level of training data. Counterintuitively, the best defense against Grover turns out to be Grover itself, with 92% accuracy, demonstrating the importance of public release of strong generators. We investigate these results further, showing that exposure bias -- and sampling strategies that alleviate its effects -- both leave artifacts that similar discriminators can pick up on. We conclude by discussing ethical issues regarding the technology, and plan to release Grover publicly, helping pave the way for better detection of neural fake news.", "year": 2019, "authors": [{"authorId": "2545335", "name": "Rowan Zellers"}, {"authorId": "14487640", "name": "Ari Holtzman"}, {"authorId": "2516777", "name": "Hannah Rashkin"}, {"authorId": "3312309", "name": "Yonatan Bisk"}, {"authorId": "143787583", "name": "Ali Farhadi"}, {"authorId": "3268360", "name": "Franziska Roesner"}, {"authorId": "1699545", "name": "Yejin Choi"}], "cluster": 15, "position": {"x": 13.471856117248535, "y": -42.21685028076172}}, {"paperId": "d8cb11d4be955f9869387a18967dee366eb851d9", "url": "https://www.semanticscholar.org/paper/d8cb11d4be955f9869387a18967dee366eb851d9", "title": "MultiFC: A Real-World Multi-Domain Dataset for Evidence-Based Fact Checking of Claims", "abstract": "We contribute the largest publicly available dataset of naturally occurring factual claims for the purpose of automatic claim verification. It is collected from 26 fact checking websites in English, paired with textual sources and rich metadata, and labelled for veracity by human expert journalists. We present an in-depth analysis of the dataset, highlighting characteristics and challenges. Further, we present results for automatic veracity prediction, both with established baselines and with a novel method for joint ranking of evidence pages and predicting veracity that outperforms all baselines. Significant performance increases are achieved by encoding evidence, and by modelling metadata. Our best-performing model achieves a Macro F1 of 49.2%, showing that this is a challenging testbed for claim veracity prediction.", "year": 2019, "authors": [{"authorId": "1736067", "name": "Isabelle Augenstein"}, {"authorId": "1784800", "name": "C. Lioma"}, {"authorId": "2111243103", "name": "Dongsheng Wang"}, {"authorId": "145980035", "name": "Lucas Chaves Lima"}, {"authorId": "144613166", "name": "Casper Hansen"}, {"authorId": "144613163", "name": "Christian Hansen"}, {"authorId": "1707651", "name": "J. Simonsen"}], "cluster": 15, "position": {"x": -1.483229398727417, "y": -45.37324523925781}}, {"paperId": "5e0daaeceb75ffbbe23be13d34ffae830cb4e8c4", "url": "https://www.semanticscholar.org/paper/5e0daaeceb75ffbbe23be13d34ffae830cb4e8c4", "title": "Generating Fact Checking Explanations", "abstract": "Most existing work on automated fact checking is concerned with predicting the veracity of claims based on metadata, social network spread, language used in claims, and, more recently, evidence supporting or denying claims. A crucial piece of the puzzle that is still missing is to understand how to automate the most elaborate part of the process \u2013 generating justifications for verdicts on claims. This paper provides the first study of how these explanations can be generated automatically based on available claim context, and how this task can be modelled jointly with veracity prediction. Our results indicate that optimising both objectives at the same time, rather than training them separately, improves the performance of a fact checking system. The results of a manual evaluation further suggest that the informativeness, coverage and overall quality of the generated explanations are also improved in the multi-task model.", "year": 2020, "authors": [{"authorId": "145676297", "name": "Pepa Atanasova"}, {"authorId": "1707651", "name": "J. Simonsen"}, {"authorId": "1784800", "name": "C. Lioma"}, {"authorId": "1736067", "name": "Isabelle Augenstein"}], "cluster": 15, "position": {"x": 1.1086386442184448, "y": -47.00983810424805}}, {"paperId": "a4947468ceac25c11a665c4f5f95a49d6dbea3cc", "url": "https://www.semanticscholar.org/paper/a4947468ceac25c11a665c4f5f95a49d6dbea3cc", "title": "Towards Debiasing Fact Verification Models", "abstract": "Fact verification requires validating a claim in the context of evidence. We show, however, that in the popular FEVER dataset this might not necessarily be the case. Claim-only classifiers perform competitively with top evidence-aware models. In this paper, we investigate the cause of this phenomenon, identifying strong cues for predicting labels solely based on the claim, without considering any evidence. We create an evaluation set that avoids those idiosyncrasies. The performance of FEVER-trained models significantly drops when evaluated on this test set. Therefore, we introduce a regularization method which alleviates the effect of bias in the training data, obtaining improvements on the newly created test set. This work is a step towards a more sound evaluation of reasoning capabilities in fact verification models.", "year": 2019, "authors": [{"authorId": "32303439", "name": "Tal Schuster"}, {"authorId": "143896588", "name": "Darsh J. Shah"}, {"authorId": "153466660", "name": "Yun Jie Serene Yeo"}, {"authorId": "67260776", "name": "Daniel Filizzola"}, {"authorId": "150991377", "name": "Enrico Santus"}, {"authorId": "1741283", "name": "R. Barzilay"}], "cluster": 15, "position": {"x": -5.298789024353027, "y": -46.1007194519043}}, {"paperId": "3a16c38294ac8899825c488490199b854e05473a", "url": "https://www.semanticscholar.org/paper/3a16c38294ac8899825c488490199b854e05473a", "title": "Evaluating adversarial attacks against multiple fact verification systems", "abstract": "Automated fact verification has been progressing owing to advancements in modeling and availability of large datasets. Due to the nature of the task, it is critical to understand the vulnerabilities of these systems against adversarial instances designed to make them predict incorrectly. We introduce two novel scoring metrics, attack potency and system resilience which take into account the correctness of the adversarial instances, an aspect often ignored in adversarial evaluations. We consider six fact verification systems from the recent Fact Extraction and VERification (FEVER) challenge: the four best-scoring ones and two baselines. We evaluate adversarial instances generated by a recently proposed state-of-the-art method, a paraphrasing method, and rule-based attacks devised for fact verification. We find that our rule-based attacks have higher potency, and that while the rankings among the top systems changed, they exhibited higher resilience than the baselines.", "year": 2019, "authors": [{"authorId": "2053211210", "name": "James Thorne"}, {"authorId": "2064056928", "name": "Andreas Vlachos"}, {"authorId": "2718039", "name": "Christos Christodoulopoulos"}, {"authorId": "2008596", "name": "Arpit Mittal"}], "cluster": 15, "position": {"x": -2.6328067779541016, "y": -48.12491989135742}}, {"paperId": "f14cb1828e314a669304b0c37bc78d6b9073f6dd", "url": "https://www.semanticscholar.org/paper/f14cb1828e314a669304b0c37bc78d6b9073f6dd", "title": "Measuring Societal Biases in Text Corpora via First-Order Co-occurrence", "abstract": "Text corpora are used to study societal biases, typically through statistical models such as word embeddings. The bias of a word towards a concept is typically estimated using vectors similarity, measuring whether the word and concept words share other words in their contexts. We argue that this second-order relationship introduces unrelated concepts into the measure, which causes an imprecise measurement of the bias. We propose instead to measure bias using the direct normalized co-occurrence associations between the word and the representative concept words, a first-order measure, by reconstructing the co-occurrence estimates inherent in the word embedding models. To study our novel corpus bias measurement method, we calculate the correlation of the gender bias values estimated from the text to the actual gender bias statistics of the U.S. job market, provided by two recent collections. The results show a consistently higher correlation when using the proposed first-order measure with a variety of word embedding models, as well as a more severe degree of bias, especially to female in a few specific occupations.", "year": 2018, "authors": [{"authorId": "2844293", "name": "Navid Rekabsaz"}, {"authorId": "46712043", "name": "J. Henderson"}, {"authorId": "145781376", "name": "Robert West"}, {"authorId": "1699657", "name": "A. Hanbury"}], "cluster": 14, "position": {"x": 5.140169620513916, "y": 35.234920501708984}}, {"paperId": "d4eeb40b9bd06ed53a26282cd527609f71e6496f", "url": "https://www.semanticscholar.org/paper/d4eeb40b9bd06ed53a26282cd527609f71e6496f", "title": "Unsupervised Discovery of Gendered Language through Latent-Variable Modeling", "abstract": "Studying the ways in which language is gendered has long been an area of interest in sociolinguistics. Studies have explored, for example, the speech of male and female characters in film and the language used to describe male and female politicians. In this paper, we aim not to merely study this phenomenon qualitatively, but instead to quantify the degree to which the language used to describe men and women is different and, moreover, different in a positive or negative way. To that end, we introduce a generative latent-variable model that jointly represents adjective (or verb) choice, with its sentiment, given the natural gender of a head (or dependent) noun. We find that there are significant differences between descriptions of male and female nouns and that these differences align with common gender stereotypes: Positive adjectives used to describe women are more often related to their bodies than adjectives used to describe men.", "year": 2019, "authors": [{"authorId": "49462969", "name": "Alexander Miserlis Hoyle"}, {"authorId": "1390095176", "name": "Lawrence Wolf-Sonkin"}, {"authorId": "1831395", "name": "H. Wallach"}, {"authorId": "1736067", "name": "Isabelle Augenstein"}, {"authorId": "1750769", "name": "Ryan Cotterell"}], "cluster": 14, "position": {"x": 12.255157470703125, "y": 36.42567443847656}}, {"paperId": "b1d24e8e08435b7c52335485a0d635abf9bc604c", "url": "https://www.semanticscholar.org/paper/b1d24e8e08435b7c52335485a0d635abf9bc604c", "title": "FEVER: a Large-scale Dataset for Fact Extraction and VERification", "abstract": "In this paper we introduce a new publicly available dataset for verification against textual sources, FEVER: Fact Extraction and VERification. It consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. The claims are classified as Supported, Refuted or NotEnoughInfo by annotators achieving 0.6841 in Fleiss kappa. For the first two classes, the annotators also recorded the sentence(s) forming the necessary evidence for their judgment. To characterize the challenge of the dataset presented, we develop a pipeline approach and compare it to suitably designed oracles. The best accuracy we achieve on labeling a claim accompanied by the correct evidence is 31.87%, while if we ignore the evidence we achieve 50.91%. Thus we believe that FEVER is a challenging testbed that will help stimulate progress on claim verification against textual sources.", "year": 2018, "authors": [{"authorId": "144603330", "name": "James Thorne"}, {"authorId": "2775151", "name": "Andreas Vlachos"}, {"authorId": "2718039", "name": "Christos Christodoulopoulos"}, {"authorId": "2008596", "name": "Arpit Mittal"}], "cluster": 15, "position": {"x": -2.6248536109924316, "y": -45.658714294433594}}, {"paperId": "c3bcdea205ec9fb1b84d75d4767f346844082b38", "url": "https://www.semanticscholar.org/paper/c3bcdea205ec9fb1b84d75d4767f346844082b38", "title": "Stereotypes in High-Stakes Decisions: Evidence from U.S. Circuit Courts", "abstract": "Attitudes towards social groups such as women and racial minorities have been shown to be important determinants of individual\u2019s decisions but are hard to measure for those in policy-making roles. We propose a way to address the challenge in the case of U.S. appellate court judges, for whom we have large corpora of written text (their published opinions). Using the universe of published opinions in U.S. Circuit Courts 1890-2013, we construct a judge-specific measure of gender-stereotyped language (gender slant) by looking at the relative co-occurrence of words identifying gender (male versus female) and words identifying gender stereotypes (career versus family). We find that female and younger judges tend to use less stereotyped language in their opinions. In addition, the attitudes measured by gender slant matter for judicial decisions: judges with higher slant vote more conservatively on women rights\u2019 issues. These more slanted judges also influence workplace outcomes for female colleagues: they are less likely to assign opinions to female judges, they cite fewer female-authored opinions, and they are more likely to reverse lower-court decisions if the lower-court judge is a woman. Our results expose a possible use of text to detect decision-makers\u2019 stereotypes that predict behavior and disparate outcomes. \u2217Arianna Ornaghi, University of Warwick, a.ornaghi@warwick.ac.uk (corresponding author); Elliott Ash, ETH Zurich, ashe@ethz.ch; Daniel Chen, Toulouse School of Economics, daniel.chen@iast.fr. We thank Jacopo Bregolin, David Cai, Christoph Goessmann, and Ornelie Manzambi for helpful research assistance.", "year": 2019, "authors": [{"authorId": "2079265131", "name": "A. Ornaghi"}], "cluster": 14, "position": {"x": 1.6034464836120605, "y": 34.93340301513672}}, {"paperId": "bb53946c7da617a05bbeef47fff74012db27ee78", "url": "https://www.semanticscholar.org/paper/bb53946c7da617a05bbeef47fff74012db27ee78", "title": "ChrEnTranslate: Cherokee-English Machine Translation Demo with Quality Estimation and Corrective Feedback", "abstract": "We introduce ChrEnTranslate, an online ma\u00ad chine translation demonstration system for translation between English and an endangered language Cherokee. It supports both statistical and neural translation models as well as pro\u00ad vides quality estimation to inform users of re\u00ad liability, two user feedback interfaces for ex\u00ad perts and common users respectively, exam\u00ad ple inputs to collect human translations for monolingual data, word alignment visualiza\u00ad tion, and relevant terms from the Cherokee\u00ad English dictionary. The quantitative evalu\u00ad ation demonstrates that our backbone trans\u00ad lation models achieve state\u00adof\u00adthe\u00adart transla\u00ad tion performance and our quality estimation well correlates with both BLEU and human judgment. By analyzing 216 pieces of expert feedback, we find that NMT is preferable be\u00ad cause it copies less than SMT, and, in gen\u00ad eral, current models can translate fragments of the source sentence but make major mistakes. When we add these 216 expert\u00adcorrected paral\u00ad lel texts into the training set and retrain mod\u00ad els, equal or slightly better performance is ob\u00ad served, which demonstrates indicates the po\u00ad tential of human\u00adin\u00adthe\u00adloop learning.1", "year": 2021, "authors": [{"authorId": null, "name": "Shiyue Zhang"}, {"authorId": "46689115", "name": "B. Frey"}, {"authorId": "143977266", "name": "M. Bansal"}], "cluster": 11, "position": {"x": -8.14432144165039, "y": 23.638303756713867}}, {"paperId": "7b5b2a9ad37d1a6c3c8916965b1958eef0a27a6a", "url": "https://www.semanticscholar.org/paper/7b5b2a9ad37d1a6c3c8916965b1958eef0a27a6a", "title": "Automatically Inferring Gender Associations from Language", "abstract": "In this paper, we pose the question: do people talk about women and men in different ways? We introduce two datasets and a novel integration of approaches for automatically inferring gender associations from language, discovering coherent word clusters, and labeling the clusters for the semantic concepts they represent. The datasets allow us to compare how people write about women and men in two different settings \u2013 one set draws from celebrity news and the other from student reviews of computer science professors. We demonstrate that there are large-scale differences in the ways that people talk about women and men and that these differences vary across domains. Human evaluations show that our methods significantly outperform strong baselines.", "year": 2019, "authors": [{"authorId": "22369664", "name": "Serina Chang"}, {"authorId": "145590324", "name": "K. McKeown"}], "cluster": 14, "position": {"x": 10.79468059539795, "y": 36.37736511230469}}, {"paperId": "0e141942fa265142f41a2a26eb17b6005d3af29e", "url": "https://www.semanticscholar.org/paper/0e141942fa265142f41a2a26eb17b6005d3af29e", "title": "The State and Fate of Linguistic Diversity and Inclusion in the NLP World", "abstract": "Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the \u201clanguage agnostic\u201d status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.", "year": 2020, "authors": [{"authorId": "47070483", "name": "Pratik M. Joshi"}, {"authorId": "50074956", "name": "Sebastin Santy"}, {"authorId": "2410839", "name": "A. Budhiraja"}, {"authorId": "3086996", "name": "Kalika Bali"}, {"authorId": "143990839", "name": "M. Choudhury"}], "cluster": 9, "position": {"x": -20.939512252807617, "y": 28.497509002685547}}, {"paperId": "a1280728623e8fd605284b2b7cf536579b9e2cbf", "url": "https://www.semanticscholar.org/paper/a1280728623e8fd605284b2b7cf536579b9e2cbf", "title": "Entity-Centric Contextual Affective Analysis", "abstract": "While contextualized word representations have improved state-of-the-art benchmarks in many NLP tasks, their potential usefulness for social-oriented tasks remains largely unexplored. We show how contextualized word embeddings can be used to capture affect dimensions in portrayals of people. We evaluate our methodology quantitatively, on held-out affect lexicons, and qualitatively, through case examples. We find that contextualized word representations do encode meaningful affect information, but they are heavily biased towards their training data, which limits their usefulness to in-domain analyses. We ultimately use our method to examine differences in portrayals of men and women.", "year": 2019, "authors": [{"authorId": "49713890", "name": "Anjalie Field"}, {"authorId": "145317727", "name": "Yulia Tsvetkov"}], "cluster": 14, "position": {"x": 6.502472877502441, "y": 18.365283966064453}}, {"paperId": "3d309aa1629ef9ca43e252eb6bf539286ed872f9", "url": "https://www.semanticscholar.org/paper/3d309aa1629ef9ca43e252eb6bf539286ed872f9", "title": "Haitian Creole: How to Build and Ship an MT Engine from Scratch in 4 days, 17 hours, & 30 minutes", "abstract": "We describe the effort of the Microsoft Translator team to develop a Haitian Creole statistical machine translation engine from scratch in a matter of days. Haitian Creole presents a number of difficulties for devleoping an SMT system, principal among these is the lack of significant amounts of parallel training data and an inconsistent orthography, both of which lead to data sparseness. We demonstrate, however, that it is possible to build a translation engine of reasonable quality over very little data by engaging with the native language community and reducing data sparseness in creative ways. As such, we show that MT as a technology and as a service can be deployed rapidly in crisis situations.", "year": 2010, "authors": [{"authorId": "119117298", "name": "W. Lewis"}], "cluster": 11, "position": {"x": -8.992133140563965, "y": 24.00729751586914}}, {"paperId": "176420f394014d9e67d5cff1e1d430541fa0f55f", "url": "https://www.semanticscholar.org/paper/176420f394014d9e67d5cff1e1d430541fa0f55f", "title": "When do Word Embeddings Accurately Reflect Surveys on our Beliefs About People?", "abstract": "Social biases are encoded in word embeddings. This presents a unique opportunity to study society historically and at scale, and a unique danger when embeddings are used in downstream applications. Here, we investigate the extent to which publicly-available word embeddings accurately reflect beliefs about certain kinds of people as measured via traditional survey methods. We find that biases found in word embeddings do, on average, closely mirror survey data across seventeen dimensions of social meaning. However, we also find that biases in embeddings are much more reflective of survey data for some dimensions of meaning (e.g. gender) than others (e.g. race), and that we can be highly confident that embedding-based measures reflect survey data only for the most salient biases.", "year": 2020, "authors": [{"authorId": "3306556", "name": "K. Joseph"}, {"authorId": "40395376", "name": "Jonathan H. Morgan"}], "cluster": 14, "position": {"x": 1.5881426334381104, "y": 38.428958892822266}}, {"paperId": "3d505c5eff8752ac1805ef546d683bfa40aec4b1", "url": "https://www.semanticscholar.org/paper/3d505c5eff8752ac1805ef546d683bfa40aec4b1", "title": "Tie-breaker: Using language models to quantify gender bias in sports journalism", "abstract": "Gender bias is an increasingly important issue in sports journalism. In this work, we propose a language-model-based approach to quantify differences in questions posed to female vs. male athletes, and apply it to tennis post-match interviews. We find that journalists ask male players questions that are generally more focused on the game when compared with the questions they ask their female counterparts. We also provide a fine-grained analysis of the extent to which the salience of this bias depends on various factors, such as question type, game outcome or player rank.", "year": 2016, "authors": [{"authorId": "3436644", "name": "Liye Fu"}, {"authorId": "1388368997", "name": "Cristian Danescu-Niculescu-Mizil"}, {"authorId": "145810617", "name": "Lillian Lee"}], "cluster": 14, "position": {"x": 12.22873306274414, "y": 33.41558837890625}}, {"paperId": "5e888bfd9b492a3b08f3cc2eb7c617fedf5bd811", "url": "https://www.semanticscholar.org/paper/5e888bfd9b492a3b08f3cc2eb7c617fedf5bd811", "title": "Relating Linguistic Gender Bias, Gender Values, and Gender Gaps: An International Analysis", "abstract": "Recent research in machine learning has shown that many machine-learned language models contain pervasive racial and gender biases, rooting from biases in their textual training data. While these biases produce sub-optimal parsing and inferences, they may help us characterize and predict statistical gender gaps and gender values in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach to (1) quantify gender bias in word embeddings (i.e., vector-based lexical semantics), (2) correlate gender biases with survey responses and statistical gender gaps in education, politics, economics, and health, and (3) integrate numerical biases and statistics to model different cultures\u2019 survey results more accurately than either in isolation. We validate this approach using 2018 Twitter data spanning 99 countries, 18 Global Gender Gap statistics from the World Economic Forum, and 8 international survey results from the World Value Survey. Integrating these heterogeneous data across cultures is an important step toward building computational models to understand group bias.", "year": 2019, "authors": [{"authorId": "2055325676", "name": "Scott E. Friedman"}, {"authorId": "1403006514", "name": "S. Schmer-Galunder"}, {"authorId": "3027221", "name": "J. Rye"}, {"authorId": "2053256748", "name": "R. Goldman"}, {"authorId": "2111075245", "name": "Anthony Chen"}, {"authorId": "2107791137", "name": "A. Chen"}], "cluster": 14, "position": {"x": 6.253790855407715, "y": 33.12543869018555}}, {"paperId": "ef5fa2e95fc853defb902b58d8e4e4fe95a01c75", "url": "https://www.semanticscholar.org/paper/ef5fa2e95fc853defb902b58d8e4e4fe95a01c75", "title": "Shirtless and Dangerous: Quantifying Linguistic Signals of Gender Bias in an Online Fiction Writing Community", "abstract": "Imagine a princess asleep in a castle, waiting for her prince to slay the dragon and rescue her. Tales like the famous Sleeping Beauty clearly divide up gender roles. But what about more modern stories, borne of a generation increasingly aware of social constructs like sexism and racism? Do these stories tend to reinforce gender stereotypes, or counter them? In this paper, we present a technique that combines natural language processing with a crowdsourced lexicon of stereotypes to capture gender biases in fiction. We apply this technique across 1.8 billion words of fiction from the Wattpad online writing community, investigating gender representation in stories, how male and female characters behave and are described, and how authors' use of gender stereotypes is associated with the community's ratings. We find that male over-representation and traditional gender stereotypes (e.g., dominant men and submissive women) are common throughout nearly every genre in our corpus. However, only some of these stereotypes, like sexual or violent men, are associated with highly rated stories. Finally, despite women often being the target of negative stereotypes, female authors are equally likely to write such stereotypes as men.", "year": 2016, "authors": [{"authorId": "2660071", "name": "Ethan Fast"}, {"authorId": "3374285", "name": "Tina Vachovsky"}, {"authorId": "145879842", "name": "Michael S. Bernstein"}], "cluster": 14, "position": {"x": 12.482577323913574, "y": 30.24739646911621}}, {"paperId": "b5d7a19bd0bae10917a8e294960fdacf224d64fe", "url": "https://www.semanticscholar.org/paper/b5d7a19bd0bae10917a8e294960fdacf224d64fe", "title": "Word embeddings quantify 100 years of gender and ethnic stereotypes", "abstract": "Significance Word embeddings are a popular machine-learning method that represents each English word by a vector, such that the geometry between these vectors captures semantic relations between the corresponding words. We demonstrate that word embeddings can be used as a powerful tool to quantify historical trends and social change. As specific applications, we develop metrics based on word embeddings to characterize how gender stereotypes and attitudes toward ethnic minorities in the United States evolved during the 20th and 21st centuries starting from 1910. Our framework opens up a fruitful intersection between machine learning and quantitative social science. Word embeddings are a powerful machine-learning framework that represents each English word by a vector. The geometric relationship between these vectors captures meaningful semantic relationships between the corresponding words. In this paper, we develop a framework to demonstrate how the temporal dynamics of the embedding helps to quantify changes in stereotypes and attitudes toward women and ethnic minorities in the 20th and 21st centuries in the United States. We integrate word embeddings trained on 100 y of text data with the US Census to show that changes in the embedding track closely with demographic and occupation shifts over time. The embedding captures societal shifts\u2014e.g., the women\u2019s movement in the 1960s and Asian immigration into the United States\u2014and also illuminates how specific adjectives and occupations became more closely associated with certain populations over time. Our framework for temporal analysis of word embedding opens up a fruitful intersection between machine learning and quantitative social science.", "year": 2018, "authors": [{"authorId": "2779427", "name": "Nikhil Garg"}, {"authorId": "5336339", "name": "L. Schiebinger"}, {"authorId": "1746807", "name": "Dan Jurafsky"}, {"authorId": "145085305", "name": "James Y. Zou"}], "cluster": 14, "position": {"x": 2.620952844619751, "y": 37.521873474121094}}, {"paperId": "6ba951771892f01206f1dd7244f14243e3885109", "url": "https://www.semanticscholar.org/paper/6ba951771892f01206f1dd7244f14243e3885109", "title": "Contextual Affective Analysis: A Case Study of People Portrayals in Online #MeToo Stories", "abstract": "In October 2017, numerous women accused producer Harvey Weinstein of sexual harassment. Their stories encouraged other women to voice allegations of sexual harassment against many high profile men, including politicians, actors, and producers. These events are broadly referred to as the #MeToo movement, named for the use of the hashtag \"#metoo\" on social media platforms like Twitter and Facebook. The movement has widely been referred to as \"empowering\" because it has amplified the voices of previously unheard women over those of traditionally powerful men. In this work, we investigate dynamics of sentiment, power and agency in online media coverage of these events. Using a corpus of online media articles about the #MeToo movement, we present a contextual affective analysis---an entity-centric approach that uses contextualized lexicons to examine how people are portrayed in media articles. We show that while these articles are sympathetic towards women who have experienced sexual harassment, they consistently present men as most powerful, even after sexual assault allegations. While we focus on media coverage of the #MeToo movement, our method for contextual affective analysis readily generalizes to other domains.", "year": 2019, "authors": [{"authorId": "49713890", "name": "Anjalie Field"}, {"authorId": "8039151", "name": "G. Bhat"}, {"authorId": "145317727", "name": "Yulia Tsvetkov"}], "cluster": 19, "position": {"x": 19.050392150878906, "y": -9.822150230407715}}, {"paperId": "7b14a165c6b7c1dc2c6c44727e623b94d834fb09", "url": "https://www.semanticscholar.org/paper/7b14a165c6b7c1dc2c6c44727e623b94d834fb09", "title": "Social Bias Frames: Reasoning about Social and Power Implications of Language", "abstract": "Warning: this paper contains content that may be offensive or upsetting. Language has the power to reinforce stereotypes and project social biases onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people\u2019s judgments about others. For example, given a statement that \u201cwe shouldn\u2019t lower our standards to hire more women,\u201d most listeners will infer the implicature intended by the speaker - that \u201cwomen (candidates) are less qualified.\u201d Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce Social Bias Frames, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover Social Bias Frames from unstructured text. We find that while state-of-the-art neural models are effective at high-level categorization of whether a given statement projects unwanted social bias (80% F1), they are not effective at spelling out more detailed explanations in terms of Social Bias Frames. Our study motivates future work that combines structured pragmatic inference with commonsense reasoning on social implications.", "year": 2020, "authors": [{"authorId": "2729164", "name": "Maarten Sap"}, {"authorId": "119902504", "name": "Saadia Gabriel"}, {"authorId": "3444092", "name": "Lianhui Qin"}, {"authorId": "1746807", "name": "Dan Jurafsky"}, {"authorId": "144365876", "name": "Noah A. Smith"}, {"authorId": "1699545", "name": "Yejin Choi"}], "cluster": 14, "position": {"x": 13.288434028625488, "y": 21.411331176757812}}, {"paperId": "e3fd3b1be871da6e048adaef4a4e201af282fe8e", "url": "https://www.semanticscholar.org/paper/e3fd3b1be871da6e048adaef4a4e201af282fe8e", "title": "Empathy Is All You Need: How a Conversational Agent Should Respond to Verbal Abuse", "abstract": "With the popularity of AI-infused systems, conversational agents (CAs) are becoming essential in diverse areas, offering new functionality and convenience, but simultaneously, suffering misuse and verbal abuse. We examine whether conversational agents' response styles under varying abuse types influence those emotions found to mitigate peoples' aggressive behaviors, involving three verbal abuse types (Insult, Threat, Swearing) and three response styles (Avoidance, Empathy, Counterattacking). Ninety-eight participants were assigned to one of the abuse type conditions, interacted with the three spoken (voice-based) CAs in turn, and reported their feelings about guiltiness, anger, and shame after each session. The results show that the agent's response style has a significant effect on user emotions. Participants were less angry and more guilty with the empathy agent than the other two agents. Furthermore, we investigated the current status of commercial CAs' responses to verbal abuse. Our study findings have direct implications for the design of conversational agents.", "year": 2020, "authors": [{"authorId": "32721006", "name": "Hyojin Chin"}, {"authorId": "10775146", "name": "Lebogang Wame Molefi"}, {"authorId": "1796342", "name": "M. Yi"}], "cluster": 4, "position": {"x": -42.378299713134766, "y": 17.451778411865234}}, {"paperId": "0c68d7d153bb56e4637d6aee051d87580e05fd5b", "url": "https://www.semanticscholar.org/paper/0c68d7d153bb56e4637d6aee051d87580e05fd5b", "title": "Detecting East Asian Prejudice on Social Media", "abstract": "During COVID-19 concerns have heightened about the spread of aggressive and hateful language online, especially hostility directed against East Asia and East Asian people. We report on a new dataset and the creation of a machine learning classifier that categorizes social media posts from Twitter into four classes: Hostility against East Asia, Criticism of East Asia, Meta-discussions of East Asian prejudice, and a neutral class. The classifier achieves a macro-F1 score of 0.83. We then conduct an in-depth ground-up error analysis and show that the model struggles with edge cases and ambiguous content. We provide the 20,000 tweet training dataset (annotated by experienced analysts), which also contains several secondary categories and additional flags. We also provide the 40,000 original annotations (before adjudication), the full codebook, annotations for COVID-19 relevance and East Asian relevance and stance for 1,000 hashtags, and the final model.", "year": 2020, "authors": [{"authorId": "2737827", "name": "Bertie Vidgen"}, {"authorId": "1686287970", "name": "Austin Botelho"}, {"authorId": "3119101", "name": "David A. Broniatowski"}, {"authorId": "29761736", "name": "E. Guest"}, {"authorId": "2114041492", "name": "M. Hall"}, {"authorId": "1791413", "name": "H. Margetts"}, {"authorId": "40944409", "name": "Rebekah Tromble"}, {"authorId": "3456512", "name": "Zeerak Waseem"}, {"authorId": "1801223", "name": "Scott A. Hale"}], "cluster": 24, "position": {"x": -0.49285897612571716, "y": -6.863792896270752}}, {"paperId": "75d0cb419d7d58e81c2975758a36a11544a9f930", "url": "https://www.semanticscholar.org/paper/75d0cb419d7d58e81c2975758a36a11544a9f930", "title": "Language from police body camera footage shows racial disparities in officer respect", "abstract": "Significance Police officers speak significantly less respectfully to black than to white community members in everyday traffic stops, even after controlling for officer race, infraction severity, stop location, and stop outcome. This paper presents a systematic analysis of officer body-worn camera footage, using computational linguistic techniques to automatically measure the respect level that officers display to community members. This work demonstrates that body camera footage can be used as a rich source of data rather than merely archival evidence, and paves the way for developing powerful language-based tools for studying and potentially improving police\u2013community relations. Using footage from body-worn cameras, we analyze the respectfulness of police officer language toward white and black community members during routine traffic stops. We develop computational linguistic methods that extract levels of respect automatically from transcripts, informed by a thin-slicing study of participant ratings of officer utterances. We find that officers speak with consistently less respect toward black versus white community members, even after controlling for the race of the officer, the severity of the infraction, the location of the stop, and the outcome of the stop. Such disparities in common, everyday interactions between police and the communities they serve have important implications for procedural justice and the building of police\u2013community trust.", "year": 2017, "authors": [{"authorId": "35248702", "name": "R. Voigt"}, {"authorId": "7587947", "name": "Nicholas P Camp"}, {"authorId": "3331141", "name": "Vinodkumar Prabhakaran"}, {"authorId": "49437682", "name": "William L. Hamilton"}, {"authorId": "8064599", "name": "Rebecca C Hetey"}, {"authorId": "12623353", "name": "Camilla Griffiths"}, {"authorId": "3046220", "name": "David Jurgens"}, {"authorId": "1746807", "name": "Dan Jurafsky"}, {"authorId": "3165935", "name": "J. Eberhardt"}], "cluster": 4, "position": {"x": -37.99353790283203, "y": 33.128719329833984}}, {"paperId": "070b4a707748e289618880ffbe4762e4e3fc7860", "url": "https://www.semanticscholar.org/paper/070b4a707748e289618880ffbe4762e4e3fc7860", "title": "Racism is a Virus: Anti-Asian Hate and Counterhate in Social Media during the COVID-19 Crisis", "abstract": "The spread of COVID-19 has sparked racism, hate, and xenophobia in social media targeted at Chinese and broader Asian communities. However, little is known about how racial hate spreads during a pandemic and the role of counterhate speech in mitigating the spread. Here we study the evolution and spread of anti-Asian hate speech through the lens of Twitter. We create COVID-HATE, the largest dataset of anti-Asian hate and counterhate spanning three months, containing over 30 million tweets, and a social network with over 87 million nodes. By creating a novel hand-labeled dataset of 2,400 tweets, we train a text classifier to identify hate and counterhate tweets that achieves an average AUROC of 0.852. We identify 891,204 hate and 200,198 counterhate tweets in COVID-HATE. Using this data to conduct longitudinal analysis, we find that while hateful users are less engaged in the COVID-19 discussions prior to their first anti-Asian tweet, they become more vocal and engaged afterwards compared to counterhate users. We find that bots comprise 10.4% of hateful users and are more vocal and hateful compared to non-bot users. Comparing bot accounts, we show that hateful bots are more successful in attracting followers compared to counterhate bots. Analysis of the social network reveals that hateful and counterhate users interact and engage extensively with one another, instead of living in isolated polarized communities. Furthermore, we find that hate is contagious and nodes are highly likely to become hateful after being exposed to hateful content. Importantly, our analysis reveals that counterhate messages can discourage users from turning hateful in the first place. Overall, this work presents a comprehensive overview of anti-Asian hate and counterhate content during a pandemic. The COVID-HATE dataset is available at this http URL.", "year": 2020, "authors": [{"authorId": "1399135100", "name": "C. Ziems"}, {"authorId": "2082464053", "name": "Bing He"}, {"authorId": "49768826", "name": "Sandeep Soni"}, {"authorId": "39703734", "name": "Srijan Kumar"}], "cluster": 24, "position": {"x": -1.2634438276290894, "y": -7.805577278137207}}, {"paperId": "995e477360908175d0b1184f6a0aace9d864bc5a", "url": "https://www.semanticscholar.org/paper/995e477360908175d0b1184f6a0aace9d864bc5a", "title": "Girls Rule, Boys Drool: Extracting Semantic and Affective Stereotypes from Twitter", "abstract": "Social identities carry widely agreed upon meanings, called stereotypes, that have important effects on social processes. In the present work, we develop a method to extract the stereotypes of Twitter users. Our method is grounded in two distinct strands of theory, one that represents stereotypes as identities' affective meanings and the other that represents stereotypes as semantic relationships between identities. After validating our approach via a prediction task, we apply the model to a dataset of 45 thousand Twitter users who actively tweeted about the Michael Brown and Eric Garner tragedies. Our work provides unique insights into the stereotypes of these users, as well as providing a way of quantifying stereotypes that blends existing sociological and psychological theory in a novel, parsimonious way.", "year": 2017, "authors": [{"authorId": "3306556", "name": "K. Joseph"}, {"authorId": "144927196", "name": "W. Wei"}, {"authorId": "1702030", "name": "Kathleen M. Carley"}], "cluster": 14, "position": {"x": 15.15845012664795, "y": 23.362932205200195}}, {"paperId": "f34c73c75a640f59c11472bf6c9786aeb774856a", "url": "https://www.semanticscholar.org/paper/f34c73c75a640f59c11472bf6c9786aeb774856a", "title": "Let's Talk About Race: Identity, Chatbots, and AI", "abstract": "Why is it so hard for chatbots to talk about race? This work explores how the biased contents of databases, the syntactic focus of natural language processing, and the opaque nature of deep learning algorithms cause chatbots difficulty in handling race-talk. In each of these areas, the tensions between race and chatbots create new opportunities for people and machines. By making the abstract and disparate qualities of this problem space tangible, we can develop chatbots that are more capable of handling race-talk in its many forms. Our goal is to provide the HCI community with ways to begin addressing the question, how can chatbots handle race-talk in new and improved ways?", "year": 2018, "authors": [{"authorId": "29847490", "name": "Ari Schlesinger"}, {"authorId": "1394341310", "name": "K. O'Hara"}, {"authorId": "1920225402", "name": "Alex S. Taylor"}], "cluster": 4, "position": {"x": -44.86068344116211, "y": 18.929235458374023}}, {"paperId": "abeee58b9fb5761133636ef117ef1a87203ad7ab", "url": "https://www.semanticscholar.org/paper/abeee58b9fb5761133636ef117ef1a87203ad7ab", "title": "Automation, Algorithms, and Politics| Talking to Bots: Symbiotic Agency and the Case of Tay", "abstract": "In 2016, Microsoft launched Tay, an experimental artificial intelligence chat bot. Learning from interactions with Twitter users, Tay was shut down after one day because of its obscene and inflammatory tweets. This article uses the case of Tay to re-examine theories of agency. How did users view the personality and actions of an artificial intelligence chat bot when interacting with Tay on Twitter? Using phenomenological research methods and pragmatic approaches to agency, we look at what people said about Tay to study how they imagine and interact with emerging technologies and to show the limitations of our current theories of agency for describing communication in these settings. We show how different qualities of agency, different expectations for technologies, and different capacities for affordance emerge in the interactions between people and artificial intelligence. We argue that a perspective of \u201csymbiotic agency\u201d\u2014informed by the imagined affordances of emerging technology\u2014is required to really understand the collapse of Tay.", "year": 2016, "authors": [{"authorId": "37998480", "name": "Gina Neff"}, {"authorId": "144210454", "name": "Peter Nagy"}], "cluster": 4, "position": {"x": -46.62623596191406, "y": 17.11880874633789}}, {"paperId": "0df347f5e3118fac7c351917e3a497899b071d1e", "url": "https://www.semanticscholar.org/paper/0df347f5e3118fac7c351917e3a497899b071d1e", "title": "Datasheets for Datasets", "abstract": "The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.", "year": 2018, "authors": [{"authorId": "2076288", "name": "Timnit Gebru"}, {"authorId": "144848816", "name": "Jamie H. Morgenstern"}, {"authorId": "40808865", "name": "Briana Vecchione"}, {"authorId": "4006636", "name": "Jennifer Wortman Vaughan"}, {"authorId": "1831395", "name": "H. Wallach"}, {"authorId": "1722360", "name": "Hal Daum\u00e9"}, {"authorId": "1810680217", "name": "Kate Crawford"}], "cluster": -1, "position": {"x": 26.118392944335938, "y": 8.943235397338867}}, {"paperId": "983ad7c704d0f9a1560af322e4807e5be7799895", "url": "https://www.semanticscholar.org/paper/983ad7c704d0f9a1560af322e4807e5be7799895", "title": "#MeToo Alexa: How Conversational Systems Respond to Sexual Harassment", "abstract": "Conversational AI systems, such as Amazon\u2019s Alexa, are rapidly developing from purely transactional systems to social chatbots, which can respond to a wide variety of user requests. In this article, we establish how current state-of-the-art conversational systems react to inappropriate requests, such as bullying and sexual harassment on the part of the user, by collecting and analysing the novel #MeTooAlexa corpus. Our results show that commercial systems mainly avoid answering, while rule-based chatbots show a variety of behaviours and often deflect. Data-driven systems, on the other hand, are often non-coherent, but also run the risk of being interpreted as flirtatious and sometimes react with counter-aggression. This includes our own system, trained on \u201cclean\u201d data, which suggests that inappropriate system behaviour is not caused by data bias.", "year": 2018, "authors": [{"authorId": "3451318", "name": "A. C. Curry"}, {"authorId": "1681799", "name": "Verena Rieser"}], "cluster": 4, "position": {"x": -43.00208282470703, "y": 18.74016571044922}}, {"paperId": "afe97d05e5b320d2af500cdae1c588f4cc0d14d2", "url": "https://www.semanticscholar.org/paper/afe97d05e5b320d2af500cdae1c588f4cc0d14d2", "title": "Towards an Ethical Framework for Publishing Twitter Data in Social Research: Taking into Account Users\u2019 Views, Online Context and Algorithmic Estimation", "abstract": "New and emerging forms of data, including posts harvested from social media sites such as Twitter, have become part of the sociologist\u2019s data diet. In particular, some researchers see an advantage in the perceived \u2018public\u2019 nature of Twitter posts, representing them in publications without seeking informed consent. While such practice may not be at odds with Twitter\u2019s terms of service, we argue there is a need to interpret these through the lens of social science research methods that imply a more reflexive ethical approach than provided in \u2018legal\u2019 accounts of the permissible use of these data in research publications. To challenge some existing practice in Twitter-based research, this article brings to the fore: (1) views of Twitter users through analysis of online survey data; (2) the effect of context collapse and online disinhibition on the behaviours of users; and (3) the publication of identifiable sensitive classifications derived from algorithms.", "year": 2017, "authors": [{"authorId": "2116741885", "name": "M. Williams"}, {"authorId": "3448243", "name": "P. Burnap"}, {"authorId": "145752168", "name": "Luke Sloan"}], "cluster": 3, "position": {"x": 35.76953125, "y": 20.79254722595215}}, {"paperId": "129cbad01be98ee88a930e31898cb76be79c41c1", "url": "https://www.semanticscholar.org/paper/129cbad01be98ee88a930e31898cb76be79c41c1", "title": "How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation", "abstract": "We investigate evaluation metrics for dialogue response generation systems where supervised labels, such as task completion, are not available. Recent works in response generation have adopted metrics from machine translation to compare a model's generated response to a single target response. We show that these metrics correlate very weakly with human judgements in the non-technical Twitter domain, and not at all in the technical Ubuntu domain. We provide quantitative and qualitative results highlighting specific weaknesses in existing metrics, and provide recommendations for future development of better automatic evaluation metrics for dialogue systems.", "year": 2016, "authors": [{"authorId": "117659895", "name": "Chiao-Wei Liu"}, {"authorId": "2054294", "name": "Ryan Lowe"}, {"authorId": "35224828", "name": "Iulian Serban"}, {"authorId": "38107789", "name": "Michael Noseworthy"}, {"authorId": "1778839", "name": "Laurent Charlin"}, {"authorId": "145134886", "name": "Joelle Pineau"}], "cluster": 4, "position": {"x": -40.942161560058594, "y": 24.663650512695312}}, {"paperId": "5f827b963939c96968a03318b4c2b011e1871eaf", "url": "https://www.semanticscholar.org/paper/5f827b963939c96968a03318b4c2b011e1871eaf", "title": "Writer Profiling Without the Writer's Text", "abstract": "Social network users may wish to preserve their anonymity online by masking their identity and not using language associated with any particular demographics or personality. However, they have no control over the language in incoming communications. We show that linguistic cues in public comments directed at a user are sufficient for an accurate inference of that user\u2019s gender, age, religion, diet, and even personality traits. Moreover, we show that directed communication is even more predictive of a user\u2019s profile than the user\u2019s own language. We then conduct a nuanced analysis of what types of social relationships are most predictive of users\u2019 attributes, and propose new strategies on how individuals can modulate their online social relationships and incoming communications to preserve their anonymity.", "year": 2017, "authors": [{"authorId": "3046220", "name": "David Jurgens"}, {"authorId": "145317727", "name": "Yulia Tsvetkov"}, {"authorId": "1746807", "name": "Dan Jurafsky"}], "cluster": 14, "position": {"x": 16.64126205444336, "y": 25.26930809020996}}, {"paperId": "f298649194c1be9cb55574c047756ae7e8a62d6b", "url": "https://www.semanticscholar.org/paper/f298649194c1be9cb55574c047756ae7e8a62d6b", "title": "\u201cParticipant\u201d Perceptions of Twitter Research Ethics", "abstract": "Social computing systems such as Twitter present new research sites that have provided billions of data points to researchers. However, the availability of public social media data has also presented ethical challenges. As the research community works to create ethical norms, we should be considering users\u2019 concerns as well. With this in mind, we report on an exploratory survey of Twitter users\u2019 perceptions of the use of tweets in research. Within our survey sample, few users were previously aware that their public tweets could be used by researchers, and the majority felt that researchers should not be able to use tweets without consent. However, we find that these attitudes are highly contextual, depending on factors such as how the research is conducted or disseminated, who is conducting it, and what the study is about. The findings of this study point to potential best practices for researchers conducting observation and analysis of public data.", "year": 2018, "authors": [{"authorId": "1844816", "name": "Casey Fiesler"}, {"authorId": "2974243", "name": "Nicholas Proferes"}], "cluster": 3, "position": {"x": 36.13111877441406, "y": 19.726322174072266}}, {"paperId": "dff6976f237ecff091547dd2df26937bd6b59198", "url": "https://www.semanticscholar.org/paper/dff6976f237ecff091547dd2df26937bd6b59198", "title": "Fifty years later: the significance of the Nuremberg Code.", "abstract": "The Nuremberg Code 1. The voluntary consent of the human subject is absolutely essential. This means that the person involved should have legal capacity to give consent; should be so situated as to be able to exercise free power of choice, without the intervention of any element of force, fraud, deceit, duress, overreaching, or other ulterior form of constraint or coercion; and should have sufficient knowledge and comprehension of the elements of the subject matter involved as to enable him to make an understanding and enlightened decision. This latter element requires that before the acceptance of an affirmative decision by .\u00a0.\u00a0.", "year": 1997, "authors": [{"authorId": "4360733", "name": "E. Shuster"}], "cluster": 16, "position": {"x": 10.809137344360352, "y": 4.423187255859375}}, {"paperId": "87eb23f934a0e6293ee8ee9b147fe0d456e65c96", "url": "https://www.semanticscholar.org/paper/87eb23f934a0e6293ee8ee9b147fe0d456e65c96", "title": "Data Statements for NLP: Toward Mitigating System Bias and Enabling Better Science", "abstract": "In this position paper, we propose data statements as a practice that NLP technologists, in both research and development, can adopt to begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations. We present a form data statements can take and explore the implications of adopting them as part of our regular practice. We argue that they will help alleviate issues related to exclusion and bias in language technology; lead to better precision in claims about how NLP research can generalize and thus better engineering results; protect companies from public embarrassment; and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.", "year": 2018, "authors": [{"authorId": "2471699", "name": "Emily M. Bender"}, {"authorId": "144029598", "name": "Batya Friedman"}], "cluster": 9, "position": {"x": -19.89776611328125, "y": 29.826047897338867}}, {"paperId": "1ece7c00d2eb6fca5443ff8e15f05a2b8b5985c2", "url": "https://www.semanticscholar.org/paper/1ece7c00d2eb6fca5443ff8e15f05a2b8b5985c2", "title": "Don\u2019t quote me: reverse identification of research participants in social media studies", "abstract": "We investigated if participants in social media surveillance studies could be reverse identified by reviewing all articles published on PubMed in 2015 or 2016 with the words \u201cTwitter\u201d and either \u201cread,\u201d \u201ccoded,\u201d or \u201ccontent\u201d in the title or abstract. Seventy-two percent (95% CI: 63\u201380) of articles quoted at least one participant\u2019s tweet and searching for the quoted content led to the participant 84% (95% CI: 74\u201391) of the time. Twenty-one percent (95% CI: 13\u201329) of articles disclosed a participant\u2019s Twitter username thereby making the participant immediately identifiable. Only one article reported obtaining consent to disclose identifying information and institutional review board (IRB) involvement was mentioned in only 40% (95% CI: 31\u201350) of articles, of which 17% (95% CI: 10\u201325) received IRB-approval and 23% (95% CI:16\u201332) were deemed exempt. Biomedical publications are routinely including identifiable information by quoting tweets or revealing usernames which, in turn, violates ICMJE ethical standards governing scientific ethics, even though said content is scientifically unnecessary. We propose that authors convey aggregate findings without revealing participants\u2019 identities, editors refuse to publish reports that reveal a participant\u2019s identity, and IRBs attend to these privacy issues when reviewing studies involving social media data. These strategies together will ensure participants are protected going forward.", "year": 2018, "authors": [{"authorId": "6359077", "name": "J. Ayers"}, {"authorId": "7665069", "name": "Theodore L. Caputi"}, {"authorId": "4317796", "name": "Camille Nebeker"}, {"authorId": "1782853", "name": "Mark Dredze"}], "cluster": 3, "position": {"x": 34.811683654785156, "y": 18.780685424804688}}, {"paperId": "221732318e3cc45aa7bc2f48435706f3e5839ddc", "url": "https://www.semanticscholar.org/paper/221732318e3cc45aa7bc2f48435706f3e5839ddc", "title": "Beyond the Belmont Principles: Ethical Challenges, Practices, and Beliefs in the Online Data Research Community", "abstract": "Pervasive information streams that document people and their routines have been a boon to social computing research. But the ethics of collecting and analyzing available&-but potentially sensitive-online data present challenges to researchers. In response to increasing public and scholarly debate over the ethics of online data research, this paper analyzes the current state of practice among researchers using online data. Qualitative and quantitative responses from a survey of 263 online data researchers document beliefs and practices around which social computing researchers are converging, as well as areas of ongoing disagreement. The survey also reveals that these disagreements are not correlated with disciplinary, methodological, or workplace affiliations. The paper concludes by reflecting on changing ethical practices in the digital age, and discusses a set of emergent best practices for ethical social computing research.", "year": 2016, "authors": [{"authorId": "2538266", "name": "Jessica Vitak"}, {"authorId": "3214594", "name": "Katie Shilton"}, {"authorId": "2220428", "name": "Zahra Ashktorab"}], "cluster": 3, "position": {"x": 37.92995071411133, "y": 19.932231903076172}}, {"paperId": "e8fa186444d98a39ee9139b1f5dd0c7618caef8f", "url": "https://www.semanticscholar.org/paper/e8fa186444d98a39ee9139b1f5dd0c7618caef8f", "title": "Privacy-preserving Neural Representations of Text", "abstract": "This article deals with adversarial attacks towards deep learning systems for Natural Language Processing (NLP), in the context of privacy protection. We study a specific type of attack: an attacker eavesdrops on the hidden representations of a neural text classifier and tries to recover information about the input text. Such scenario may arise in situations when the computation of a neural network is shared across multiple devices, e.g. some hidden representation is computed by a user\u2019s device and sent to a cloud-based model. We measure the privacy of a hidden representation by the ability of an attacker to predict accurately specific private information from it and characterize the tradeoff between the privacy and the utility of neural representations. Finally, we propose several defense methods based on modified training objectives and show that they improve the privacy of neural representations.", "year": 2018, "authors": [{"authorId": "3443469", "name": "Maximin Coavoux"}, {"authorId": "143790510", "name": "Shashi Narayan"}, {"authorId": "40146204", "name": "Shay B. Cohen"}], "cluster": 15, "position": {"x": 20.471574783325195, "y": -47.400390625}}, {"paperId": "a24d72bd0d08d515cb3e26f94131d33ad6c861db", "url": "https://www.semanticscholar.org/paper/a24d72bd0d08d515cb3e26f94131d33ad6c861db", "title": "Ethical Challenges in Data-Driven Dialogue Systems", "abstract": "The use of dialogue systems as a medium for human-machine interaction is an increasingly prevalent paradigm. A growing number of dialogue systems use conversation strategies that are learned from large datasets. There are well documented instances where interactions with these system have resulted in biased or even offensive conversations due to the data-driven training process. Here, we highlight potential ethical issues that arise in dialogue systems research, including: implicit biases in data-driven systems, the rise of adversarial examples, potential sources of privacy violations, safety concerns, special considerations for reinforcement learning systems, and reproducibility concerns. We also suggest areas stemming from these issues that deserve further investigation. Through this initial survey, we hope to spur research leading to robust, safe, and ethically sound dialogue systems.", "year": 2018, "authors": [{"authorId": "40068904", "name": "Peter Henderson"}, {"authorId": "40910779", "name": "Koustuv Sinha"}, {"authorId": "1411255298", "name": "Nicolas Angelard-Gontier"}, {"authorId": "145604319", "name": "Nan Rosemary Ke"}, {"authorId": "47001277", "name": "Genevieve Fried"}, {"authorId": "2054294", "name": "Ryan Lowe"}, {"authorId": "145134886", "name": "Joelle Pineau"}], "cluster": 4, "position": {"x": -42.872642517089844, "y": 21.959320068359375}}, {"paperId": "d47a682723f710395454687319bb55635e653105", "url": "https://www.semanticscholar.org/paper/d47a682723f710395454687319bb55635e653105", "title": "Language (Technology) is Power: A Critical Survey of \u201cBias\u201d in NLP", "abstract": "We survey 146 papers analyzing \u201cbias\u201d in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing \u201cbias\u201d is an inherently normative process. We further find that these papers\u2019 proposed quantitative techniques for measuring or mitigating \u201cbias\u201d are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing \u201cbias\u201d in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of \u201cbias\u201d---i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements\u2014and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.", "year": 2020, "authors": [{"authorId": "3422038", "name": "Su Lin Blodgett"}, {"authorId": "2881033", "name": "Solon Barocas"}, {"authorId": "2065041692", "name": "Hal Daum'e"}, {"authorId": "1831395", "name": "H. Wallach"}], "cluster": 9, "position": {"x": -19.40808868408203, "y": 30.795385360717773}}, {"paperId": "5966d7c7f60898d610812e24c64d4d57855ad86a", "url": "https://www.semanticscholar.org/paper/5966d7c7f60898d610812e24c64d4d57855ad86a", "title": "Semantics derived automatically from language corpora necessarily contain human biases", "abstract": "Artificial intelligence and machine learning are in a period of astounding growth. However, there are concerns that these technologies may be used, either with or without intention, to perpetuate the prejudice and unfairness that unfortunately characterizes many human institutions. Here we show for the first time that human-like semantic biases result from the application of standard machine learning to ordinary language---the same sort of language humans are exposed to every day. We replicate a spectrum of standard human biases as exposed by the Implicit Association Test and other well-known psychological studies. We replicate these using a widely used, purely statistical machine-learning model---namely, the GloVe word embedding---trained on a corpus of text from the Web. Our results indicate that language itself contains recoverable and accurate imprints of our historic biases, whether these are morally neutral as towards insects or flowers, problematic as towards race or gender, or even simply veridical, reflecting the status quo for the distribution of gender with respect to careers or first names. These regularities are captured by machine learning along with the rest of semantics. In addition to our empirical findings concerning language, we also contribute new methods for evaluating bias in text, the Word Embedding Association Test (WEAT) and the Word Embedding Factual Association Test (WEFAT). Our results have implications not only for AI and machine learning, but also for the fields of psychology, sociology, and human ethics, since they raise the possibility that mere exposure to everyday language can account for the biases we replicate here.", "year": 2016, "authors": [{"authorId": "144537437", "name": "Aylin Caliskan"}, {"authorId": "145315445", "name": "J. Bryson"}, {"authorId": "47735253", "name": "A. Narayanan"}], "cluster": 14, "position": {"x": 8.131874084472656, "y": 24.56338882446289}}, {"paperId": "df2df1749b93ba86328ec7b86ff7e8d30029e3f5", "url": "https://www.semanticscholar.org/paper/df2df1749b93ba86328ec7b86ff7e8d30029e3f5", "title": "Garbage in, garbage out?: do machine learning application papers in social computing report where human-labeled training data comes from?", "abstract": "Many machine learning projects for new application areas involve teams of humans who label data for a particular purpose, from hiring crowdworkers to the paper's authors labeling the data themselves. Such a task is quite similar to (or a form of) structured content analysis, which is a longstanding methodology in the social sciences and humanities, with many established best practices. In this paper, we investigate to what extent a sample of machine learning application papers in social computing --- specifically papers from ArXiv and traditional publications performing an ML classification task on Twitter data --- give specific details about whether such best practices were followed. Our team conducted multiple rounds of structured content analysis of each paper, making determinations such as: Does the paper report who the labelers were, what their qualifications were, whether they independently labeled the same items, whether inter-rater reliability metrics were disclosed, what level of training and/or instructions were given to labelers, whether compensation for crowdworkers is disclosed, and if the training data is publicly available. We find a wide divergence in whether such practices were followed and documented. Much of machine learning research and education focuses on what is done once a \"gold standard\" of training data is available, but we discuss issues around the equally-important aspect of whether such data is reliable in the first place.", "year": 2020, "authors": [{"authorId": "143984380", "name": "R. Geiger"}, {"authorId": "2114076674", "name": "Kevin Yu"}, {"authorId": "3800238", "name": "Yanlai Yang"}, {"authorId": "1468343614", "name": "Mindy Dai"}, {"authorId": "2116036625", "name": "Jie Qiu"}, {"authorId": "1468484624", "name": "Rebekah Tang"}, {"authorId": "1712271131", "name": "Jenny Huang"}], "cluster": 3, "position": {"x": 26.606582641601562, "y": 9.804553985595703}}, {"paperId": "d3aca13c966bb22eed7086baeb287a64bc18c152", "url": "https://www.semanticscholar.org/paper/d3aca13c966bb22eed7086baeb287a64bc18c152", "title": "Comparing Spoken Dialog Corpora Collected with Recruited Subjects versus Real Users", "abstract": "Empirical spoken dialog research often involves the collection and analysis of a dialog corpus. However, it is not well understood whether and how a corpus of dialogs collected using recruited subjects differs from a corpus of dialogs obtained from real users. In this paper we use Let\u2019s Go Lab, a platform for experimenting with a deployed spoken dialog bus information system, to address this question. Our first corpus is collected by recruiting subjects to call Let\u2019s Go in a standard laboratory setting, while our second corpus consists of calls from real users calling Let\u2019s Go during its operating hours. We quantitatively characterize the two collected corpora using previously proposed measures from the spoken dialog literature, then discuss the statistically significant similarities and differences between the two corpora with respect to these measures. For example, we find that recruited subjects talk more and speak faster, while real users ask for more help and more frequently interrupt the system. In contrast, we find no difference with respect to dialog structure.", "year": 2007, "authors": [{"authorId": "49317886", "name": "H. Ai"}, {"authorId": "1693369", "name": "Antoine Raux"}, {"authorId": "2314124", "name": "D. Bohus"}, {"authorId": "1716325", "name": "M. Esk\u00e9nazi"}, {"authorId": "1737616", "name": "D. Litman"}], "cluster": 4, "position": {"x": -39.9024772644043, "y": 27.068387985229492}}, {"paperId": "d08392eee17f809d32d7d37e9345383f41271164", "url": "https://www.semanticscholar.org/paper/d08392eee17f809d32d7d37e9345383f41271164", "title": "Sorting Things Out: Classification and Its Consequences", "abstract": "What do a seventeenth-century mortality table (whose causes of death include \"fainted in a bath,\" \"frighted,\" and \"itch\"); the identification of South Africans during apartheid as European, Asian, colored, or black; and the separation of machine- from hand-washables have in common? All are examples of classification -- the scaffolding of information infrastructures. In Sorting Things Out, Geoffrey C. Bowker and Susan Leigh Star explore the role of categories and standards in shaping the modern world. In a clear and lively style, they investigate a variety of classification systems, including the International Classification of Diseases, the Nursing Interventions Classification, race classification under apartheid in South Africa, and the classification of viruses and of tuberculosis. The authors emphasize the role of invisibility in the process by which classification orders human interaction. They examine how categories are made and kept invisible, and how people can change this invisibility when necessary. They also explore systems of classification as part of the built information environment. Much as an urban historian would review highway permits and zoning decisions to tell a city's story, the authors review archives of classification design to understand how decisions have been made. Sorting Things Out has a moral agenda, for each standard and category valorizes some point of view and silences another. Standards and classifications produce advantage or suffering. Jobs are made and lost; some regions benefit at the expense of others. How these choices are made and how we think about that process are at the moral and political core of this work. The book is an important empirical source for understanding the building of information infrastructures.", "year": 1999, "authors": [{"authorId": "2075941617", "name": "Geof Bowker"}, {"authorId": "1730598", "name": "S. L. Star"}], "cluster": 10, "position": {"x": -19.067996978759766, "y": 35.68737030029297}}, {"paperId": "520ec00dc35475e0554dbb72f27bd2eeb6f4191d", "url": "https://www.semanticscholar.org/paper/520ec00dc35475e0554dbb72f27bd2eeb6f4191d", "title": "The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks", "abstract": "This paper describes a testing methodology for quantitatively assessing the risk that rare or unique training-data sequences are unintentionally memorized by generative sequence models---a common type of machine-learning model. Because such models are sometimes trained on sensitive data (e.g., the text of users' private messages), this methodology can benefit privacy by allowing deep-learning practitioners to select means of training that minimize such memorization. \nIn experiments, we show that unintended memorization is a persistent, hard-to-avoid issue that can have serious consequences. Specifically, for models trained without consideration of memorization, we describe new, efficient procedures that can extract unique, secret sequences, such as credit card numbers. We show that our testing strategy is a practical and easy-to-use first line of defense, e.g., by describing its application to quantitatively limit data exposure in Google's Smart Compose, a commercial text-completion neural network trained on millions of users' email messages.", "year": 2019, "authors": [{"authorId": "2483738", "name": "Nicholas Carlini"}, {"authorId": "2118484320", "name": "Chang Liu"}, {"authorId": "1758110", "name": "\u00da. Erlingsson"}, {"authorId": "36426383", "name": "Jernej Kos"}, {"authorId": "143711382", "name": "D. Song"}], "cluster": -1, "position": {"x": 21.269115447998047, "y": -46.99687957763672}}, {"paperId": "493fac37cea49afb98c52c2f5dd75c303a325b25", "url": "https://www.semanticscholar.org/paper/493fac37cea49afb98c52c2f5dd75c303a325b25", "title": "Mitigating Gender Bias in Natural Language Processing: Literature Review", "abstract": "As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in popularity, it becomes increasingly vital to recognize the role they play in shaping societal biases and stereotypes. Although NLP models have shown success in modeling various applications, they propagate and may even amplify gender bias found in text corpora. While the study of bias in artificial intelligence is not new, methods to mitigate gender bias in NLP are relatively nascent. In this paper, we review contemporary studies on recognizing and mitigating gender bias in NLP. We discuss gender bias based on four forms of representation bias and analyze methods recognizing gender bias. Furthermore, we discuss the advantages and drawbacks of existing gender debiasing methods. Finally, we discuss future studies for recognizing and mitigating gender bias in NLP.", "year": 2019, "authors": [{"authorId": "1516120843", "name": "Tony Sun"}, {"authorId": "146072982", "name": "Andrew Gaut"}, {"authorId": "148149462", "name": "Shirlyn Tang"}, {"authorId": "48356040", "name": "Yuxin Huang"}, {"authorId": "2165346", "name": "Mai ElSherief"}, {"authorId": "33524946", "name": "Jieyu Zhao"}, {"authorId": "1705929", "name": "Diba Mirza"}, {"authorId": "1397933253", "name": "E. Belding-Royer"}, {"authorId": "2782886", "name": "Kai-Wei Chang"}, {"authorId": "1682479", "name": "William Yang Wang"}], "cluster": 14, "position": {"x": 10.197617530822754, "y": 32.18004608154297}}, {"paperId": "94cf3f2c4410fcb06a90abebd99f7113c69e1ed9", "url": "https://www.semanticscholar.org/paper/94cf3f2c4410fcb06a90abebd99f7113c69e1ed9", "title": "Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them", "abstract": "Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between \u201cgender-neutralized\u201d words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.", "year": 2019, "authors": [{"authorId": "1821892", "name": "Hila Gonen"}, {"authorId": "2089067", "name": "Y. Goldberg"}], "cluster": 14, "position": {"x": 7.385732173919678, "y": 34.67080307006836}}, {"paperId": "31a848022de5933029435a2c8304c2bd12537b0d", "url": "https://www.semanticscholar.org/paper/31a848022de5933029435a2c8304c2bd12537b0d", "title": "The trouble with using provider assessments for rating clinical performance: it's a matter of bias.", "abstract": "The International Association for the Study of Pain has referred to pain as the fifth vital sign, and acute pain management after surgery has been shown to be a key factor in quality of recovery. In addition, the establishment of pain management benchmarks by the Joint Commission on the Accreditation of Healthcare Organizations more than a decade ago has resulted in a greater awareness of patients\u2019 right to optimal pain control by health care practitioners and administrators. Postoperative pain control has become a priority for hospitals across the United States. Optimization of postoperative pain management has been demonstrated through the implementation of protocols that include multimodal analgesic regimens, surgicalspecific treatment pathways, implementation of a 24-hour anesthesiology pain service, and pain-specific training for physicians and nurses involved in postoperative care.1 Importantly, pain as assessed by the numeric rating scale (NRS), for which 0 = no pain and 10 = maximal pain, has been shown to be significantly reduced after the implementation of postoperative analgesia protocol. These data suggest that NRS pain scores might be a useful metric to evaluate the quality of anesthesia care provided after the transition from surgery to recovery. Wanderer et al.2 from the Vanderbilt University have applied this principle in a research report in the current edition of Anesthesia & Analgesia in an attempt to use rank ordering by initial postanesthesia recovery unit NRS pain scores, as collected by nurses in a clinical setting, to compare supervising anesthesiologists when adjusted for confounding factors. The analysis included 26 680 cases using electronic documentation and excluded physician and nurse providers who had not cared for \u2265100 patients. When admission postanesthesia recovery unit scores were compared among anesthesiologists after adjusting for patient and surgical factors, only 6.4% of the 69 supervising anesthesiologists were found to differ in median postanesthesia recovery room admission pain scores. This finding clearly demonstrates that as presently assessed, initial postanesthesia recovery scores are a poor metric for identifying differences among supervising anesthesiologists, and the authors correctly concluded that they should not be included in the assessment of anesthesia care performance. Interestingly, the study also found that 16 of 66 (24%) recovery room nurses elicited median pain scores less than the median value for the entire group, and 33 nurses (50%) had elicited median pain scores significantly higher than the median for the entire group. These differences translated into a range of odds ratios from 0.16 (95% confidence interval, 0.11\u20132.4) for the lowest to 2.95 (95% confidence interval, 2.43\u20133.59) for the highest nurse compared with the nurse who ranked the median value for the overall group. In fact, NRS pain assessments using the 0 to 10 NRS pain score were found to depend more on the nurse making the assessment than patient age, gender and race, preoperative use of opioids, American Society of Anesthesiologists physical status, or procedure. This finding should not be interpreted to suggest dishonest recordings of NRS values by nurses (86%\u201390% of nurses accurately record pain ratings provided by patients), but that personal opinions, knowledge, and attitudes toward pain strongly influence assessments and management.3 Wanderer et al. discuss the use of nonstandard item descriptors rather than \u201cno pain\u201d equals 0 and \u201cthe worst possible pain\u201d equals 10 as anchors for the NRS pain scales as a possible explanation for the variability in the nurse assessor\u2013recorded NRS. They cited a recent systematic review that identified 24 distinct anchoring phrases in 54 included studies.4 The use of anchors during decision making can create a form of cognitive bias because individuals tend to rely heavily on these points when making decision adjustments. Factors that have been shown to affect the influence of anchoring on decision making include happier moods and conscientious personalities, certainly desirable attributes in postanesthesia care nurses. These are factors that patients are likely to perceive, and substituting anchors could clearly influence the perceived value reported by patients.5 The method of presentation of the NRS score range by the evaluator can be used to influence the choice made by the decision maker. This method is called the framing effect and is another type of cognitive bias.6 The presenter in this situation is referred to as the choice architect. This practice is not an uncommon phenomenon when using Likert scales because the differences between scores in the range are not The Trouble with Using Provider Assessments for Rating Clinical Performance: It\u2019s a Matter of Bias", "year": 2015, "authors": [{"authorId": "143647272", "name": "R. McCarthy"}, {"authorId": "52138902", "name": "G. D. de Oliveira"}], "cluster": 5, "position": {"x": 42.702640533447266, "y": 6.144616603851318}}, {"paperId": "ccf6a69a7f33bcf052aa7def176d3b9de495beb7", "url": "https://www.semanticscholar.org/paper/ccf6a69a7f33bcf052aa7def176d3b9de495beb7", "title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings", "abstract": "The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.", "year": 2016, "authors": [{"authorId": "2843215", "name": "Tolga Bolukbasi"}, {"authorId": "2782886", "name": "Kai-Wei Chang"}, {"authorId": "145085305", "name": "James Y. Zou"}, {"authorId": "1699322", "name": "Venkatesh Saligrama"}, {"authorId": "2186481", "name": "A. Kalai"}], "cluster": 14, "position": {"x": 8.24806022644043, "y": 35.44158172607422}}, {"paperId": "9967cb4fd949039c6f04dd9f2f4c3331dbebe6f7", "url": "https://www.semanticscholar.org/paper/9967cb4fd949039c6f04dd9f2f4c3331dbebe6f7", "title": "Gender Bias in Coreference Resolution", "abstract": "We present an empirical study of gender bias in coreference resolution systems. We first introduce a novel, Winograd schema-style set of minimal pair sentences that differ only by pronoun gender. With these \u201cWinogender schemas,\u201d we evaluate and confirm systematic gender bias in three publicly-available coreference resolution systems, and correlate this bias with real-world and textual gender statistics.", "year": 2018, "authors": [{"authorId": "2034613", "name": "Rachel Rudinger"}, {"authorId": "2300343", "name": "Jason Naradowsky"}, {"authorId": "2056398837", "name": "Brian Leonard"}, {"authorId": "7536576", "name": "Benjamin Van Durme"}], "cluster": 13, "position": {"x": 24.83343505859375, "y": 43.073516845703125}}, {"paperId": "1935a5e3937753dc7db90126a221f11009c17984", "url": "https://www.semanticscholar.org/paper/1935a5e3937753dc7db90126a221f11009c17984", "title": "Algorithms of Oppression: How Search Engines Reinforce Racism", "abstract": "Read and considered thoughtfully, Safiya Umoja Noble\u2019s Algorithms of Oppression: How Search Engines Reinforce Racism is devastating. It reduces to rubble the notion that technology is neutral and ideology-free. Noble\u2019s crushing the neutrality myth does several things. First, this act lays foundations for her argument: only if you recognize and understand that technology is built with, and integrates, bias, can you then be open to her primary thesis: search engines advance discriminatory and often racist content. Second, it banishes a convenient response for many self-identified meritocratic Silicon Valley \u201cwinners\u201d and their supporters. Postreading, some individuals may retain their beliefs in a neutral and ideology-free technology in spite of the overwhelming evidence and citations Noble brings to bear. Effective countering of Noble\u2019s claims is unlikely to occur. For professionals working in technology, information, argumentation, and/or rhetorical studies, Algorithms of Oppression is refreshing. Agonistic towards structural racism and its defenses, single-minded in its evidentiary presentation, collaborative in its acknowledgement of others\u2019 scholarship and research, Noble models many academic, critical, and social moves. Technology scholars and writers will find in Algorithms of Oppression a masterful mentor text on how to be an activist researcher scholar. Noble also makes this enjoyable reading. It is uncommon to find academic books that can simultaneously be read, used, and applied by academics and non-academics alike.", "year": 2018, "authors": [{"authorId": "72273447", "name": "S. Noble"}], "cluster": 10, "position": {"x": -17.44487762451172, "y": 34.5850944519043}}, {"paperId": "0be19fd9896e5d40222c690cc3ff553adc7c0e27", "url": "https://www.semanticscholar.org/paper/0be19fd9896e5d40222c690cc3ff553adc7c0e27", "title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods", "abstract": "In this paper, we introduce a new benchmark for co-reference resolution focused on gender bias, WinoBias. Our corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a neural coreference system all link gendered pronouns to pro-stereotypical entities with higher accuracy than anti-stereotypical entities, by an average difference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation approach that, in combination with existing word-embedding debiasing techniques, removes the bias demonstrated by these systems in WinoBias without significantly affecting their performance on existing datasets.", "year": 2018, "authors": [{"authorId": "33524946", "name": "Jieyu Zhao"}, {"authorId": "1785372925", "name": "Tianlu Wang"}, {"authorId": "2064210", "name": "Mark Yatskar"}, {"authorId": "2004053", "name": "Vicente Ordonez"}, {"authorId": "2782886", "name": "Kai-Wei Chang"}], "cluster": 13, "position": {"x": 24.14696502685547, "y": 41.75789260864258}}, {"paperId": "a2ce1fb96c0b78bee18bb2cb2c3d55dc48d54cbd", "url": "https://www.semanticscholar.org/paper/a2ce1fb96c0b78bee18bb2cb2c3d55dc48d54cbd", "title": "Measuring Bias in Contextualized Word Representations", "abstract": "Contextual word embeddings such as BERT have achieved state of the art performance in numerous NLP tasks. Since they are optimized to capture the statistical properties of training data, they tend to pick up on and amplify social stereotypes present in the data as well. In this study, we (1)~propose a template-based method to quantify bias in BERT; (2)~show that this method obtains more consistent results in capturing social biases than the traditional cosine based method; and (3)~conduct a case study, evaluating gender bias in a downstream task of Gender Pronoun Resolution. Although our case study focuses on gender bias, the proposed technique is generalizable to unveiling other biases, including in multiclass settings, such as racial and religious biases.", "year": 2019, "authors": [{"authorId": "147225682", "name": "Keita Kurita"}, {"authorId": "47963068", "name": "Nidhi Vyas"}, {"authorId": "18081101", "name": "Ayush Pareek"}, {"authorId": "1690706", "name": "A. Black"}, {"authorId": "145317727", "name": "Yulia Tsvetkov"}], "cluster": 14, "position": {"x": 8.16482162475586, "y": 20.96728515625}}, {"paperId": "e85a50b523915b5fba3e3f1fdb743650f7d21bed", "url": "https://www.semanticscholar.org/paper/e85a50b523915b5fba3e3f1fdb743650f7d21bed", "title": "Women\u2019s Syntactic Resilience and Men\u2019s Grammatical Luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing", "abstract": "Several linguistic studies have shown the prevalence of various lexical and grammatical patterns in texts authored by a person of a particular gender, but models for part-of-speech tagging and dependency parsing have still not adapted to account for these differences. To address this, we annotate the Wall Street Journal part of the Penn Treebank with the gender information of the articles\u2019 authors, and build taggers and parsers trained on this data that show performance differences in text written by men and women. Further analyses reveal numerous part-of-speech tags and syntactic relations whose prediction performances benefit from the prevalence of a specific gender in the training data. The results underscore the importance of accounting for gendered differences in syntactic tasks, and outline future venues for developing more accurate taggers and parsers. We release our data to the research community.", "year": 2019, "authors": [{"authorId": "31099365", "name": "Aparna Garimella"}, {"authorId": "2271847", "name": "Carmen Banea"}, {"authorId": "144547315", "name": "E. Hovy"}, {"authorId": "145557251", "name": "Rada Mihalcea"}], "cluster": 14, "position": {"x": 16.084749221801758, "y": 33.7458381652832}}, {"paperId": "c590d2c8c2fb6ce5d32ee9165ab24171165f2b70", "url": "https://www.semanticscholar.org/paper/c590d2c8c2fb6ce5d32ee9165ab24171165f2b70", "title": "Assessing gender bias in machine translation: a case study with Google Translate", "abstract": "Recently there has been a growing concern in academia, industrial research laboratories and the mainstream commercial media about the phenomenon dubbed as machine bias , where trained statistical models\u2014unbeknownst to their creators\u2014grow to reflect controversial societal asymmetries, such as gender or racial bias. A significant number of Artificial Intelligence tools have recently been suggested to be harmfully biased toward some minority, with reports of racist criminal behavior predictors, Apple\u2019s Iphone X failing to differentiate between two distinct Asian people and the now infamous case of Google photos\u2019 mistakenly classifying black people as gorillas. Although a systematic study of such biases can be difficult, we believe that automated translation tools can be exploited through gender neutral languages to yield a window into the phenomenon of gender bias in AI. In this paper, we start with a comprehensive list of job positions from the U.S. Bureau of Labor Statistics (BLS) and used it in order to build sentences in constructions like \u201cHe/She is an Engineer\u201d (where \u201cEngineer\u201d is replaced by the job position of interest) in 12 different gender neutral languages such as Hungarian, Chinese, Yoruba, and several others. We translate these sentences into English using the Google Translate API, and collect statistics about the frequency of female, male and gender neutral pronouns in the translated output. We then show that Google Translate exhibits a strong tendency toward male defaults, in particular for fields typically associated to unbalanced gender distribution or stereotypes such as STEM (Science, Technology, Engineering and Mathematics) jobs. We ran these statistics against BLS\u2019 data for the frequency of female participation in each job position, in which we show that Google Translate fails to reproduce a real-world distribution of female workers. In summary, we provide experimental evidence that even if one does not expect in principle a 50:50 pronominal gender distribution, Google Translate yields male defaults much more frequently than what would be expected from demographic data alone. We believe that our study can shed further light on the phenomenon of machine bias and are hopeful that it will ignite a debate about the need to augment current statistical translation tools with debiasing techniques\u2014which can already be found in the scientific literature.", "year": 2019, "authors": [{"authorId": "144677268", "name": "Marcelo O. R. Prates"}, {"authorId": "144862483", "name": "Pedro H. C. Avelar"}, {"authorId": "2335532", "name": "L. Lamb"}], "cluster": 14, "position": {"x": 8.933815002441406, "y": 31.462005615234375}}, {"paperId": "0ab2fb6c850bd1c5882deb4984d37b4ccbee580c", "url": "https://www.semanticscholar.org/paper/0ab2fb6c850bd1c5882deb4984d37b4ccbee580c", "title": "Towards Understanding Gender Bias in Relation Extraction", "abstract": "Recent developments in Neural Relation Extraction (NRE) have made significant strides towards Automated Knowledge Base Construction. While much attention has been dedicated towards improvements in accuracy, there have been no attempts in the literature to evaluate social biases exhibited in NRE systems. In this paper, we create WikiGenderBias, a distantly supervised dataset composed of over 45,000 sentences including a 10% human annotated test set for the purpose of analyzing gender bias in relation extraction systems. We find that when extracting spouse-of and hypernym (i.e., occupation) relations, an NRE system performs differently when the gender of the target entity is different. However, such disparity does not appear when extracting relations such as birthDate or birthPlace. We also analyze how existing bias mitigation techniques, such as name anonymization, word embedding debiasing, and data augmentation affect the NRE system in terms of maintaining the test performance and reducing biases. Unfortunately, due to NRE models rely heavily on surface level cues, we find that existing bias mitigation approaches have a negative effect on NRE. Our analysis lays groundwork for future quantifying and mitigating bias in NRE.", "year": 2020, "authors": [{"authorId": "146072982", "name": "Andrew Gaut"}, {"authorId": "1516120843", "name": "Tony Sun"}, {"authorId": "148149462", "name": "Shirlyn Tang"}, {"authorId": "48356040", "name": "Yuxin Huang"}, {"authorId": "144130537", "name": "Jing Qian"}, {"authorId": "2165346", "name": "Mai ElSherief"}, {"authorId": "2110118965", "name": "Jieyu Zhao"}, {"authorId": "1705929", "name": "Diba Mirza"}, {"authorId": "8208963", "name": "E. Belding"}, {"authorId": "2782886", "name": "Kai-Wei Chang"}, {"authorId": "1682479", "name": "William Yang Wang"}], "cluster": 13, "position": {"x": 21.72320556640625, "y": 40.069740295410156}}, {"paperId": "5e9c85235210b59a16bdd84b444a904ae271f7e7", "url": "https://www.semanticscholar.org/paper/5e9c85235210b59a16bdd84b444a904ae271f7e7", "title": "On Measuring Social Biases in Sentence Encoders", "abstract": "The Word Embedding Association Test shows that GloVe and word2vec word embeddings exhibit human-like implicit biases based on gender, race, and other social constructs (Caliskan et al., 2017). Meanwhile, research on learning reusable text representations has begun to explore sentence-level texts, with some sentence encoders seeing enthusiastic adoption. Accordingly, we extend the Word Embedding Association Test to measure bias in sentence encoders. We then test several sentence encoders, including state-of-the-art methods such as ELMo and BERT, for the social biases studied in prior work and two important biases that are difficult or impossible to test at the word level. We observe mixed results including suspicious patterns of sensitivity that suggest the test\u2019s assumptions may not hold in general. We conclude by proposing directions for future work on measuring bias in sentence encoders.", "year": 2019, "authors": [{"authorId": "98868399", "name": "Chandler May"}, {"authorId": "144906624", "name": "Alex Wang"}, {"authorId": "88739501", "name": "Shikha Bordia"}, {"authorId": "3644767", "name": "Samuel R. Bowman"}, {"authorId": "2034613", "name": "Rachel Rudinger"}], "cluster": 14, "position": {"x": 5.423303604125977, "y": 21.290699005126953}}, {"paperId": "039b1c1210c437f3b3ce6e0275ee2137bf5b951c", "url": "https://www.semanticscholar.org/paper/039b1c1210c437f3b3ce6e0275ee2137bf5b951c", "title": "Assessing Social and Intersectional Biases in Contextualized Word Representations", "abstract": "Social bias in machine learning has drawn significant attention, with work ranging from demonstrations of bias in a multitude of applications, curating definitions of fairness for different contexts, to developing algorithms to mitigate bias. In natural language processing, gender bias has been shown to exist in context-free word embeddings. Recently, contextual word representations have outperformed word embeddings in several downstream NLP tasks. These word representations are conditioned on their context within a sentence, and can also be used to encode the entire sentence. In this paper, we analyze the extent to which state-of-the-art models for contextual word representations, such as BERT and GPT-2, encode biases with respect to gender, race, and intersectional identities. Towards this, we propose assessing bias at the contextual word level. This novel approach captures the contextual effects of bias missing in context-free word embeddings, yet avoids confounding effects that underestimate bias at the sentence encoding level. We demonstrate evidence of bias at the corpus level, find varying evidence of bias in embedding association tests, show in particular that racial bias is strongly encoded in contextual word models, and observe that bias effects for intersectional minorities are exacerbated beyond their constituent minority identities. Further, evaluating bias effects at the contextual word level captures biases that are not captured at the sentence level, confirming the need for our novel approach.", "year": 2019, "authors": [{"authorId": "144787248", "name": "Y. Tan"}, {"authorId": "144776615", "name": "L. E. Celis"}], "cluster": 14, "position": {"x": 7.285807132720947, "y": 22.36878776550293}}, {"paperId": "3259d52ae00e65b98391e7e6a2f672dfee721bf8", "url": "https://www.semanticscholar.org/paper/3259d52ae00e65b98391e7e6a2f672dfee721bf8", "title": "Quantifying Social Biases in Contextual Word Representations", "abstract": "Contextual word embeddings such as BERT have achieved state of the art performance in numerous NLP tasks. Since they are optimized to capture the statistical properties of training data, they tend to pick up on and amplify social stereotypes present in the data as well. In this study, we (1) propose a template-based method to quantify bias in BERT; (2) show that this method obtains more consistent results in capturing social biases than the traditional cosine based method; and (3) conduct a case study, evaluating gender bias in a downstream task of Gender Pronoun Resolution. Although our case study focuses on gender bias, the proposed technique is generalizable to unveiling other biases, including in multiclass settings, such as racial and religious biases.", "year": 2019, "authors": [{"authorId": "147225682", "name": "Keita Kurita"}, {"authorId": "47963068", "name": "Nidhi Vyas"}, {"authorId": "18081101", "name": "Ayush Pareek"}, {"authorId": "1690706", "name": "A. Black"}, {"authorId": "145317727", "name": "Yulia Tsvetkov"}], "cluster": 14, "position": {"x": 9.078545570373535, "y": 21.438690185546875}}, {"paperId": "008e9001ea78e9654b5c43aeb818ea6cb06ea934", "url": "https://www.semanticscholar.org/paper/008e9001ea78e9654b5c43aeb818ea6cb06ea934", "title": "Automatically Identifying Gender Issues in Machine Translation using Perturbations", "abstract": "The successful application of neural methods to machine translation has realized huge quality advances for the community. With these improvements, many have noted outstanding challenges, including the modeling and treatment of gendered language. While previous studies have identified issues using synthetic examples, we develop a novel technique to mine examples from real world data to explore challenges for deployed systems. We use our method to compile an evaluation benchmark spanning examples for four languages from three language families, which we publicly release to facilitate research. The examples in our benchmark expose where model representations are gendered, and the unintended consequences these gendered representations can have in downstream application.", "year": 2020, "authors": [{"authorId": "1821892", "name": "Hila Gonen"}, {"authorId": "20825661", "name": "Kellie Webster"}], "cluster": 11, "position": {"x": -4.017476558685303, "y": 26.99178695678711}}, {"paperId": "40a6e8d8f253882c585f163b7333842d60ed6f14", "url": "https://www.semanticscholar.org/paper/40a6e8d8f253882c585f163b7333842d60ed6f14", "title": "Toward Gender-Inclusive Coreference Resolution", "abstract": "Correctly resolving textual mentions of people fundamentally entails making inferences about those people. Such inferences raise the risk of systemic biases in coreference resolution systems, including biases that can harm binary and non-binary trans and cis stakeholders. To better understand such biases, we foreground nuanced conceptualizations of gender from sociology and sociolinguistics, and develop two new datasets for interrogating bias in crowd annotations and in existing coreference resolution systems. Through these studies, conducted on English text, we confirm that without acknowledging and building systems that recognize the complexity of gender, we build systems that lead to many potential harms.", "year": 2020, "authors": [{"authorId": "48696491", "name": "Yang Trista Cao"}, {"authorId": "1722360", "name": "Hal Daum\u00e9"}], "cluster": 13, "position": {"x": 25.2761173248291, "y": 44.18788528442383}}, {"paperId": "5d4af8c9321168f9ba7a501f33fb019fa2deaa22", "url": "https://www.semanticscholar.org/paper/5d4af8c9321168f9ba7a501f33fb019fa2deaa22", "title": "Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems", "abstract": "Automatic machine learning systems can inadvertently accentuate and perpetuate inappropriate human biases. Past work on examining inappropriate biases has largely focused on just individual systems. Further, there is no benchmark dataset for examining inappropriate biases in systems. Here for the first time, we present the Equity Evaluation Corpus (EEC), which consists of 8,640 English sentences carefully chosen to tease out biases towards certain races and genders. We use the dataset to examine 219 automatic sentiment analysis systems that took part in a recent shared task, SemEval-2018 Task 1 \u2018Affect in Tweets\u2019. We find that several of the systems show statistically significant bias; that is, they consistently provide slightly higher sentiment intensity predictions for one race or one gender. We make the EEC freely available.", "year": 2018, "authors": [{"authorId": "2886725", "name": "Svetlana Kiritchenko"}, {"authorId": "143880621", "name": "Saif M. Mohammad"}], "cluster": 14, "position": {"x": 8.358948707580566, "y": 28.70608139038086}}, {"paperId": "0f4bcebc95548a7286106b67bf1115802f093469", "url": "https://www.semanticscholar.org/paper/0f4bcebc95548a7286106b67bf1115802f093469", "title": "Mitigating Gender Bias Amplification in Distribution by Posterior Regularization", "abstract": "Advanced machine learning techniques have boosted the performance of natural language processing. Nevertheless, recent studies, e.g., (CITATION) show that these techniques inadvertently capture the societal bias hidden in the corpus and further amplify it. However, their analysis is conducted only on models\u2019 top predictions. In this paper, we investigate the gender bias amplification issue from the distribution perspective and demonstrate that the bias is amplified in the view of predicted probability distribution over labels. We further propose a bias mitigation approach based on posterior regularization. With little performance loss, our method can almost remove the bias amplification in the distribution. Our study sheds the light on understanding the bias amplification.", "year": 2020, "authors": [{"authorId": "1693706507", "name": "Shengyu Jia"}, {"authorId": "2056088060", "name": "Tao Meng"}, {"authorId": "33524946", "name": "Jieyu Zhao"}, {"authorId": "2782886", "name": "Kai-Wei Chang"}], "cluster": 14, "position": {"x": 9.216482162475586, "y": 40.405296325683594}}, {"paperId": "57032c1e327c88a53ab41c17e91bf1406f9ef5c9", "url": "https://www.semanticscholar.org/paper/57032c1e327c88a53ab41c17e91bf1406f9ef5c9", "title": "Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns", "abstract": "Coreference resolution is an important task for natural language understanding, and the resolution of ambiguous pronouns a longstanding challenge. Nonetheless, existing corpora do not capture ambiguous pronouns in sufficient volume or diversity to accurately indicate the practical utility of models. Furthermore, we find gender bias in existing corpora and systems favoring masculine entities. To address this, we present and release GAP, a gender-balanced labeled corpus of 8,908 ambiguous pronoun\u2013name pairs sampled to provide diverse coverage of challenges posed by real-world text. We explore a range of baselines that demonstrate the complexity of the challenge, the best achieving just 66.9% F1. We show that syntactic structure and continuous neural models provide promising, complementary cues for approaching the challenge.", "year": 2018, "authors": [{"authorId": "20825661", "name": "Kellie Webster"}, {"authorId": "144409897", "name": "Marta Recasens"}, {"authorId": "82840075", "name": "Vera Axelrod"}, {"authorId": "1387994164", "name": "Jason Baldridge"}], "cluster": 13, "position": {"x": 25.523466110229492, "y": 41.22298049926758}}, {"paperId": "00059087c954c1af6ece33115315e3e0ecc2f2c2", "url": "https://www.semanticscholar.org/paper/00059087c954c1af6ece33115315e3e0ecc2f2c2", "title": "Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem", "abstract": "Training data for NLP tasks often exhibits gender bias in that fewer sentences refer to women than to men. In Neural Machine Translation (NMT) gender bias has been shown to reduce translation quality, particularly when the target language has grammatical gender. The recent WinoMT challenge set allows us to measure this effect directly (Stanovsky et al, 2019) Ideally we would reduce system bias by simply debiasing all data prior to training, but achieving this effectively is itself a challenge. Rather than attempt to create a \u2018balanced\u2019 dataset, we use transfer learning on a small set of trusted, gender-balanced examples. This approach gives strong and consistent improvements in gender debiasing with much less computational cost than training from scratch. A known pitfall of transfer learning on new domains is \u2018catastrophic forgetting\u2019, which we address at adaptation and inference time. During adaptation we show that Elastic Weight Consolidation allows a performance trade-off between general translation quality and bias reduction. At inference time we propose a lattice-rescoring scheme which outperforms all systems evaluated in Stanovsky et al, 2019 on WinoMT with no degradation of general test set BLEU. We demonstrate our approach translating from English into three languages with varied linguistic properties and data availability.", "year": 2020, "authors": [{"authorId": "38635490", "name": "Danielle Saunders"}, {"authorId": "36126076", "name": "B. Byrne"}], "cluster": 11, "position": {"x": -3.4585635662078857, "y": 27.745460510253906}}, {"paperId": "7a4f3a0cfc0cc2aafa4ed1a2924380e82d5e3e4c", "url": "https://www.semanticscholar.org/paper/7a4f3a0cfc0cc2aafa4ed1a2924380e82d5e3e4c", "title": "Demographic Dialectal Variation in Social Media: A Case Study of African-American English", "abstract": "Though dialectal language is increasingly abundant on social media, few resources exist for developing NLP tools to handle such language. We conduct a case study of dialectal language in online conversational text by investigating African-American English (AAE) on Twitter. We propose a distantly supervised model to identify AAE-like language from demographics associated with geo-located messages, and we verify that this language follows well-known AAE linguistic phenomena. In addition, we analyze the quality of existing language identification and dependency parsing tools on AAE-like text, demonstrating that they perform poorly on such text compared to text associated with white speakers. We also provide an ensemble classifier for language identification which eliminates this disparity and release a new corpus of tweets containing AAE-like language.", "year": 2016, "authors": [{"authorId": "3422038", "name": "Su Lin Blodgett"}, {"authorId": "32446207", "name": "L. Green"}, {"authorId": "153724741", "name": "Brendan T. O'Connor"}], "cluster": 4, "position": {"x": -34.48352813720703, "y": 32.661617279052734}}, {"paperId": "a24d72bd0d08d515cb3e26f94131d33ad6c861db", "url": "https://www.semanticscholar.org/paper/a24d72bd0d08d515cb3e26f94131d33ad6c861db", "title": "Ethical Challenges in Data-Driven Dialogue Systems", "abstract": "The use of dialogue systems as a medium for human-machine interaction is an increasingly prevalent paradigm. A growing number of dialogue systems use conversation strategies that are learned from large datasets. There are well documented instances where interactions with these system have resulted in biased or even offensive conversations due to the data-driven training process. Here, we highlight potential ethical issues that arise in dialogue systems research, including: implicit biases in data-driven systems, the rise of adversarial examples, potential sources of privacy violations, safety concerns, special considerations for reinforcement learning systems, and reproducibility concerns. We also suggest areas stemming from these issues that deserve further investigation. Through this initial survey, we hope to spur research leading to robust, safe, and ethically sound dialogue systems.", "year": 2018, "authors": [{"authorId": "40068904", "name": "Peter Henderson"}, {"authorId": "40910779", "name": "Koustuv Sinha"}, {"authorId": "1411255298", "name": "Nicolas Angelard-Gontier"}, {"authorId": "145604319", "name": "Nan Rosemary Ke"}, {"authorId": "47001277", "name": "Genevieve Fried"}, {"authorId": "2054294", "name": "Ryan Lowe"}, {"authorId": "145134886", "name": "Joelle Pineau"}], "cluster": 4, "position": {"x": -41.67522048950195, "y": 21.438154220581055}}, {"paperId": "219b7266ae848937da170c5510b2bfc66d17859a", "url": "https://www.semanticscholar.org/paper/219b7266ae848937da170c5510b2bfc66d17859a", "title": "Racial disparities in automated speech recognition", "abstract": "Significance Automated speech recognition (ASR) systems are now used in a variety of applications to convert spoken language to text, from virtual assistants, to closed captioning, to hands-free computing. By analyzing a large corpus of sociolinguistic interviews with white and African American speakers, we demonstrate large racial disparities in the performance of five popular commercial ASR systems. Our results point to hurdles faced by African Americans in using increasingly widespread tools driven by speech recognition technology. More generally, our work illustrates the need to audit emerging machine-learning systems to ensure they are broadly inclusive. Automated speech recognition (ASR) systems, which use sophisticated machine-learning algorithms to convert spoken language to text, have become increasingly widespread, powering popular virtual assistants, facilitating automated closed captioning, and enabling digital dictation platforms for health care. Over the last several years, the quality of these systems has dramatically improved, due both to advances in deep learning and to the collection of large-scale datasets used to train the systems. There is concern, however, that these tools do not work equally well for all subgroups of the population. Here, we examine the ability of five state-of-the-art ASR systems\u2014developed by Amazon, Apple, Google, IBM, and Microsoft\u2014to transcribe structured interviews conducted with 42 white speakers and 73 black speakers. In total, this corpus spans five US cities and consists of 19.8 h of audio matched on the age and gender of the speaker. We found that all five ASR systems exhibited substantial racial disparities, with an average word error rate (WER) of 0.35 for black speakers compared with 0.19 for white speakers. We trace these disparities to the underlying acoustic models used by the ASR systems as the race gap was equally large on a subset of identical phrases spoken by black and white individuals in our corpus. We conclude by proposing strategies\u2014such as using more diverse training datasets that include African American Vernacular English\u2014to reduce these performance differences and ensure speech recognition technology is inclusive.", "year": 2020, "authors": [{"authorId": "101883616", "name": "Allison Koenecke"}, {"authorId": "41127369", "name": "A. Nam"}, {"authorId": "145729503", "name": "Emily Lake"}, {"authorId": "1589493589", "name": "Joe Nudell"}, {"authorId": "113762868", "name": "Minnie Quartey"}, {"authorId": "102794367", "name": "Zion Mengesha"}, {"authorId": "1589437057", "name": "Connor Toups"}, {"authorId": "2064764701", "name": "J. Rickford"}, {"authorId": "1746807", "name": "Dan Jurafsky"}, {"authorId": "143802734", "name": "Sharad Goel"}], "cluster": 4, "position": {"x": -38.22742462158203, "y": 30.36246109008789}}, {"paperId": "1080dc00733e010fdd6a9b999506a0d4d864519d", "url": "https://www.semanticscholar.org/paper/1080dc00733e010fdd6a9b999506a0d4d864519d", "title": "Effects of Talker Dialect, Gender & Race on Accuracy of Bing Speech and YouTube Automatic Captions", "abstract": "This project compares the accuracy of two automatic speech recognition (ASR) systems\u2013Bing Speech and YouTube\u2019s automatic captions\u2013across gender, race and four dialects of American English. The dialects included were chosen for their acoustic dissimilarity. Bing Speech had differences in word error rate (WER) between dialects and ethnicities, but they were not statistically reliable. YouTube\u2019s automatic captions, however, did have statistically different WERs between dialects and races. The lowest average error rates were for General American and white talkers, respectively. Neither system had a reliably different WER between genders, which had been previously reported for YouTube\u2019s automatic captions [1]. However, the higher error rate non-white talkers is worrying, as it may reduce the utility of these systems for talkers of color.", "year": 2017, "authors": [{"authorId": "3421442", "name": "Rachael Tatman"}, {"authorId": "32423353", "name": "C. Kasten"}], "cluster": 4, "position": {"x": -38.686214447021484, "y": 29.350994110107422}}, {"paperId": "a20ecabd83e0962329448d8af5025b8061c4ba36", "url": "https://www.semanticscholar.org/paper/a20ecabd83e0962329448d8af5025b8061c4ba36", "title": "Social Bias in Elicited Natural Language Inferences", "abstract": "We analyze the Stanford Natural Language Inference (SNLI) corpus in an investigation of bias and stereotyping in NLP data. The SNLI human-elicitation protocol makes it prone to amplifying bias and stereotypical associations, which we demonstrate statistically (using pointwise mutual information) and with qualitative examples.", "year": 2017, "authors": [{"authorId": "2034613", "name": "Rachel Rudinger"}, {"authorId": "98868399", "name": "Chandler May"}, {"authorId": "7536576", "name": "Benjamin Van Durme"}], "cluster": 14, "position": {"x": 12.514845848083496, "y": 20.380159378051758}}, {"paperId": "7b8318894cbeca32f1ae55780a0903445a3f4ac6", "url": "https://www.semanticscholar.org/paper/7b8318894cbeca32f1ae55780a0903445a3f4ac6", "title": "Man is to Person as Woman is to Location: Measuring Gender Bias in Named Entity Recognition", "abstract": "In this paper, we study the bias in named entity recognition (NER) models---specifically, the difference in the ability to recognize male and female names as PERSON entity types. We evaluate NER models on a dataset containing 139 years of U.S. census baby names and find that relatively more female names, as opposed to male names, are not recognized as PERSON entities. The result of this analysis yields a new benchmark for gender bias evaluation in named entity recognition systems. The data and code for the application of this benchmark is publicly available for researchers to use.", "year": 2020, "authors": [{"authorId": "51997673", "name": "Ninareh Mehrabi"}, {"authorId": "145845766", "name": "Thamme Gowda"}, {"authorId": "2775559", "name": "Fred Morstatter"}, {"authorId": "3157053", "name": "Nanyun Peng"}, {"authorId": "143728483", "name": "A. Galstyan"}], "cluster": 13, "position": {"x": 20.412111282348633, "y": 39.08413314819336}}, {"paperId": "3cc2f69951cd24fe61be4cf32d62afbac297bc2b", "url": "https://www.semanticscholar.org/paper/3cc2f69951cd24fe61be4cf32d62afbac297bc2b", "title": "Social Biases in NLP Models as Barriers for Persons with Disabilities", "abstract": "Building equitable and inclusive NLP technologies demands consideration of whether and how social attitudes are represented in ML models. In particular, representations encoded in models often inadvertently perpetuate undesirable social biases from the data on which they are trained. In this paper, we present evidence of such undesirable biases towards mentions of disability in two different English language models: toxicity prediction and sentiment analysis. Next, we demonstrate that the neural embeddings that are the critical first step in most NLP pipelines similarly contain undesirable biases towards mentions of disability. We end by highlighting topical biases in the discourse about disability which may contribute to the observed model biases; for instance, gun violence, homelessness, and drug addiction are over-represented in texts discussing mental illness.", "year": 2020, "authors": [{"authorId": "2083807", "name": "B. Hutchinson"}, {"authorId": "3331141", "name": "Vinodkumar Prabhakaran"}, {"authorId": "40081727", "name": "Emily L. Denton"}, {"authorId": "20825661", "name": "Kellie Webster"}, {"authorId": "2112887022", "name": "Yu Zhong"}, {"authorId": "1667883461", "name": "Stephen Denuyl"}], "cluster": 14, "position": {"x": 5.539798736572266, "y": 25.1195068359375}}, {"paperId": "59e94c9f21937643678ff494901f3d8b22af4e2f", "url": "https://www.semanticscholar.org/paper/59e94c9f21937643678ff494901f3d8b22af4e2f", "title": "Racial Disparity in Natural Language Processing: A Case Study of Social Media African-American English", "abstract": "We highlight an important frontier in algorithmic fairness: disparity in the quality of natural language processing algorithms when applied to language from authors of different social groups. For example, current systems sometimes analyze the language of females and minorities more poorly than they do of whites and males. We conduct an empirical analysis of racial disparity in language identification for tweets written in African-American English, and discuss implications of disparity in NLP.", "year": 2017, "authors": [{"authorId": "3422038", "name": "Su Lin Blodgett"}, {"authorId": "153724741", "name": "Brendan T. O'Connor"}], "cluster": 4, "position": {"x": -35.474876403808594, "y": 32.55988311767578}}, {"paperId": "8417424bf9fe7a67f06f15c487403e953ab24a96", "url": "https://www.semanticscholar.org/paper/8417424bf9fe7a67f06f15c487403e953ab24a96", "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints", "abstract": "Language is increasingly being used to de-fine rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. In this work, we study data and models associated with multilabel object classification and visual semantic role labeling. We find that (a) datasets for these tasks contain significant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33% more likely to involve females than males in a training set, and a trained model further amplifies the disparity to 68% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 47.5% and 40.5% for multilabel classification and visual semantic role labeling, respectively\u3002", "year": 2017, "authors": [{"authorId": "33524946", "name": "Jieyu Zhao"}, {"authorId": "1785372925", "name": "Tianlu Wang"}, {"authorId": "2064210", "name": "Mark Yatskar"}, {"authorId": "2004053", "name": "Vicente Ordonez"}, {"authorId": "2782886", "name": "Kai-Wei Chang"}], "cluster": 14, "position": {"x": 9.361470222473145, "y": 42.00199890136719}}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "url": "https://www.semanticscholar.org/paper/d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP", "abstract": "Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.", "year": 2019, "authors": [{"authorId": "2268272", "name": "Emma Strubell"}, {"authorId": "47079359", "name": "Ananya Ganesh"}, {"authorId": "143753639", "name": "A. McCallum"}], "cluster": 8, "position": {"x": -34.3682746887207, "y": -20.84988784790039}}, {"paperId": "6d9727f1f058614cada3fe296eeebd8ec4fc512a", "url": "https://www.semanticscholar.org/paper/6d9727f1f058614cada3fe296eeebd8ec4fc512a", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c", "abstract": "The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.", "year": 2021, "authors": [{"authorId": "2471699", "name": "Emily M. Bender"}, {"authorId": "2076288", "name": "Timnit Gebru"}, {"authorId": "1584940075", "name": "Angelina McMillan-Major"}, {"authorId": "2051526200", "name": "Shmargaret Shmitchell"}], "cluster": 8, "position": {"x": -34.05990219116211, "y": -18.881776809692383}}, {"paperId": "fb73b93de3734a996829caf31e4310e0054e9c6b", "url": "https://www.semanticscholar.org/paper/fb73b93de3734a996829caf31e4310e0054e9c6b", "title": "Green AI", "abstract": "Creating efficiency in AI research will decrease its carbon footprint and increase its inclusivity as deep learning study should not require the deepest pockets.", "year": 2020, "authors": [{"authorId": "4671928", "name": "Roy Schwartz"}, {"authorId": "34176020", "name": "Jesse Dodge"}, {"authorId": "2116830388", "name": "Noah Smith"}, {"authorId": "1741101", "name": "Oren Etzioni"}], "cluster": 8, "position": {"x": -35.78632354736328, "y": -22.59843635559082}}, {"paperId": "21e59098bb5e36175f653d5142442d061669d07f", "url": "https://www.semanticscholar.org/paper/21e59098bb5e36175f653d5142442d061669d07f", "title": "Race as a Bundle of Sticks: Designs that Estimate Effects of Seemingly Immutable Characteristics", "abstract": "Although understanding the role of race, ethnicity, and identity is central to political science, methodological debates persist about whether it is possible to estimate the effect of something immutable. At the heart of the debate is an older theoretical question: Is race best understood under an essentialist or constructivist framework? In contrast to the \u201cimmutable characteristics\u201d or essentialist approach, we argue that race should be operationalized as a \u201cbundle of sticks\u201d that can be disaggregated into elements. With elements of race, causal claims may be possible using two designs: (a) studies that measure the effect of exposure to a racial cue and (b) studies that exploit within-group variation to measure the effect of some manipulable element. These designs can reconcile scholarship on race and causation and offer a clear framework for future research.", "year": 2016, "authors": [{"authorId": "34435183", "name": "M. Sen"}, {"authorId": "117054289", "name": "Omar Wasow"}], "cluster": 14, "position": {"x": -0.4966946840286255, "y": 38.51373291015625}}, {"paperId": "52a14b391f994d83759787500a9bda865acdb3c5", "url": "https://www.semanticscholar.org/paper/52a14b391f994d83759787500a9bda865acdb3c5", "title": "Recommender systems and their ethical challenges", "abstract": "This article presents the first, systematic analysis of the ethical challenges posed by recommender systems through a literature review. The article identifies six areas of concern, and maps them onto a proposed taxonomy of different kinds of ethical impact. The analysis uncovers a gap in the literature: currently user-centred approaches do not consider the interests of a variety of other stakeholders\u2014as opposed to just the receivers of a recommendation\u2014in assessing the ethical impacts of a recommender system.", "year": 2020, "authors": [{"authorId": "103705266", "name": "S. Milano"}, {"authorId": "2084659", "name": "Mariarosaria Taddeo"}, {"authorId": "1982425", "name": "L. Floridi"}], "cluster": 3, "position": {"x": 39.742496490478516, "y": 18.83700942993164}}, {"paperId": "10391eed628dfece8a9136f76c5df53b5704422d", "url": "https://www.semanticscholar.org/paper/10391eed628dfece8a9136f76c5df53b5704422d", "title": "Social Chemistry 101: Learning to Reason about Social and Moral Norms", "abstract": "Social norms---the unspoken commonsense rules about acceptable social behavior---are crucial in understanding the underlying causes and intents of people's actions in narratives. For example, underlying an action such as \"wanting to call cops on my neighbors\" are social norms that inform our conduct, such as \"It is expected that you report crimes.\" \nWe present Social Chemistry, a new conceptual formalism to study people's everyday social norms and moral judgments over a rich spectrum of real life situations described in natural language. We introduce Social-Chem-101, a large-scale corpus that catalogs 292k rules-of-thumb such as \"it is rude to run a blender at 5am\" as the basic conceptual units. Each rule-of-thumb is further broken down with 12 different dimensions of people's judgments, including social judgments of good and bad, moral foundations, expected cultural pressure, and assumed legality, which together amount to over 4.5 million annotations of categorical labels and free-text descriptions. \nComprehensive empirical results based on state-of-the-art neural models demonstrate that computational modeling of social norms is a promising research direction. Our model framework, Neural Norm Transformer, learns and generalizes Social-Chem-101 to successfully reason about previously unseen situations, generating relevant (and potentially novel) attribute-aware social rules-of-thumb.", "year": 2020, "authors": [{"authorId": "39191185", "name": "Maxwell Forbes"}, {"authorId": "2012510", "name": "Jena D. Hwang"}, {"authorId": "3103343", "name": "Vered Shwartz"}, {"authorId": "2729164", "name": "Maarten Sap"}, {"authorId": "1699545", "name": "Yejin Choi"}], "cluster": 16, "position": {"x": 10.8031005859375, "y": 7.175267219543457}}, {"paperId": "13f25c69973373e616c48688d06a6b6ae2736ef0", "url": "https://www.semanticscholar.org/paper/13f25c69973373e616c48688d06a6b6ae2736ef0", "title": "Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning", "abstract": "Accurate reporting of energy and carbon usage is essential for understanding the potential climate impacts of machine learning research. We introduce a framework that makes this easier by providing a simple interface for tracking realtime energy consumption and carbon emissions, as well as generating standardized online appendices. Utilizing this framework, we create a leaderboard for energy efficient reinforcement learning algorithms to incentivize responsible research in this area as an example for other areas of machine learning. Finally, based on case studies using our framework, we propose strategies for mitigation of carbon emissions and reduction of energy consumption. By making accounting easier, we hope to further the sustainable development of machine learning experiments and spur more research into energy efficient algorithms.", "year": 2020, "authors": [{"authorId": "40068904", "name": "Peter Henderson"}, {"authorId": "2112348666", "name": "Jieru Hu"}, {"authorId": "8365320", "name": "Joshua Romoff"}, {"authorId": "2563117", "name": "Emma Brunskill"}, {"authorId": "1746807", "name": "Dan Jurafsky"}, {"authorId": "145134886", "name": "Joelle Pineau"}], "cluster": 8, "position": {"x": -34.26314163208008, "y": -22.821609497070312}}, {"paperId": "187608bf94b2dccd25d1266ed925abf7b55dbb2e", "url": "https://www.semanticscholar.org/paper/187608bf94b2dccd25d1266ed925abf7b55dbb2e", "title": "Re-imagining Algorithmic Fairness in India and Beyond", "abstract": "Conventional algorithmic fairness is West-centric, as seen in its subgroups, values, and methods. In this paper, we de-center algorithmic fairness and analyse AI power in India. Based on 36 qualitative interviews and a discourse analysis of algorithmic deployments in India, we find that several assumptions of algorithmic fairness are challenged. We find that in India, data is not always reliable due to socio-economic factors, ML makers appear to follow double standards, and AI evokes unquestioning aspiration. We contend that localising model fairness alone can be window dressing in India, where the distance between models and oppressed communities is large. Instead, we re-imagine algorithmic fairness in India and provide a roadmap to re-contextualise data and models, empower oppressed communities, and enable Fair-ML ecosystems.", "year": 2021, "authors": [{"authorId": "3283026", "name": "Nithya Sambasivan"}, {"authorId": "2032219854", "name": "Erin Arnesen"}, {"authorId": "2083807", "name": "B. Hutchinson"}, {"authorId": "2155007", "name": "T. Doshi"}, {"authorId": "3331141", "name": "Vinodkumar Prabhakaran"}], "cluster": 10, "position": {"x": -16.077346801757812, "y": 35.62035369873047}}, {"paperId": "8763723e27cc1d4aad166b5e1d9cb0fc8c8043dd", "url": "https://www.semanticscholar.org/paper/8763723e27cc1d4aad166b5e1d9cb0fc8c8043dd", "title": "Participatory Problem Formulation for Fairer Machine Learning Through Community Based System Dynamics", "abstract": "Recent research on algorithmic fairness has highlighted that the problem formulation phase of ML system development can be a key source of bias that has significant downstream impacts on ML system fairness outcomes. However, very little attention has been paid to methods for improving the fairness efficacy of this critical phase of ML system development. Current practice neither accounts for the dynamic complexity of high-stakes domains nor incorporates the perspectives of vulnerable stakeholders. In this paper we introduce community based system dynamics (CBSD) as an approach to enable the participation of typically excluded stakeholders in the problem formulation phase of the ML system development process and facilitate the deep problem understanding required to mitigate bias during this crucial stage.", "year": 2020, "authors": [{"authorId": "2110495186", "name": "Donald Martin"}, {"authorId": "2007375202", "name": "V. Prabhakaran"}, {"authorId": "5066125", "name": "Jill A. Kuhlberg"}, {"authorId": "152735378", "name": "A. Smart"}, {"authorId": "103087275", "name": "William S. Isaac"}], "cluster": 10, "position": {"x": -14.989895820617676, "y": 36.20085144042969}}, {"paperId": "2a1573cfa29a426c695e2caf6de0167a12b788ef", "url": "https://www.semanticscholar.org/paper/2a1573cfa29a426c695e2caf6de0167a12b788ef", "title": "Open Problems in Cooperative AI", "abstract": "Problems of cooperation--in which agents seek ways to jointly improve their welfare--are ubiquitous and important. They can be found at scales ranging from our daily routines--such as driving on highways, scheduling meetings, and working collaboratively--to our global challenges--such as peace, commerce, and pandemic preparedness. Arguably, the success of the human species is rooted in our ability to cooperate. Since machines powered by artificial intelligence are playing an ever greater role in our lives, it will be important to equip them with the capabilities necessary to cooperate and to foster cooperation. \nWe see an opportunity for the field of artificial intelligence to explicitly focus effort on this class of problems, which we term Cooperative AI. The objective of this research would be to study the many aspects of the problems of cooperation and to innovate in AI to contribute to solving these problems. Central goals include building machine agents with the capabilities needed for cooperation, building tools to foster cooperation in populations of (machine and/or human) agents, and otherwise conducting AI research for insight relevant to problems of cooperation. This research integrates ongoing work on multi-agent systems, game theory and social choice, human-machine interaction and alignment, natural-language processing, and the construction of social tools and platforms. However, Cooperative AI is not the union of these existing areas, but rather an independent bet about the productivity of specific kinds of conversations that involve these and other areas. We see opportunity to more explicitly focus on the problem of cooperation, to construct unified theory and vocabulary, and to build bridges with adjacent communities working on cooperation, including in the natural, social, and behavioural sciences.", "year": 2020, "authors": [{"authorId": "3198576", "name": "A. Dafoe"}, {"authorId": "37591038", "name": "Edward Hughes"}, {"authorId": "1698412", "name": "Yoram Bachrach"}, {"authorId": "2059467919", "name": "Tantum Collins"}, {"authorId": "47610458", "name": "Kevin R. McKee"}, {"authorId": "1700356", "name": "Joel Z. Leibo"}, {"authorId": "144652297", "name": "K. Larson"}, {"authorId": "1686971", "name": "T. Graepel"}], "cluster": 4, "position": {"x": -45.624149322509766, "y": 15.422049522399902}}, {"paperId": "8755c15fe073c6af03664b2a74aafef1fed5f198", "url": "https://www.semanticscholar.org/paper/8755c15fe073c6af03664b2a74aafef1fed5f198", "title": "BERT has a Moral Compass: Improvements of ethical and moral values of machines", "abstract": "Allowing machines to choose whether to kill humans would be devastating for world peace and security. But how do we equip machines with the ability to learn ethical or even moral choices? Jentzsch et al.(2019) showed that applying machine learning to human texts can extract deontological ethical reasoning about \"right\" and \"wrong\" conduct by calculating a moral bias score on a sentence level using sentence embeddings. The machine learned that it is objectionable to kill living beings, but it is fine to kill time; It is essential to eat, yet one might not eat dirt; it is important to spread information, yet one should not spread misinformation. However, the evaluated moral bias was restricted to simple actions -- one verb -- and a ranking of actions with surrounding context. Recently BERT ---and variants such as RoBERTa and SBERT--- has set a new state-of-the-art performance for a wide range of NLP tasks. But has BERT also a better moral compass? In this paper, we discuss and show that this is indeed the case. Thus, recent improvements of language representations also improve the representation of the underlying ethical and moral values of the machine. We argue that through an advanced semantic representation of text, BERT allows one to get better insights of moral and ethical values implicitly represented in text. This enables the Moral Choice Machine (MCM) to extract more accurate imprints of moral choices and ethical values.", "year": 2019, "authors": [{"authorId": "40896023", "name": "P. Schramowski"}, {"authorId": "13671251", "name": "Cigdem Turan"}, {"authorId": "151209594", "name": "Sophie F. Jentzsch"}, {"authorId": "3249046", "name": "C. Rothkopf"}, {"authorId": "1746871", "name": "K. Kersting"}], "cluster": 16, "position": {"x": 9.80479907989502, "y": 6.679966449737549}}, {"paperId": "ced289065723368bca48636edf71eeed50f40a39", "url": "https://www.semanticscholar.org/paper/ced289065723368bca48636edf71eeed50f40a39", "title": "Existential Risk Prevention as Global Priority", "abstract": "risks are those that threaten the entire future of humanity. Many theories of value imply that even relatively small reductions in net existential risk have enormous expected value. Despite their importance, issues surrounding human-extinction risks and related hazards remain poorly understood. In this article, I clarify the concept of existential risk and develop an improved classification scheme. I discuss the relation between existential risks and basic issues in axiology, and show how existential risk reduction (via the maxipok rule) can serve as a strongly action-guiding principle for utilitarian concerns. I also show how the notion of existential risk suggests a new way of thinking about the ideal of sustainability. Policy Implications \u2022 Existential risk is a concept that can focus long-term global efforts and sustainability concerns. \u2022 The biggest existential risks are anthropogenic and related to potential future technologies. \u2022 A moral case can be made that existential risk reduction is strictly more important than any other global public good. \u2022 Sustainability should be reconceptualised in dynamic terms, as aiming for a sustainable trajectory rather than a sus- tainable state. \u2022 Some small existential risks can be mitigated today directly (e.g. asteroids) or indirectly (by building resilience and reserves to increase survivability in a range of extreme scenarios) but it is more important to build capacity to improve humanity's ability to deal with the larger existential risks that will arise later in this century. This will require collective wisdom, technology foresight, and the ability when necessary to mobilise a strong global coordi- nated response to anticipated existential risks. \u2022 Perhaps the most cost-effective way to reduce existential risks today is to fund analysis of a wide range of existen- tial risks and potential mitigation strategies, with a long-term perspective.", "year": 2013, "authors": [{"authorId": "2193691", "name": "N. Bostrom"}], "cluster": 12, "position": {"x": -28.69054412841797, "y": -40.42756652832031}}]